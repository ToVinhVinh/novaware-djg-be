"""
Streamlit App for Recommendation System
Giao di·ªán ƒë·ªÉ demo, so s√°nh v√† hi·ªÉn th·ªã chi ti·∫øt thu·∫≠t to√°n c√°c models
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import sys
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, List
import time
import re

# Import training pipeline
# Add current directory to path to find train_recommendation.py
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# Import train_recommendation (will be used when training button is clicked)
_train_import_error = None
try:
    import train_recommendation
except ImportError as e:
    # Don't fail immediately, just show warning when needed
    train_recommendation = None
    _train_import_error = str(e)

# Page config
st.set_page_config(
    page_title="Fashion Recommendation System",
    page_icon="üëî",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #1f77b4;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2ca02c;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .step-header {
        font-size: 1.2rem;
        font-weight: bold;
        color: #d62728;
        margin-top: 1rem;
        background-color: #f0f2f6;
        padding: 0.5rem;
        border-radius: 5px;
    }
    .formula-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 5px;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_resource
def load_models():
    """Load trained models"""
    try:
        with open('recommendation_system/data/preprocessor.pkl', 'rb') as f:
            preprocessor = pickle.load(f)
        
        with open('recommendation_system/models/content_based_model.pkl', 'rb') as f:
            cb_model = pickle.load(f)
        
        with open('recommendation_system/models/gnn_model.pkl', 'rb') as f:
            gnn_model = pickle.load(f)
        
        with open('recommendation_system/models/hybrid_model.pkl', 'rb') as f:
            hybrid_model = pickle.load(f)
        
        return preprocessor, cb_model, gnn_model, hybrid_model
    except Exception as e:
        return None, None, None, None


@st.cache_data
def load_comparison_results():
    """Load comparison results"""
    try:
        df = pd.read_csv('recommendation_system/evaluation/comparison_results.csv')
        return df
    except:
        return None

def compute_sparsity(df: pd.DataFrame) -> pd.Series:
    """Return sparsity (percentage of missing values) per column"""
    if df.empty:
        return pd.Series(dtype=float)
    non_null_counts = df.count()
    sparsity = 1 - (non_null_counts / len(df))
    return sparsity.sort_values(ascending=False)

def render_sparsity_chart(df: pd.DataFrame, title: str, key: str):
    """Plot sparsity bar chart"""
    sparsity = compute_sparsity(df)
    if sparsity.empty:
        st.info("Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t√≠nh ƒë·ªô th∆∞a.")
        return
    sparsity_df = sparsity.reset_index()
    sparsity_df.columns = ['Column', 'Sparsity']
    fig = px.bar(
        sparsity_df,
        x='Column',
        y='Sparsity',
        title=title,
        labels={'Column': 'C·ªôt', 'Sparsity': 'ƒê·ªô th∆∞a (t·ªâ l·ªá null)'}
    )
    st.plotly_chart(fig, use_container_width=True)

def render_distribution_chart(df: pd.DataFrame, dataset_key: str):
    """Plot distribution chart for selected column"""
    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    available_cols = categorical_cols + numeric_cols
    if not available_cols:
        st.info("Kh√¥ng c√≥ c·ªôt ph√π h·ª£p ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì t·ªâ l·ªá.")
        return
    selected_col = st.selectbox(
        "Ch·ªçn c·ªôt ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì t·ªâ l·ªá",
        available_cols,
        key=f"{dataset_key}_distribution_column"
    )
    if selected_col in categorical_cols:
        value_counts = df[selected_col].fillna("N/A").value_counts().head(10)
        fig = px.pie(
            values=value_counts.values,
            names=value_counts.index,
            title=f"T·ªâ l·ªá ph√¢n b·ªë c·ªßa '{selected_col}'"
        )
    else:
        numeric_series = df[selected_col].dropna()
        if numeric_series.empty:
            st.info("C·ªôt ƒë√£ ch·ªçn kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì.")
            return
        hist_data = pd.cut(numeric_series, bins=10).value_counts().sort_index()
        hist_df = hist_data.reset_index()
        hist_df.columns = ['Range', 'Count']
        hist_df['Range'] = hist_df['Range'].astype(str)
        fig = px.bar(
            hist_df,
            x='Range',
            y='Count',
            title=f"Ph√¢n b·ªë gi√° tr·ªã c·ªßa '{selected_col}'",
            labels={'Range': 'Kho·∫£ng gi√° tr·ªã', 'Count': 'S·ªë l∆∞·ª£ng'}
        )
    st.plotly_chart(fig, use_container_width=True)

def render_data_statistics(df: pd.DataFrame):
    """Display descriptive statistics for numeric columns"""
    if df.empty:
        st.info("Dataset tr·ªëng, kh√¥ng th·ªÉ th·ªëng k√™.")
        return
    numeric_df = df.select_dtypes(include=[np.number])
    if numeric_df.empty:
        st.info("Kh√¥ng c√≥ c·ªôt s·ªë ƒë·ªÉ th·ªëng k√™.")
        return
    stats_df = numeric_df.describe().T  # count, mean, std, min, 25%, 50%, 75%, max
    st.dataframe(stats_df, use_container_width=True)

def render_dataset_upload_section(
    dataset_key: str,
    display_name: str,
    purpose_text: str
):
    """Render upload + analytics UI for a dataset"""
    st.markdown(f"#### {display_name}")
    st.write(purpose_text)
    uploaded_file = st.file_uploader(
        f"T·∫£i l√™n {display_name}",
        type=['csv'],
        key=f"{dataset_key}_file_uploader"
    )
    if uploaded_file is None:
        st.info("Ch∆∞a c√≥ file ƒë∆∞·ª£c t·∫£i l√™n.")
        return
    try:
        df = pd.read_csv(uploaded_file)
    except Exception as exc:
        st.error(f"L·ªói khi ƒë·ªçc file CSV: {exc}")
        return
    st.success(f"ƒê√£ t·∫£i {display_name}: {len(df)} rows √ó {len(df.columns)} columns")
    col_rows, col_cols = st.columns(2)
    with col_rows:
        st.metric("S·ªë d√≤ng (rows)", len(df))
    with col_cols:
        st.metric("S·ªë c·ªôt (columns)", len(df.columns))
    st.markdown("**üëÄ Xem tr∆∞·ªõc d·ªØ li·ªáu (t·ªëi ƒëa 100 d√≤ng ƒë·∫ßu):**")
    st.dataframe(df.head(100), use_container_width=True)
    st.markdown("**üìâ Bi·ªÉu ƒë·ªì ƒë·ªô th∆∞a (t·ªâ l·ªá gi√° tr·ªã null tr√™n m·ªói c·ªôt):**")
    render_sparsity_chart(df, f"ƒê·ªô th∆∞a - {display_name}", dataset_key)
    st.markdown("**üìä Bi·ªÉu ƒë·ªì t·ªâ l·ªá / ph√¢n b·ªë:**")
    render_distribution_chart(df, dataset_key)
    st.markdown("**üìà B·∫£ng th·ªëng k√™ d·ªØ li·ªáu (count, mean, std, min, 25%, 50%, 75%, max):**")
    render_data_statistics(df)

def display_product_info(product_info: Dict, score: float = None):
    """Display product information"""
    col1, col2 = st.columns([1, 3])
    
    with col1:
        if score is not None:
            st.metric("Score", f"{score:.4f}")
    
    with col2:
        st.markdown(f"**{product_info.get('productDisplayName', 'N/A')}**")
        st.write(f"üè∑Ô∏è **Category**: {product_info.get('masterCategory', 'N/A')} > {product_info.get('subCategory', 'N/A')} > {product_info.get('articleType', 'N/A')}")
        st.write(f"üë§ **Gender**: {product_info.get('gender', 'N/A')}")
        st.write(f"üé® **Color**: {product_info.get('baseColour', 'N/A')}")

def render_metrics_table(df, highlight_model=None):
    """Render metrics table with highlighting"""
    if df is None:
        st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu metrics. Vui l√≤ng ch·∫°y t√≠nh to√°n tr∆∞·ªõc.")
        return

    st.markdown("### üìä B·∫£ng T·ªïng H·ª£p Ch·ªâ S·ªë C√°c M√¥ H√¨nh")
    
    # Format dataframe - ch·ªâ l·∫•y c√°c c·ªôt c·∫ßn thi·∫øt
    required_cols = ['model_name', 'recall@10', 'recall@20', 'ndcg@10', 'ndcg@20', 
                     'precision@10', 'precision@20', 'training_time', 'avg_inference_time',
                     'coverage@10', 'diversity@10']
    
    # T·∫°o display_df v·ªõi c√°c c·ªôt c·∫ßn thi·∫øt
    display_df = df.copy()
    available_cols = [col for col in required_cols if col in display_df.columns]
    display_df = display_df[available_cols]
    
    # Rename columns for better display
    column_mapping = {
        'model_name': 'Model',
        'recall@10': 'Recall@10',
        'recall@20': 'Recall@20',
        'ndcg@10': 'NDCG@10',
        'ndcg@20': 'NDCG@20',
        'precision@10': 'Precision@10',
        'precision@20': 'Precision@20',
        'training_time': 'Training Time (s)',
        'avg_inference_time': 'Inference Time (s)',
        'coverage@10': 'Coverage@10',
        'diversity@10': 'Diversity@10'
    }
    display_df = display_df.rename(columns=column_mapping)
    
    # Format numeric columns
    numeric_cols = display_df.select_dtypes(include=[np.number]).columns
    display_df[numeric_cols] = display_df[numeric_cols].round(4)
    
    def highlight_row(row):
        model_name = row.get('Model', '')
        if model_name == highlight_model:
            return ['background-color: #e6ffe6'] * len(row)
        return [''] * len(row)

    st.dataframe(display_df.style.apply(highlight_row, axis=1), use_container_width=True)


def slugify_model_name(model_name: str) -> str:
    """Convert model name to slug used for log filenames."""
    return re.sub(r'[^a-z0-9]+', '_', model_name.lower()).strip('_')


def load_evaluation_log(model_name: str):
    """Load evaluation log content for a model."""
    slug = slugify_model_name(model_name)
    log_path = os.path.join('recommendation_system', 'evaluation', 'logs', f'{slug}.log')
    if os.path.exists(log_path):
        with open(log_path, 'r', encoding='utf-8') as f:
            return slug, f.read()
    return slug, None


def parse_evaluation_log(log_text: str) -> Dict:
    """
    Parse evaluation log ƒë·ªÉ extract metrics v√† v√≠ d·ª• t√≠nh to√°n
    
    Returns:
        Dictionary ch·ª©a:
        - metrics: Dict v·ªõi c√°c metrics v√† gi√° tr·ªã
        - examples: Dict v·ªõi c√°c v√≠ d·ª• t√≠nh to√°n cho t·ª´ng metric
        - formulas: Dict v·ªõi c√°c c√¥ng th·ª©c cho t·ª´ng metric
    """
    if not log_text:
        return {'metrics': {}, 'examples': {}, 'formulas': {}}
    
    metrics = {}
    examples = {}
    formulas = {}
    
    lines = log_text.split('\n')
    i = 0
    current_metric = None
    
    while i < len(lines):
        line = lines[i].strip()
        
        # Skip empty lines and headers
        if not line or line.startswith('===') or line.startswith('[') or 'EVALUATING' in line or 'RESULTS FOR' in line:
            i += 1
            continue
        
        # Parse metric value (format: "metric_name: value")
        # Look for pattern like "recall@10: 0.0186" or "training_time: 0.0807"
        if ':' in line and not line.startswith('üìê') and not line.startswith('üßÆ'):
            parts = line.split(':', 1)
            if len(parts) == 2:
                metric_name = parts[0].strip()
                value_str = parts[1].strip()
                
                # Remove any trailing text after the number
                # e.g., "0.0186   üìê C√¥ng th·ª©c:" -> "0.0186"
                value_str = value_str.split()[0] if value_str.split() else value_str
                
                # Try to parse as float
                try:
                    value = float(value_str)
                    metrics[metric_name] = value
                    current_metric = metric_name
                except ValueError:
                    pass
        
        # Parse formula (format: "   üìê C√¥ng th·ª©c: ...")
        if 'üìê C√¥ng th·ª©c:' in line:
            formula = line.split('üìê C√¥ng th·ª©c:', 1)[1].strip()
            if current_metric:
                formulas[current_metric] = formula
        
        if 'V√≠ d·ª• √°p d·ª•ng:' in line:
            example = line.split('V√≠ d·ª• √°p d·ª•ng:', 1)[1].strip()
            if current_metric:
                examples[current_metric] = example
        
        i += 1
    
    return {
        'metrics': metrics,
        'examples': examples,
        'formulas': formulas
    }


def render_metrics_in_step(
    metrics_data,
    metric_keys: List[str],
    step_title: str,
    key_suffix: str,
    model_name: str = None
):
    """
    Hi·ªÉn th·ªã metrics chi ti·∫øt trong m·ªôt b∆∞·ªõc
    
    Args:
        metrics_data: Dictionary t·ª´ parse_evaluation_log ho·∫∑c pd.Series t·ª´ comparison_df
        metric_keys: List c√°c metric keys c·∫ßn hi·ªÉn th·ªã (e.g., ['recall@10', 'precision@10'])
        step_title: Ti√™u ƒë·ªÅ c·ªßa b∆∞·ªõc
        key_suffix: Suffix cho key c·ªßa Streamlit components
        model_name: T√™n model (ƒë·ªÉ load log n·∫øu c·∫ßn)
    """
    # Ki·ªÉm tra metrics_data m·ªôt c√°ch an to√†n (tr√°nh l·ªói v·ªõi pandas Series)
    if metrics_data is None:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu metrics. Vui l√≤ng ch·∫°y train & evaluate tr∆∞·ªõc.")
        return
    elif isinstance(metrics_data, pd.Series):
        if metrics_data.empty:
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu metrics. Vui l√≤ng ch·∫°y train & evaluate tr∆∞·ªõc.")
            return
    elif isinstance(metrics_data, dict):
        if not metrics_data or (isinstance(metrics_data, dict) and 'metrics' in metrics_data and not metrics_data['metrics']):
            st.info("Ch∆∞a c√≥ d·ªØ li·ªáu metrics. Vui l√≤ng ch·∫°y train & evaluate tr∆∞·ªõc.")
            return
    
    # Load parsed log ƒë·ªÉ l·∫•y formulas v√† examples (n·∫øu ch∆∞a c√≥ trong metrics_data)
    parsed_log = None
    if model_name:
        _, log_text = load_evaluation_log(model_name)
        if log_text:
            parsed_log = parse_evaluation_log(log_text)
    
    # T·∫°o columns cho metrics (2 c·ªôt)
    n_cols = 2
    cols = st.columns(n_cols)
    
    for idx, metric_key in enumerate(metric_keys):
        col_idx = idx % n_cols
        with cols[col_idx]:
            # Get metric value, formula, and example
            value = None
            formula = ''
            example = ''
            
            if isinstance(metrics_data, dict) and 'metrics' in metrics_data:
                # From parsed log
                value = metrics_data['metrics'].get(metric_key, None)
                formula = metrics_data['formulas'].get(metric_key, '')
                example = metrics_data['examples'].get(metric_key, '')
            elif isinstance(metrics_data, pd.Series):
                # From comparison_df
                value = metrics_data.get(metric_key, None)
                # Get formula and example from parsed log if available
                if parsed_log:
                    formula = parsed_log['formulas'].get(metric_key, '')
                    example = parsed_log['examples'].get(metric_key, '')
            
            if value is not None:
                # Format metric name for display
                display_name = metric_key.replace('@', '@').replace('_', ' ').title()
                
                # Display metric
                st.metric(display_name, f"{value:.4f}")
                
                # Show formula and example in expander
                with st.expander(f"Chi ti·∫øt {display_name}", expanded=False):
                    if formula:
                        st.markdown(f"**C√¥ng th·ª©c:** {formula}")
                    
                    if example:
                        # Ph√¢n t√≠ch example ƒë·ªÉ hi·ªÉn th·ªã r√µ r√†ng h∆°n
                        if "| Trung b√¨nh" in example:
                            # T√°ch example th√†nh c√°c ph·∫ßn
                            parts = example.split(" | ")
                            user_examples = []
                            avg_formula = None
                            
                            for part in parts:
                                if "Trung b√¨nh" in part:
                                    avg_formula = part
                                else:
                                    user_examples.append(part)
                            
                            # Hi·ªÉn th·ªã v√≠ d·ª• t√≠nh to√°n cho t·ª´ng user
                            st.markdown("#### V√≠ d·ª• t√≠nh to√°n cho t·ª´ng user:")
                            for i, user_ex in enumerate(user_examples, 1):
                                st.markdown(f"**{i}. {user_ex}**")
                            
                            if avg_formula:
                                st.markdown("#### C√¥ng th·ª©c t√≠nh trung b√¨nh:")
                                
                                # Parse c√¥ng th·ª©c ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n
                                if "=" in avg_formula:
                                    formula_parts = avg_formula.split("=")
                                    if len(formula_parts) >= 2:
                                        left_side = formula_parts[0].strip()
                                        right_side = "=".join(formula_parts[1:]).strip()
                                        
                                        # Extract s·ªë users t·ª´ c√¥ng th·ª©c
                                        import re
                                        n_users_match = re.search(r'user(\d+)', right_side)
                                        n_users = n_users_match.group(1) if n_users_match else "N"
                                        
                                        # Extract metric name t·ª´ display_name
                                        metric_var = display_name.replace(" ", "_").lower()
                                        
                                        # Hi·ªÉn th·ªã c√¥ng th·ª©c d·∫°ng to√°n h·ªçc
                                        st.markdown(f"""
                                        **C√¥ng th·ª©c:**
                                        $$\\text{{Trung b√¨nh}} = \\frac{{\\sum_{{u=1}}^{{{n_users}}} {display_name}_u}}{{{n_users}}}$$
                                        """)
                                        
                                        # Hi·ªÉn th·ªã d·∫°ng m·ªü r·ªông
                                        st.markdown(f"""
                                        **D·∫°ng m·ªü r·ªông:**
                                        $$\\text{{Trung b√¨nh}} = \\frac{{{display_name}_{{user1}} + {display_name}_{{user2}} + \\ldots + {display_name}_{{user{n_users}}}}}{{{n_users}}}$$
                                        """)
                                        
                                        # Hi·ªÉn th·ªã v·ªõi gi√° tr·ªã c·ª• th·ªÉ t·ª´ v√≠ d·ª•
                                        if len(user_examples) >= 1:
                                            # L·∫•y gi√° tr·ªã t·ª´ c√°c v√≠ d·ª• users
                                            example_values = []
                                            for ex in user_examples:
                                                # Extract gi√° tr·ªã t·ª´ v√≠ d·ª•
                                                # Format c√≥ th·ªÉ l√†: "User X: hits=Y, |T_u|=Z ‚Üí recall=0.0186"
                                                # ho·∫∑c: "User X: DCG=Y, IDCG=Z ‚Üí NDCG=0.0575"
                                                # ho·∫∑c: "User X: hits=Y, K=Z ‚Üí precision=0.0100"
                                                
                                                # T√¨m pattern: "‚Üí metric_name=value" (gi√° tr·ªã sau d·∫•u ‚Üí)
                                                # Ho·∫∑c t√¨m gi√° tr·ªã cu·ªëi c√πng trong chu·ªói (sau d·∫•u = cu·ªëi c√πng)
                                                pattern1 = r'‚Üí\s*\w+\s*=\s*([\d.]+)'  # "‚Üí recall=0.0186" ho·∫∑c "‚Üí NDCG=0.0575"
                                                match1 = re.search(pattern1, ex)
                                                
                                                if match1:
                                                    val = float(match1.group(1))
                                                    example_values.append(val)
                                                else:
                                                    # Fallback: t√¨m t·∫•t c·∫£ c√°c gi√° tr·ªã s·ªë v√† l·∫•y gi√° tr·ªã cu·ªëi c√πng
                                                    # (th∆∞·ªùng l√† metric value)
                                                    all_numbers = re.findall(r'([\d.]+)', ex)
                                                    if all_numbers:
                                                        # L·∫•y s·ªë cu·ªëi c√πng (th∆∞·ªùng l√† metric value)
                                                        val = float(all_numbers[-1])
                                                        example_values.append(val)
                                            
                                            if example_values:
                                                n_examples = len(example_values)
                                                # Hi·ªÉn th·ªã v√≠ d·ª• v·ªõi c√°c users
                                                example_text = f"**V√≠ d·ª• v·ªõi {n_examples} user(s):**\n"
                                                for i, (ex, val) in enumerate(zip(user_examples[:3], example_values[:3]), 1):
                                                    # Extract user number
                                                    user_match = re.search(r'User\s+(\d+)', ex)
                                                    user_num = user_match.group(1) if user_match else str(i)
                                                    example_text += f"- {display_name}_user{user_num} = {val:.4f}\n"
                                                
                                                if n_examples < int(n_users):
                                                    example_text += f"- ...\n"
                                                    example_text += f"- {display_name}_user{n_users} = ...\n"
                                                
                                                # T·∫°o c√¥ng th·ª©c v·ªõi v√≠ d·ª•
                                                if n_examples >= 2:
                                                    sum_example = sum(example_values[:2])
                                                    formula_example = f"{example_values[0]:.4f} + {example_values[1]:.4f}"
                                                    if n_examples > 2:
                                                        formula_example += f" + {example_values[2]:.4f}"
                                                    formula_example += f" + \\ldots"
                                                else:
                                                    formula_example = f"{example_values[0]:.4f} + \\ldots"
                                                
                                                st.markdown(example_text)
                                                st.markdown(f"""
                                                **T√≠nh to√°n:**
                                                $$\\text{{Trung b√¨nh}} = \\frac{{{formula_example} + {display_name}_{{user{n_users}}}}}{{{n_users}}} = {value:.4f}$$
                                                """)
                        else:
                            st.markdown(f"**V√≠ d·ª• √°p d·ª•ng:** {example}")
                    
                    if not formula and not example:
                        st.info("Ch∆∞a c√≥ chi ti·∫øt t√≠nh to√°n. Xem log evaluation ƒë·ªÉ bi·∫øt th√™m.")
            else:
                # Metric kh√¥ng c√≥ trong data
                display_name = metric_key.replace('@', '@').replace('_', ' ').title()
                st.info(f"{display_name}: Ch∆∞a c√≥ d·ªØ li·ªáu")


def render_evaluation_log_section(model_name: str, key_suffix: str):
    """Display evaluation logs (if any) inside an expander."""
    slug, log_text = load_evaluation_log(model_name)
    with st.expander("üìú Evaluation Log (Raw)", expanded=False):
        if log_text:
            st.text_area(
                "Chi ti·∫øt log t√≠nh to√°n",
                log_text,
                height=320,
                key=f"log_text_{key_suffix}"
            )
            st.download_button(
                "‚¨áÔ∏è T·∫£i log",
                log_text,
                file_name=f"{slug}.log",
                mime="text/plain",
                key=f"log_download_{key_suffix}"
            )
        else:
            st.info("Ch∆∞a c√≥ log evaluation. H√£y ch·∫°y train & evaluate ƒë·ªÉ t·∫°o log.")


def run_training(model_type: str):
    """Run training for specific model type"""
    import io
    from contextlib import redirect_stdout
    
    model_names = {
        "all": "T·∫•t C·∫£ Models",
        "content_based": "Content-Based Filtering",
        "gnn": "GNN (GraphSAGE)",
        "hybrid": "Hybrid (GNN + Content-Based)"
    }
    
    model_name = model_names.get(model_type, model_type)
    
    with st.status(f"ƒêang train {model_name}...", expanded=True) as status:
        st.write(f"üöÄ B·∫Øt ƒë·∫ßu training {model_name}...")
        try:
            # Redirect stdout to capture logs
            f = io.StringIO()
            with redirect_stdout(f):
                if model_type == "all":
                    train_recommendation.train_and_evaluate()
                elif model_type == "content_based":
                    train_recommendation.train_content_based(evaluate=True)
                elif model_type == "gnn":
                    train_recommendation.train_gnn(evaluate=True)
                elif model_type == "hybrid":
                    train_recommendation.train_hybrid(evaluate=True)
                else:
                    raise ValueError(f"Unknown model type: {model_type}")
            
            output_log = f.getvalue()
            st.text_area("Logs", output_log, height=300)
            
            # Reload data
            st.cache_resource.clear()
            st.cache_data.clear()
            preprocessor, cb_model, gnn_model, hybrid_model = load_models()
            comparison_df = load_comparison_results()
            
            status.update(label=f"‚úÖ Ho√†n th√†nh training {model_name}!", state="complete", expanded=False)
            st.success(f"‚úÖ ƒê√£ ho√†n th√†nh training {model_name} v√† c·∫≠p nh·∫≠t s·ªë li·ªáu!")
        except Exception as e:
            status.update(label=f"‚ùå L·ªói khi train {model_name}", state="error")
            st.error(f"L·ªói: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

def main():
    """Main app"""
    
    # Header
    st.markdown('<div class="main-header">üëî Fashion Recommendation System</div>', unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.title("‚öôÔ∏è Menu")
    
    page = st.sidebar.radio(
        "Ch·ªçn ch·ª©c nƒÉng",
        ["üìö Algorithms & Steps", "üìä Model Comparison", "üéØ Personalized Recommendations", "üëó Outfit Recommendations"]
    )
    
    # Load data initially
    preprocessor, cb_model, gnn_model, hybrid_model = load_models()
    comparison_df = load_comparison_results()

    # ========== PAGE 1: ALGORITHMS & STEPS ==========
    if page == "üìö Algorithms & Steps":
        st.markdown("### Upload & Kh√°m Ph√° B·ªô D·ªØ Li·ªáu")
        dataset_sections = [
            (
                "users",
                "users.csv",
                "Ch·ª©a th√¥ng tin h·ªì s∆° ng∆∞·ªùi d√πng (tu·ªïi, gi·ªõi t√≠nh, th·ªã hi·∫øu) d√πng ƒë·ªÉ c√° nh√¢n h√≥a g·ª£i √Ω v√† theo d√µi h√†nh vi."
            ),
            (
                "products",
                "products.csv",
                "Danh s√°ch to√†n b·ªô s·∫£n ph·∫©m (category, m√†u s·∫Øc, usage...) d√πng cho Content-Based v√† visualization."
            ),
            (
                "interactions",
                "interactions.csv",
                "Log t∆∞∆°ng t√°c user-product (purchase/cart/like) l√†m ƒë·∫ßu v√†o hu·∫•n luy·ªán GNN & ƒë√°nh gi√°."
            )
        ]
        for ds_key, ds_name, ds_desc in dataset_sections:
            render_dataset_upload_section(ds_key, ds_name, ds_desc)
        
        # Training Buttons Section
        st.markdown("### üîÑ Training Models")
        
        # Check if train_recommendation is available
        if train_recommendation is None:
            st.error(f"‚ùå Kh√¥ng th·ªÉ import train_recommendation module: {_train_import_error}")
            st.info("Vui l√≤ng ƒë·∫£m b·∫£o file train_recommendation.py t·ªìn t·∫°i trong th∆∞ m·ª•c g·ªëc.")
        else:
            # Create columns for buttons
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                if st.button("üîÑ Train T·∫•t C·∫£", type="primary", use_container_width=True):
                    run_training("all")
            
            with col2:
                if st.button("üìä Train Content-Based", use_container_width=True):
                    run_training("content_based")
            
            with col3:
                if st.button("üï∏Ô∏è Train GNN", use_container_width=True):
                    run_training("gnn")
            
            with col4:
                if st.button("üîÄ Train Hybrid", use_container_width=True):
                    run_training("hybrid")
            
            st.info("üí° Ch·ªçn model ƒë·ªÉ train ri√™ng l·∫ª ho·∫∑c train t·∫•t c·∫£ c√πng l√∫c. Hybrid model c·∫ßn Content-Based v√† GNN ƒë√£ ƒë∆∞·ª£c train tr∆∞·ªõc.")

        if preprocessor is None:
            st.warning("Vui l√≤ng ch·∫°y t√≠nh to√°n ƒë·ªÉ kh·ªüi t·∫°o models.")
            st.stop()

        # Tabs for each model
        tab1, tab2, tab3 = st.tabs(["1Ô∏è‚É£ Content-Based Filtering", "2Ô∏è‚É£ GNN (GraphSAGE)", "3Ô∏è‚É£ Hybrid Model"])
        
        # --- CONTENT-BASED TAB ---
        with tab1:
            st.markdown("### 1Ô∏è‚É£ Content-Based Filtering")
            st.markdown("**M√¥ t·∫£:** G·ª£i √Ω d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng v·ªÅ ƒë·∫∑c ƒëi·ªÉm s·∫£n ph·∫©m (Category, Color, Usage...).")
            
            # B∆Ø·ªöC 1
            with st.expander("B∆∞·ªõc 1: Feature Engineering (T·∫°o ƒë·∫∑c tr∆∞ng)", expanded=True):
                st.markdown('<div class="step-header">B∆∞·ªõc 1: Feature Engineering</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung th·ª±c hi·ªán:** Chuy·ªÉn ƒë·ªïi c√°c thu·ªôc t√≠nh s·∫£n ph·∫©m th√†nh chu·ªói vƒÉn b·∫£n, √°p d·ª•ng tr·ªçng s·ªë b·∫±ng c√°ch l·∫∑p l·∫°i t·ª´ kh√≥a.")
                
                # Th√¥ng tin d·ªØ li·ªáu
                col_data1, col_data2 = st.columns(2)
                with col_data1:
                    st.metric("T·ªïng s·ªë s·∫£n ph·∫©m", len(preprocessor.products_df))
                    st.metric("T·ªïng s·ªë users", len(preprocessor.users_df))
                with col_data2:
                    st.metric("Train interactions", len(preprocessor.train_interactions))
                    st.metric("Test interactions", len(preprocessor.test_interactions))
                
                st.write(f"**D·ªØ li·ªáu s·ª≠ d·ª•ng:** To√†n b·ªô {len(preprocessor.products_df)} s·∫£n ph·∫©m trong `products.csv` (kh√¥ng ph√¢n chia train/test v√¨ ƒë√¢y l√† d·ªØ li·ªáu s·∫£n ph·∫©m tƒ©nh).")
                
                st.markdown("""
                **C√¥ng th·ª©c √°p d·ª•ng:**
                $$Text(P_i) = [Gender] + [MasterCategory] + [SubCategory] \\times 2 + [ArticleType] \\times 3 + [BaseColour] + [Usage]$$
                
                **Gi·∫£i th√≠ch:** C√°c features ƒë∆∞·ª£c k·∫øt h·ª£p th√†nh chu·ªói vƒÉn b·∫£n, trong ƒë√≥:
                - `ArticleType` ƒë∆∞·ª£c l·∫∑p l·∫°i **3 l·∫ßn** (tr·ªçng s·ªë cao nh·∫•t - quan tr·ªçng nh·∫•t)
                - `SubCategory` ƒë∆∞·ª£c l·∫∑p l·∫°i **2 l·∫ßn** (tr·ªçng s·ªë trung b√¨nh)
                - C√°c features kh√°c (Gender, MasterCategory, BaseColour, Usage) xu·∫•t hi·ªán **1 l·∫ßn**
                
                **L√Ω do:** Vi·ªác l·∫∑p l·∫°i gi√∫p TF-IDF coi tr·ªçng c√°c features quan tr·ªçng h∆°n khi t√≠nh to√°n similarity.
                """)
                
                st.write("**V√≠ d·ª• √°p d·ª•ng c√¥ng th·ª©c:**")
                if len(cb_model.products_df) > 0:
                    example_product = cb_model.products_df.iloc[0]
                    st.write(f"- **S·∫£n ph·∫©m:** {example_product.get('productDisplayName', 'N/A')}")
                    st.write(f"- Gender: {example_product.get('gender', 'N/A')}")
                    st.write(f"- MasterCategory: {example_product.get('masterCategory', 'N/A')}")
                    st.write(f"- SubCategory: {example_product.get('subCategory', 'N/A')} (x2)")
                    st.write(f"- ArticleType: {example_product.get('articleType', 'N/A')} (x3)")
                    st.write(f"- BaseColour: {example_product.get('baseColour', 'N/A')}")
                    st.write(f"- Usage: {example_product.get('usage', 'N/A')}")
                
                st.write("**K·∫øt qu·∫£ t√≠nh to√°n (V√≠ d·ª• 2 s·∫£n ph·∫©m ƒë·∫ßu ti√™n):**")
                example_df = cb_model.products_df[['productDisplayName', 'feature_text']].head(2)
                st.dataframe(example_df, use_container_width=True)
                st.info("üí° **Ph√¢n t√≠ch:** Vi·ªác l·∫∑p l·∫°i `ArticleType` 3 l·∫ßn gi√∫p thu·∫≠t to√°n coi tr·ªçng lo·∫°i s·∫£n ph·∫©m h∆°n m√†u s·∫Øc. ƒêi·ªÅu n√†y gi√∫p g·ª£i √Ω s·∫£n ph·∫©m c√πng lo·∫°i (v√≠ d·ª•: √°o thun v·ªõi √°o thun) thay v√¨ ch·ªâ d·ª±a v√†o m√†u s·∫Øc.")

            # B∆Ø·ªöC 2
            with st.expander("B∆∞·ªõc 2: Vectorization (TF-IDF) & Ma tr·∫≠n"):
                st.markdown('<div class="step-header">B∆∞·ªõc 2: Vectorization</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung th·ª±c hi·ªán:** Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector s·ªë h·ªçc s·ª≠ d·ª•ng TF-IDF.")
                st.write(f"**D·ªØ li·ªáu s·ª≠ d·ª•ng:** To√†n b·ªô {len(cb_model.products_df)} s·∫£n ph·∫©m t·ª´ B∆∞·ªõc 1 (feature_text).")
                
                st.markdown("""
                **C√¥ng th·ª©c TF-IDF:**
                $$TF(t, d) = \\frac{count(t, d)}{len(d)}, \\quad IDF(t) = \\log(\\frac{N}{df(t)}), \\quad TF\\text{-}IDF = TF \\times IDF$$
                
                Trong ƒë√≥:
                - $TF(t, d)$: T·∫ßn su·∫•t t·ª´ $t$ trong document $d$
                - $IDF(t)$: Ngh·ªãch ƒë·∫£o t·∫ßn su·∫•t document, ƒëo ƒë·ªô hi·∫øm c·ªßa t·ª´ $t$
                - $N$: T·ªïng s·ªë documents (s·∫£n ph·∫©m)
                - $df(t)$: S·ªë documents ch·ª©a t·ª´ $t$
                """)
                
                if cb_model.tfidf_vectorizer is not None:
                    feature_names = cb_model.tfidf_vectorizer.get_feature_names_out()
                    # L·∫•y vector c·ªßa 5 s·∫£n ph·∫©m ƒë·∫ßu ti√™n
                    tfidf_subset = cb_model.tfidf_vectorizer.transform(cb_model.products_df['feature_text'].head(5))
                    tfidf_df = pd.DataFrame(tfidf_subset.toarray(), columns=feature_names, index=cb_model.products_df['productDisplayName'].head(5))
                    
                    st.write(f"**Ma tr·∫≠n TF-IDF (Top 5 s·∫£n ph·∫©m x Top 10 features):**")
                    st.write(f"**Shape:** {tfidf_subset.shape[0]} s·∫£n ph·∫©m √ó {tfidf_subset.shape[1]} features")
                    st.dataframe(tfidf_df.iloc[:, :10].style.background_gradient(cmap='Blues', axis=None), use_container_width=True)
                    
                    if len(tfidf_df) >= 2:
                        p1_name = tfidf_df.index[0]
                        p2_name = tfidf_df.index[1]
                        # T√¨m feature c√≥ gi√° tr·ªã cao nh·∫•t cho m·ªói s·∫£n ph·∫©m
                        top_feature_p1 = tfidf_df.loc[p1_name].nlargest(1).index[0]
                        top_value_p1 = tfidf_df.loc[p1_name, top_feature_p1]
                        st.write(f"**V√≠ d·ª• √°p d·ª•ng:** S·∫£n ph·∫©m *'{p1_name}'* c√≥ feature *'{top_feature_p1}'* v·ªõi TF-IDF score = **{top_value_p1:.4f}** (cao nh·∫•t).")
                    
                    st.info(f"üí° **√ù nghƒ©a:** Gi√° tr·ªã c√†ng cao (ƒë·∫≠m) nghƒ©a l√† t·ª´ kh√≥a ƒë√≥ c√†ng ƒë·∫∑c tr∆∞ng cho s·∫£n ph·∫©m. Ma tr·∫≠n th∆∞a (nhi·ªÅu s·ªë 0) v√¨ m·ªói s·∫£n ph·∫©m ch·ªâ c√≥ m·ªôt s·ªë features nh·∫•t ƒë·ªãnh.")

            # B∆Ø·ªöC 3
            with st.expander("B∆∞·ªõc 3: Similarity Calculation & V√≠ d·ª• t√≠nh to√°n"):
                st.markdown('<div class="step-header">B∆∞·ªõc 3: T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung th·ª±c hi·ªán:** T√≠nh Cosine Similarity gi·ªØa t·∫•t c·∫£ c√°c c·∫∑p s·∫£n ph·∫©m d·ª±a tr√™n TF-IDF vectors.")
                st.write(f"**D·ªØ li·ªáu s·ª≠ d·ª•ng:** Ma tr·∫≠n TF-IDF t·ª´ B∆∞·ªõc 2 ({cb_model.similarity_matrix.shape[0]} √ó {cb_model.similarity_matrix.shape[1]}).")
                
                st.markdown("""
                **C√¥ng th·ª©c Cosine Similarity:**
                $$Cosine(A, B) = \\frac{A \\cdot B}{||A|| \\times ||B||} = \\frac{\\sum_{i=1}^{n} A_i B_i}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\sqrt{\\sum_{i=1}^{n} B_i^2}}$$
                
                Trong ƒë√≥:
                - $A, B$: Hai vector TF-IDF c·ªßa 2 s·∫£n ph·∫©m
                - $A_i, B_i$: Gi√° tr·ªã TF-IDF c·ªßa feature th·ª© $i$
                - K·∫øt qu·∫£: Gi√° tr·ªã t·ª´ 0 ƒë·∫øn 1 (1 = gi·ªëng nhau ho√†n to√†n, 0 = kh√°c bi·ªát ho√†n to√†n)
                """)
                
                if cb_model.similarity_matrix is not None:
                    # L·∫•y ma tr·∫≠n similarity nh·ªè (5x5)
                    sim_subset = cb_model.similarity_matrix[:5, :5]
                    sim_df = pd.DataFrame(sim_subset, 
                                        index=cb_model.products_df['productDisplayName'].head(5),
                                        columns=cb_model.products_df['productDisplayName'].head(5))
                    
                    st.write(f"**Ma tr·∫≠n Similarity (5√ó5 m·∫´u t·ª´ ma tr·∫≠n {cb_model.similarity_matrix.shape[0]}√ó{cb_model.similarity_matrix.shape[1]}):**")
                    st.dataframe(sim_df.style.background_gradient(cmap='Greens', axis=None), use_container_width=True)
                    
                    # Th·ªëng k√™
                    avg_sim = cb_model.similarity_matrix.mean()
                    max_sim = cb_model.similarity_matrix.max()
                    min_sim = cb_model.similarity_matrix.min()
                    st.write(f"**Th·ªëng k√™ ma tr·∫≠n:**")
                    st.write(f"- ƒê·ªô t∆∞∆°ng ƒë·ªìng trung b√¨nh: {avg_sim:.4f}")
                    st.write(f"- ƒê·ªô t∆∞∆°ng ƒë·ªìng cao nh·∫•t: {max_sim:.4f} (s·∫£n ph·∫©m v·ªõi ch√≠nh n√≥)")
                    st.write(f"- ƒê·ªô t∆∞∆°ng ƒë·ªìng th·∫•p nh·∫•t: {min_sim:.4f}")
                    
                    # V√≠ d·ª• t√≠nh to√°n c·ª• th·ªÉ
                    p1_name = sim_df.index[0]
                    p2_name = sim_df.index[1]
                    score = sim_df.iloc[0, 1]
                    st.write(f"**V√≠ d·ª• √°p d·ª•ng:** ƒê·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa *'{p1_name}'* v√† *'{p2_name}'* l√† **{score:.4f}**.")
                    if score > 0.5:
                        st.write("=> Hai s·∫£n ph·∫©m n√†y r·∫•t gi·ªëng nhau v·ªÅ ƒë·∫∑c ƒëi·ªÉm (c√≥ th·ªÉ c√πng lo·∫°i, m√†u s·∫Øc, ho·∫∑c m·ª•c ƒë√≠ch s·ª≠ d·ª•ng).")
                    elif score > 0.3:
                        st.write("=> Hai s·∫£n ph·∫©m n√†y c√≥ m·ªôt s·ªë ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng.")
                    else:
                        st.write("=> Hai s·∫£n ph·∫©m n√†y kh√° kh√°c bi·ªát v·ªÅ ƒë·∫∑c ƒëi·ªÉm.")

            # B∆Ø·ªöC 4
            with st.expander("B∆∞·ªõc 4: Evaluation (T√≠nh to√°n ch·ªâ s·ªë)", expanded=True):
                st.markdown('<div class="step-header">B∆∞·ªõc 4: ƒê√°nh gi√° & T√≠nh Metrics</div>', unsafe_allow_html=True)
                
                # Th√¥ng tin d·ªØ li·ªáu
                st.write("**D·ªØ li·ªáu s·ª≠ d·ª•ng:**")
                col_eval1, col_eval2 = st.columns(2)
                with col_eval1:
                    st.metric("Train-set", f"{len(preprocessor.train_interactions)} interactions")
                    st.write(f"- Users: {preprocessor.train_interactions['user_idx'].nunique()}")
                    st.write(f"- Products: {preprocessor.train_interactions['product_idx'].nunique()}")
                with col_eval2:
                    st.metric("Test-set", f"{len(preprocessor.test_interactions)} interactions")
                    st.write(f"- Users: {preprocessor.test_interactions['user_idx'].nunique()}")
                    st.write(f"- Products: {preprocessor.test_interactions['product_idx'].nunique()}")
                
                st.write("**Quy tr√¨nh ƒë√°nh gi√°:**")
                st.write("1. V·ªõi m·ªói user trong test-set, ·∫©n c√°c s·∫£n ph·∫©m h·ªç ƒë√£ t∆∞∆°ng t√°c (purchase/cart/like)")
                st.write("2. D√πng m√¥ h√¨nh g·ª£i √Ω Top-K s·∫£n ph·∫©m cho user ƒë√≥")
                st.write("3. So s√°nh danh s√°ch g·ª£i √Ω v·ªõi ground truth (s·∫£n ph·∫©m th·ª±c t·∫ø user ƒë√£ t∆∞∆°ng t√°c)")
                st.write("4. T√≠nh c√°c ch·ªâ s·ªë metrics d·ª±a tr√™n k·∫øt qu·∫£ so s√°nh")
                
                # Load parsed log data
                _, log_text = load_evaluation_log("Content-Based Filtering")
                parsed_log = parse_evaluation_log(log_text) if log_text else {}
                
                # Get metrics from comparison_df
                cb_metrics_row = None
                if comparison_df is not None:
                    cb_rows = comparison_df[comparison_df['model_name'] == 'Content-Based Filtering']
                    if len(cb_rows) > 0:
                        cb_metrics_row = cb_rows.iloc[0]
                
                # Hi·ªÉn th·ªã Training Time v√† Inference Time
                st.markdown("#### ‚è±Ô∏è Th·ªùi gian Training & Inference")
                col_time1, col_time2 = st.columns(2)
                with col_time1:
                    training_time = parsed_log['metrics'].get('training_time', 
                        cb_metrics_row['training_time'] if cb_metrics_row is not None else None)
                    if training_time is not None:
                        st.metric("Training Time (s)", f"{training_time:.4f}")
                with col_time2:
                    inference_time = parsed_log['metrics'].get('avg_inference_time',
                        cb_metrics_row['avg_inference_time'] if cb_metrics_row is not None else None)
                    if inference_time is not None:
                        st.metric("Inference Time (s)", f"{inference_time:.4f}")
                
                # Hi·ªÉn th·ªã metrics @10
                st.markdown("#### üìà Metrics @10")
                metrics_10 = ['recall@10', 'precision@10', 'ndcg@10', 'coverage@10', 'diversity@10']
                if cb_metrics_row is not None:
                    render_metrics_in_step(cb_metrics_row, metrics_10, "B∆∞·ªõc 4", "cb_10", model_name="Content-Based Filtering")
                elif parsed_log:
                    render_metrics_in_step(parsed_log, metrics_10, "B∆∞·ªõc 4", "cb_10", model_name="Content-Based Filtering")
                
                # Hi·ªÉn th·ªã metrics @20
                st.markdown("#### üìà Metrics @20")
                metrics_20 = ['recall@20', 'precision@20', 'ndcg@20', 'coverage@20', 'diversity@20']
                if cb_metrics_row is not None:
                    render_metrics_in_step(cb_metrics_row, metrics_20, "B∆∞·ªõc 4", "cb_20", model_name="Content-Based Filtering")
                elif parsed_log:
                    render_metrics_in_step(parsed_log, metrics_20, "B∆∞·ªõc 4", "cb_20", model_name="Content-Based Filtering")
                
                st.markdown("#### üìä B·∫£ng T·ªïng H·ª£p")
                render_metrics_table(comparison_df, highlight_model="Content-Based Filtering")
                render_evaluation_log_section("Content-Based Filtering", "cb")

        # --- GNN TAB ---
        with tab2:
            st.markdown("### 2Ô∏è‚É£ GNN (GraphSAGE)")
            st.markdown("**M√¥ t·∫£:** S·ª≠ d·ª•ng m·∫°ng n∆°-ron ƒë·ªì th·ªã ƒë·ªÉ h·ªçc m·ªëi quan h·ªá gi·ªØa User v√† Product.")
            
            # B∆Ø·ªöC 1
            with st.expander("B∆∞·ªõc 1: Graph Construction & D·ªØ li·ªáu Train", expanded=True):
                st.markdown('<div class="step-header">B∆∞·ªõc 1: X√¢y d·ª±ng ƒë·ªì th·ªã & D·ªØ li·ªáu</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung th·ª±c hi·ªán:** X√¢y d·ª±ng ƒë·ªì th·ªã l∆∞·ª°ng ph√¢n (Bipartite Graph) t·ª´ interactions gi·ªØa users v√† products.")
                
                # Th√¥ng tin d·ªØ li·ªáu
                st.write("**D·ªØ li·ªáu Train-set:** S·ª≠ d·ª•ng `train_interactions` (80% d·ªØ li·ªáu ƒë·∫ßu, t√°ch theo th·ªùi gian).")
                col_data1, col_data2 = st.columns(2)
                with col_data1:
                    st.metric("Train interactions", len(preprocessor.train_interactions))
                    st.metric("S·ªë l∆∞·ª£ng Users (Nodes)", gnn_model.n_users)
                    st.metric("S·ªë l∆∞·ª£ng Products (Nodes)", gnn_model.n_products)
                with col_data2:
                    if gnn_model.graph_data:
                        st.metric("S·ªë l∆∞·ª£ng C·∫°nh (Edges)", gnn_model.graph_data.edge_index.shape[1])
                        st.metric("Feature Dimension", gnn_model.graph_data.x.shape[1])
                        st.metric("T·ªïng s·ªë Nodes", gnn_model.graph_data.x.shape[0])
                
                st.write("**C·∫•u tr√∫c ƒë·ªì th·ªã:**")
                st.write("- **Lo·∫°i:** Bipartite Graph (ƒë·ªì th·ªã l∆∞·ª°ng ph√¢n)")
                st.write("- **Nodes:** Users + Products")
                st.write("- **Edges:** T∆∞∆°ng t√°c gi·ªØa User v√† Product (purchase, cart, like)")
                st.write("- **Edge Weights:** ƒê·ªô m·∫°nh c·ªßa t∆∞∆°ng t√°c (1.0 cho purchase, 0.7 cho cart, 0.5 cho like)")
                
                st.write("**Ma tr·∫≠n k·ªÅ (Adjacency - Minh h·ªça):**")
                st.code("""
User 1 <---[weight=1.0]---> Product A
User 2 <---[weight=0.7]---> Product A
User 1 <---[weight=0.5]---> Product B
                """)
                
                if gnn_model.graph_data:
                    # T√≠nh to√°n m·ªôt s·ªë th·ªëng k√™
                    n_edges = gnn_model.graph_data.edge_index.shape[1]
                    n_nodes = gnn_model.graph_data.x.shape[0]
                    avg_degree = (n_edges * 2) / n_nodes if n_nodes > 0 else 0
                    st.write(f"**Th·ªëng k√™ ƒë·ªì th·ªã:**")
                    st.write(f"- S·ªë c·∫°nh trung b√¨nh m·ªói node: {avg_degree:.2f}")
                    st.write(f"- M·∫≠t ƒë·ªô ƒë·ªì th·ªã: {(n_edges / (n_nodes * (n_nodes - 1))) * 100:.4f}%")
                
                st.info("üí° **Ph√¢n t√≠ch:** ƒê·ªì th·ªã l√† Bipartite (L∆∞·ª°ng ph√¢n), c·∫°nh n·ªëi gi·ªØa User v√† Product th·ªÉ hi·ªán t∆∞∆°ng t√°c. GraphSAGE s·∫Ω h·ªçc embedding cho m·ªói node d·ª±a tr√™n th√¥ng tin t·ª´ c√°c h√†ng x√≥m (neighbors).")

            # B∆Ø·ªöC 2
            with st.expander("B∆∞·ªõc 2: Graph Convolution (GraphSAGE)"):
                st.markdown('<div class="step-header">B∆∞·ªõc 2: T√≠ch ch·∫≠p ƒë·ªì th·ªã (Graph Convolution)</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung:** Lan truy·ªÅn th√¥ng tin t·ª´ h√†ng x√≥m (Neighbors) ƒë·ªÉ c·∫≠p nh·∫≠t Embedding cho m·ªói node.")
                st.write(f"**D·ªØ li·ªáu s·ª≠ d·ª•ng:** ƒê·ªì th·ªã t·ª´ B∆∞·ªõc 1 v·ªõi {gnn_model.graph_data.x.shape[0]} nodes v√† {gnn_model.graph_data.edge_index.shape[1]} edges.")
                
                st.markdown("""
                **C√¥ng th·ª©c GraphSAGE (Mean Aggregator):**
                
                **B∆∞·ªõc 1 - Aggregate (T·ªïng h·ª£p th√¥ng tin t·ª´ neighbors):**
                $$h_{N(v)}^{(k)} = \\frac{1}{|N(v)|} \\sum_{u \\in N(v)} h_u^{(k-1)}$$
                
                **B∆∞·ªõc 2 - Update (C·∫≠p nh·∫≠t embedding):**
                $$h_v^{(k)} = \\sigma\\left(W^{(k)} \\cdot \\text{CONCAT}(h_v^{(k-1)}, h_{N(v)}^{(k)})\\right)$$
                
                Trong ƒë√≥:
                - $h_v^{(k)}$: Embedding c·ªßa node $v$ ·ªü layer $k$
                - $N(v)$: T·∫≠p neighbors c·ªßa node $v$
                - $W^{(k)}$: Ma tr·∫≠n tr·ªçng s·ªë ·ªü layer $k$
                - $\\sigma$: H√†m activation (ReLU)
                - $\\text{CONCAT}$: N·ªëi vector hi·ªán t·∫°i v·ªõi vector t·ªïng h·ª£p t·ª´ neighbors
                """)
                
                st.write("**V√≠ d·ª• √°p d·ª•ng:**")
                st.write("1. User A c√≥ neighbors: Product X, Product Y, Product Z")
                st.write("2. Aggregate: L·∫•y trung b√¨nh embeddings c·ªßa X, Y, Z")
                st.write("3. Update: N·ªëi embedding hi·ªán t·∫°i c·ªßa User A v·ªõi vector t·ªïng h·ª£p, sau ƒë√≥ nh√¢n v·ªõi ma tr·∫≠n tr·ªçng s·ªë v√† √°p d·ª•ng ReLU")
                st.write("4. K·∫øt qu·∫£: Embedding m·ªõi c·ªßa User A ph·∫£n √°nh s·ªü th√≠ch d·ª±a tr√™n c√°c s·∫£n ph·∫©m ƒë√£ t∆∞∆°ng t√°c")
                
                st.write("**K·∫øt qu·∫£ t√≠nh to√°n (Embeddings):**")
                if gnn_model.node_embeddings is not None:
                    emb_df = pd.DataFrame(gnn_model.node_embeddings[:5, :10]) # 5 users, 10 dims
                    st.write(f"**User Embeddings (Top 5 users, 10 chi·ªÅu ƒë·∫ßu):** Shape {gnn_model.node_embeddings.shape}")
                    st.write(f"- T·ªïng s·ªë embeddings: {gnn_model.node_embeddings.shape[0]} (Users + Products)")
                    st.write(f"- Dimension m·ªói embedding: {gnn_model.node_embeddings.shape[1]}")
                    st.dataframe(emb_df.style.background_gradient(cmap='Purples', axis=None), use_container_width=True)
                    
                    # Th·ªëng k√™
                    avg_emb = gnn_model.node_embeddings.mean()
                    std_emb = gnn_model.node_embeddings.std()
                    st.write(f"**Th·ªëng k√™ embeddings:**")
                    st.write(f"- Gi√° tr·ªã trung b√¨nh: {avg_emb:.4f}")
                    st.write(f"- ƒê·ªô l·ªách chu·∫©n: {std_emb:.4f}")
                    
                    st.info("üí° **√ù nghƒ©a:** M·ªói d√≤ng l√† m·ªôt vector ƒë·∫°i di·ªán cho s·ªü th√≠ch c·ªßa User (ho·∫∑c ƒë·∫∑c tr∆∞ng c·ªßa Product) sau khi h·ªçc t·ª´ ƒë·ªì th·ªã. C√°c users c√≥ s·ªü th√≠ch t∆∞∆°ng t·ª± s·∫Ω c√≥ embeddings g·∫ßn nhau trong kh√¥ng gian vector.")

            # B∆Ø·ªöC 3
            with st.expander("B∆∞·ªõc 3: Training & Loss Function"):
                st.markdown('<div class="step-header">B∆∞·ªõc 3: Hu·∫•n luy·ªán v·ªõi BPR Loss</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung:** T·ªëi ∆∞u h√≥a embedding sao cho ƒëi·ªÉm c·ªßa c·∫∑p (User, Item d∆∞∆°ng) l·ªõn h∆°n (User, Item √¢m).")
                st.write(f"**D·ªØ li·ªáu s·ª≠ d·ª•ng:** Train-set v·ªõi {len(preprocessor.train_interactions)} interactions.")
                
                st.markdown("""
                **C√¥ng th·ª©c BPR Loss (Bayesian Personalized Ranking):**
                $$L = -\\frac{1}{|D|} \\sum_{(u,i,j) \\in D} w_{ui} \\cdot \\ln \\sigma(\\hat{x}_{ui} - \\hat{x}_{uj})$$
                
                Trong ƒë√≥:
                - $D$: T·∫≠p c√°c triplets $(u, i, j)$
                - $u$: User
                - $i$: Item d∆∞∆°ng (user ƒë√£ t∆∞∆°ng t√°c)
                - $j$: Item √¢m (user ch∆∞a t∆∞∆°ng t√°c, negative sample)
                - $w_{ui}$: Tr·ªçng s·ªë c·ªßa interaction (1.0 cho purchase, 0.7 cho cart, 0.5 cho like)
                - $\\hat{x}_{ui} = h_u \\cdot h_i$: ƒêi·ªÉm d·ª± ƒëo√°n (dot product c·ªßa embeddings)
                - $\\sigma$: Sigmoid function
                
                **√ù nghƒ©a:** Loss c√†ng nh·ªè nghƒ©a l√† model c√†ng ph√¢n bi·ªát t·ªët gi·ªØa items user th√≠ch v√† kh√¥ng th√≠ch. Weighted loss gi√∫p model coi tr·ªçng c√°c t∆∞∆°ng t√°c m·∫°nh h∆°n (purchase > cart > like).
                """)
                
                st.write("**V√≠ d·ª• √°p d·ª•ng:**")
                st.write("1. User A ƒë√£ mua Product X (positive)")
                st.write("2. Random ch·ªçn Product Y m√† User A ch∆∞a mua (negative)")
                st.write("3. T√≠nh: $score_{AX} = embedding_A \\cdot embedding_X$")
                st.write("4. T√≠nh: $score_{AY} = embedding_A \\cdot embedding_Y$")
                st.write("5. Loss = $-\\ln(\\sigma(score_{AX} - score_{AY}))$")
                st.write("6. M·ª•c ti√™u: $score_{AX} > score_{AY}$ (User A th√≠ch X h∆°n Y)")
                
                if gnn_model.training_losses:
                    st.write(f"**K·∫øt qu·∫£ training:**")
                    st.write(f"- Training Loss cu·ªëi c√πng: {gnn_model.training_losses[-1]:.4f}")
                    st.write(f"- Training Loss ban ƒë·∫ßu: {gnn_model.training_losses[0]:.4f}")
                    st.write(f"- C·∫£i thi·ªán: {((gnn_model.training_losses[0] - gnn_model.training_losses[-1]) / gnn_model.training_losses[0] * 100):.2f}%")
                    st.write(f"- Th·ªùi gian hu·∫•n luy·ªán: {gnn_model.training_time:.2f}s")
                    st.write(f"- S·ªë epochs: {len(gnn_model.training_losses)}")
                    
                    # V·∫Ω bi·ªÉu ƒë·ªì loss n·∫øu c√≥
                    if len(gnn_model.training_losses) > 1:
                        loss_df = pd.DataFrame({
                            'Epoch': range(1, len(gnn_model.training_losses) + 1),
                            'Loss': gnn_model.training_losses
                        })
                        fig = px.line(loss_df, x='Epoch', y='Loss', title='Training Loss Over Time')
                        st.plotly_chart(fig, use_container_width=True)

            # B∆Ø·ªöC 4
            with st.expander("B∆∞·ªõc 4: Evaluation (T√≠nh to√°n ch·ªâ s·ªë)", expanded=True):
                st.markdown('<div class="step-header">B∆∞·ªõc 4: ƒê√°nh gi√° & T√≠nh Metrics</div>', unsafe_allow_html=True)
                
                # Th√¥ng tin d·ªØ li·ªáu
                st.write("**D·ªØ li·ªáu s·ª≠ d·ª•ng:**")
                col_eval1, col_eval2 = st.columns(2)
                with col_eval1:
                    st.metric("Train-set", f"{len(preprocessor.train_interactions)} interactions")
                    st.write(f"- Users: {preprocessor.train_interactions['user_idx'].nunique()}")
                    st.write(f"- Products: {preprocessor.train_interactions['product_idx'].nunique()}")
                with col_eval2:
                    st.metric("Test-set", f"{len(preprocessor.test_interactions)} interactions")
                    st.write(f"- Users: {preprocessor.test_interactions['user_idx'].nunique()}")
                    st.write(f"- Products: {preprocessor.test_interactions['product_idx'].nunique()}")
                
                st.write("**Ph∆∞∆°ng ph√°p d·ª± ƒëo√°n:**")
                st.markdown("""
                **C√¥ng th·ª©c t√≠nh ƒëi·ªÉm:**
                $$\\hat{x}_{ui} = h_u \\cdot h_i$$
                
                Trong ƒë√≥:
                - $h_u$: User embedding (t·ª´ node_embeddings)
                - $h_i$: Product embedding (t·ª´ node_embeddings)
                - $\\hat{x}_{ui}$: ƒêi·ªÉm d·ª± ƒëo√°n user $u$ s·∫Ω th√≠ch product $i$
                
                **Quy tr√¨nh:**
                1. V·ªõi m·ªói user trong test-set, t√≠nh ƒëi·ªÉm v·ªõi t·∫•t c·∫£ products
                2. S·∫Øp x·∫øp products theo ƒëi·ªÉm gi·∫£m d·∫ßn
                3. L·∫•y Top-K products l√†m recommendations
                4. So s√°nh v·ªõi ground truth (products user th·ª±c t·∫ø ƒë√£ t∆∞∆°ng t√°c)
                5. T√≠nh c√°c metrics: Recall, Precision, NDCG, Coverage, Diversity
                """)
                
                # Load parsed log data
                _, log_text = load_evaluation_log("GNN (GraphSAGE)")
                parsed_log = parse_evaluation_log(log_text) if log_text else {}
                
                # Get metrics from comparison_df
                gnn_metrics_row = None
                if comparison_df is not None:
                    gnn_rows = comparison_df[comparison_df['model_name'] == 'GNN (GraphSAGE)']
                    if len(gnn_rows) > 0:
                        gnn_metrics_row = gnn_rows.iloc[0]
                
                # Hi·ªÉn th·ªã Training Time v√† Inference Time
                st.markdown("#### ‚è±Ô∏è Th·ªùi gian Training & Inference")
                col_time1, col_time2 = st.columns(2)
                with col_time1:
                    training_time = parsed_log['metrics'].get('training_time',
                        gnn_metrics_row['training_time'] if gnn_metrics_row is not None else None)
                    if training_time is not None:
                        st.metric("Training Time (s)", f"{training_time:.4f}")
                with col_time2:
                    inference_time = parsed_log['metrics'].get('avg_inference_time',
                        gnn_metrics_row['avg_inference_time'] if gnn_metrics_row is not None else None)
                    if inference_time is not None:
                        st.metric("Inference Time (s)", f"{inference_time:.4f}")
                
                # Hi·ªÉn th·ªã metrics @10
                st.markdown("#### üìà Metrics @10")
                metrics_10 = ['recall@10', 'precision@10', 'ndcg@10', 'coverage@10', 'diversity@10']
                if gnn_metrics_row is not None:
                    render_metrics_in_step(gnn_metrics_row, metrics_10, "B∆∞·ªõc 4", "gnn_10", model_name="GNN (GraphSAGE)")
                elif parsed_log:
                    render_metrics_in_step(parsed_log, metrics_10, "B∆∞·ªõc 4", "gnn_10", model_name="GNN (GraphSAGE)")
                
                # Hi·ªÉn th·ªã metrics @20
                st.markdown("#### üìà Metrics @20")
                metrics_20 = ['recall@20', 'precision@20', 'ndcg@20', 'coverage@20', 'diversity@20']
                if gnn_metrics_row is not None:
                    render_metrics_in_step(gnn_metrics_row, metrics_20, "B∆∞·ªõc 4", "gnn_20", model_name="GNN (GraphSAGE)")
                elif parsed_log:
                    render_metrics_in_step(parsed_log, metrics_20, "B∆∞·ªõc 4", "gnn_20", model_name="GNN (GraphSAGE)")
                
                st.markdown("#### üìê C√¥ng th·ª©c t√≠nh c√°c ch·ªâ s·ªë (t∆∞∆°ng t·ª± Content-Based):")
                
                # Recall@K
                with st.expander("Recall@K", expanded=False):
                    st.markdown("""
                    $$Recall@K = \\frac{1}{|U|} \\sum_{u \\in U} \\frac{|R_u \\cap T_u|}{|T_u|}$$
                    """)
                
                # Precision@K
                with st.expander("Precision@K", expanded=False):
                    st.markdown("""
                    $$Precision@K = \\frac{1}{|U|} \\sum_{u \\in U} \\frac{|R_u \\cap T_u|}{K}$$
                    """)
                
                # NDCG@K
                with st.expander("NDCG@K", expanded=False):
                    st.markdown("""
                    $$NDCG@K = \\frac{DCG@K}{IDCG@K}, \\quad DCG@K = \\sum_{i=1}^{K} \\frac{rel_i}{\\log_2(i+1)}$$
                    """)
                
                # Coverage@K
                with st.expander("Coverage@K", expanded=False):
                    st.markdown("""
                    $$Coverage@K = \\frac{|\\bigcup_{u \\in U} R_u|}{|P|}$$
                    """)
                
                # Diversity@K
                with st.expander("Diversity@K", expanded=False):
                    st.markdown("""
                    $$Diversity@K = \\frac{1}{|U|} \\sum_{u \\in U} \\frac{|\\text{unique categories in } R_u|}{K}$$
                    """)
                
                st.markdown("#### üìä B·∫£ng T·ªïng H·ª£p")
                render_metrics_table(comparison_df, highlight_model="GNN (GraphSAGE)")
                render_evaluation_log_section("GNN (GraphSAGE)", "gnn")
        # --- HYBRID TAB ---
        with tab3:
            st.markdown("### 3Ô∏è‚É£ Hybrid Model (GNN + Content-Based)")
            st.markdown("**M√¥ t·∫£:** K·∫øt h·ª£p ƒëi·ªÉm s·ªë t·ª´ GNN v√† Content-Based ƒë·ªÉ t·∫≠n d·ª•ng ∆∞u ƒëi·ªÉm c·∫£ hai.")
            
            # B∆Ø·ªöC 1
            with st.expander("B∆∞·ªõc 1: Score Normalization (Chu·∫©n h√≥a)", expanded=True):
                st.markdown('<div class="step-header">B∆∞·ªõc 1: Chu·∫©n h√≥a ƒëi·ªÉm s·ªë</div>', unsafe_allow_html=True)
                st.write("**N·ªôi dung:** ƒê∆∞a ƒëi·ªÉm s·ªë c·ªßa GNN (th∆∞·ªùng l√† dot product, range r·ªông) v√† CB (cosine, 0-1) v·ªÅ c√πng thang ƒëo [0, 1].")
                st.write("**D·ªØ li·ªáu s·ª≠ d·ª•ng:** Scores t·ª´ GNN model v√† Content-Based model cho c√πng m·ªôt t·∫≠p candidates.")
                
                st.markdown("""
                **C√¥ng th·ª©c Min-Max Scaling:**
                $$Score_{norm} = \\frac{Score - \\min(Scores)}{\\max(Scores) - \\min(Scores)}$$
                
                Trong ƒë√≥:
                - $Score$: ƒêi·ªÉm s·ªë g·ªëc (t·ª´ GNN ho·∫∑c CB)
                - $\\min(Scores)$: ƒêi·ªÉm s·ªë th·∫•p nh·∫•t trong t·∫≠p
                - $\\max(Scores)$: ƒêi·ªÉm s·ªë cao nh·∫•t trong t·∫≠p
                - $Score_{norm}$: ƒêi·ªÉm s·ªë sau khi chu·∫©n h√≥a (0-1)
                
                **L√Ω do:** GNN v√† CB c√≥ thang ƒëi·ªÉm kh√°c nhau, c·∫ßn chu·∫©n h√≥a ƒë·ªÉ k·∫øt h·ª£p c√¥ng b·∫±ng.
                """)
                
                st.write("**V√≠ d·ª• minh h·ªça:**")
                ex_data = {
                    'Product': ['P1', 'P2', 'P3'],
                    'GNN Score (Raw)': [5.2, 2.1, 1.5],
                    'CB Score (Raw)': [0.8, 0.3, 0.2],
                    'GNN Norm': [1.0, 0.16, 0.0],
                    'CB Norm': [1.0, 0.17, 0.0]
                }
                ex_df = pd.DataFrame(ex_data)
                st.dataframe(ex_df, use_container_width=True)
                
                st.write("**Gi·∫£i th√≠ch v√≠ d·ª•:**")
                st.write("- GNN: min=1.5, max=5.2 ‚Üí P1: (5.2-1.5)/(5.2-1.5)=1.0, P2: (2.1-1.5)/(5.2-1.5)=0.16")
                st.write("- CB: min=0.2, max=0.8 ‚Üí P1: (0.8-0.2)/(0.8-0.2)=1.0, P2: (0.3-0.2)/(0.8-0.2)=0.17")
                st.info("üí° **Ph√¢n t√≠ch:** Sau chu·∫©n h√≥a, c·∫£ hai models ƒë·ªÅu c√≥ thang ƒëi·ªÉm [0, 1], gi√∫p k·∫øt h·ª£p c√¥ng b·∫±ng h∆°n.")

            # B∆Ø·ªöC 2
            with st.expander("B∆∞·ªõc 2: Weighted Combination (K·∫øt h·ª£p)"):
                st.markdown('<div class="step-header">B∆∞·ªõc 2: K·∫øt h·ª£p c√≥ tr·ªçng s·ªë</div>', unsafe_allow_html=True)
                st.write(f"**N·ªôi dung:** T√≠nh ƒëi·ªÉm cu·ªëi c√πng b·∫±ng c√°ch k·∫øt h·ª£p c√≥ tr·ªçng s·ªë gi·ªØa GNN v√† Content-Based v·ªõi $\\alpha = {hybrid_model.alpha}$.")
                st.write("**D·ªØ li·ªáu s·ª≠ d·ª•ng:** Normalized scores t·ª´ B∆∞·ªõc 1.")
                
                st.markdown("""
                **C√¥ng th·ª©c Late Fusion:**
                $$Score_{final} = \\alpha \\times Score_{GNN\\_norm} + (1 - \\alpha) \\times Score_{CB\\_norm}$$
                
                Trong ƒë√≥:
                - $\\alpha$: Tr·ªçng s·ªë cho GNN (m·∫∑c ƒë·ªãnh 0.5 = c√¢n b·∫±ng khi kh·ªüi t·∫°o model)
                - $Score_{GNN\\_norm}$: ƒêi·ªÉm s·ªë ƒë√£ chu·∫©n h√≥a t·ª´ GNN (Min-Max scaling v·ªÅ [0, 1])
                - $Score_{CB\\_norm}$: ƒêi·ªÉm s·ªë ƒë√£ chu·∫©n h√≥a t·ª´ Content-Based (Min-Max scaling v·ªÅ [0, 1])
                - $Score_{final}$: ƒêi·ªÉm s·ªë cu·ªëi c√πng ƒë·ªÉ ranking
                
                **L∆∞u √Ω quan tr·ªçng:** 
                - Khi kh·ªüi t·∫°o, Hybrid model c√≥ th·ªÉ d√πng $\\alpha = 0.5$ (c√¢n b·∫±ng)
                - **Trong th·ª±c t·∫ø khi recommend**, model s·ª≠ d·ª•ng **dynamic weight** (GNN=0.8, CB=0.2) ƒë·ªÉ ∆∞u ti√™n GNN cao h∆°n v√¨ GNN th∆∞·ªùng cho k·∫øt qu·∫£ t·ªët h∆°n Content-Based
                - C√¥ng th·ª©c th·ª±c t·∫ø: $Score_{final} = 0.8 \\times Score_{GNN\\_norm} + 0.2 \\times Score_{CB\\_norm}$
                """)
                
                st.write("**V√≠ d·ª• √°p d·ª•ng (v·ªõi alpha=0.5):**")
                st.write("Gi·∫£ s·ª≠ c√≥ 3 s·∫£n ph·∫©m sau khi chu·∫©n h√≥a:")
                ex_combine = pd.DataFrame({
                    'Product': ['P1', 'P2', 'P3'],
                    'GNN Norm': [1.0, 0.5, 0.2],
                    'CB Norm': [0.8, 0.6, 0.4],
                    'Final Score (Œ±=0.5)': [0.9, 0.55, 0.3],
                    'Final Score (Œ±=0.8)': [0.96, 0.52, 0.24]
                })
                st.dataframe(ex_combine, use_container_width=True)
                
                st.write("**T√≠nh to√°n chi ti·∫øt cho P1 (Œ±=0.5):**")
                st.write("$$Score_{final}(P1) = 0.5 \\times 1.0 + 0.5 \\times 0.8 = 0.5 + 0.4 = 0.9$$")
                st.write("**T√≠nh to√°n chi ti·∫øt cho P1 (Œ±=0.8 - dynamic weight):**")
                st.write("$$Score_{final}(P1) = 0.8 \\times 1.0 + 0.2 \\times 0.8 = 0.8 + 0.16 = 0.96$$")
                
                st.info(f"üí° **Ph√¢n t√≠ch:** V·ªõi $\\alpha = {hybrid_model.alpha}$, model c√¢n b·∫±ng gi·ªØa GNN (h·ªçc t·ª´ t∆∞∆°ng t√°c) v√† CB (d·ª±a tr√™n ƒë·∫∑c tr∆∞ng). Dynamic weight (0.8/0.2) ∆∞u ti√™n GNN h∆°n v√¨ n√≥ th∆∞·ªùng t·ªët h∆°n CB.")

            # B∆Ø·ªöC 3
            with st.expander("B∆∞·ªõc 3: Evaluation & Analysis", expanded=True):
                st.markdown('<div class="step-header">B∆∞·ªõc 3: ƒê√°nh gi√° t·ªïng h·ª£p</div>', unsafe_allow_html=True)
                
                # Th√¥ng tin d·ªØ li·ªáu
                st.write("**D·ªØ li·ªáu s·ª≠ d·ª•ng:**")
                col_eval1, col_eval2 = st.columns(2)
                with col_eval1:
                    st.metric("Train-set", f"{len(preprocessor.train_interactions)} interactions")
                    st.write(f"- Users: {preprocessor.train_interactions['user_idx'].nunique()}")
                    st.write(f"- Products: {preprocessor.train_interactions['product_idx'].nunique()}")
                with col_eval2:
                    st.metric("Test-set", f"{len(preprocessor.test_interactions)} interactions")
                    st.write(f"- Users: {preprocessor.test_interactions['user_idx'].nunique()}")
                    st.write(f"- Products: {preprocessor.test_interactions['product_idx'].nunique()}")
                
                st.write("**Quy tr√¨nh ƒë√°nh gi√°:**")
                st.write("1. V·ªõi m·ªói user trong test-set, l·∫•y candidates t·ª´ c·∫£ GNN v√† Content-Based")
                st.write("2. Chu·∫©n h√≥a v√† k·∫øt h·ª£p scores theo c√¥ng th·ª©c ·ªü B∆∞·ªõc 2")
                st.write("3. S·∫Øp x·∫øp v√† l·∫•y Top-K recommendations")
                st.write("4. So s√°nh v·ªõi ground truth v√† t√≠nh c√°c metrics")
                
                # Load parsed log data
                _, log_text = load_evaluation_log("Hybrid (GNN + Content-Based)")
                parsed_log = parse_evaluation_log(log_text) if log_text else {}
                
                # Get metrics from comparison_df
                hybrid_metrics_row = None
                if comparison_df is not None:
                    hybrid_rows = comparison_df[comparison_df['model_name'] == 'Hybrid (GNN + Content-Based)']
                    if len(hybrid_rows) > 0:
                        hybrid_metrics_row = hybrid_rows.iloc[0]
                
                # Hi·ªÉn th·ªã Training Time v√† Inference Time
                st.markdown("#### ‚è±Ô∏è Th·ªùi gian Training & Inference")
                col_time1, col_time2 = st.columns(2)
                with col_time1:
                    training_time = parsed_log['metrics'].get('training_time',
                        hybrid_metrics_row['training_time'] if hybrid_metrics_row is not None else None)
                    if training_time is not None:
                        st.metric("Training Time (s)", f"{training_time:.4f}")
                with col_time2:
                    inference_time = parsed_log['metrics'].get('avg_inference_time',
                        hybrid_metrics_row['avg_inference_time'] if hybrid_metrics_row is not None else None)
                    if inference_time is not None:
                        st.metric("Inference Time (s)", f"{inference_time:.4f}")
                
                # Hi·ªÉn th·ªã metrics @10
                st.markdown("#### üìà Metrics @10")
                metrics_10 = ['recall@10', 'precision@10', 'ndcg@10', 'coverage@10', 'diversity@10']
                if hybrid_metrics_row is not None:
                    render_metrics_in_step(hybrid_metrics_row, metrics_10, "B∆∞·ªõc 3", "hybrid_10", model_name="Hybrid (GNN + Content-Based)")
                elif parsed_log:
                    render_metrics_in_step(parsed_log, metrics_10, "B∆∞·ªõc 3", "hybrid_10", model_name="Hybrid (GNN + Content-Based)")
                
                # Hi·ªÉn th·ªã metrics @20
                st.markdown("#### üìà Metrics @20")
                metrics_20 = ['recall@20', 'precision@20', 'ndcg@20', 'coverage@20', 'diversity@20']
                if hybrid_metrics_row is not None:
                    render_metrics_in_step(hybrid_metrics_row, metrics_20, "B∆∞·ªõc 3", "hybrid_20", model_name="Hybrid (GNN + Content-Based)")
                elif parsed_log:
                    render_metrics_in_step(parsed_log, metrics_20, "B∆∞·ªõc 3", "hybrid_20", model_name="Hybrid (GNN + Content-Based)")
                
                st.markdown("#### üìê C√¥ng th·ª©c t√≠nh c√°c ch·ªâ s·ªë (t∆∞∆°ng t·ª± c√°c models kh√°c):")
                
                # T√≥m t·∫Øt c√¥ng th·ª©c
                st.write("**Recall@K:** T·ª∑ l·ªá s·∫£n ph·∫©m relevant ƒë∆∞·ª£c t√¨m th·∫•y")
                st.write("**Precision@K:** T·ª∑ l·ªá s·∫£n ph·∫©m relevant trong Top-K")
                st.write("**NDCG@K:** Ch·∫•t l∆∞·ª£ng ranking (coi tr·ªçng v·ªã tr√≠)")
                st.write("**Coverage@K:** T·ª∑ l·ªá s·∫£n ph·∫©m trong catalog ƒë∆∞·ª£c g·ª£i √Ω")
                st.write("**Diversity@K:** ƒê·ªô ƒëa d·∫°ng c·ªßa danh s√°ch g·ª£i √Ω")
                
                st.markdown("#### üìä B·∫£ng T·ªïng H·ª£p")
                render_metrics_table(comparison_df, highlight_model="Hybrid (GNN + Content-Based)")
                render_evaluation_log_section("Hybrid (GNN + Content-Based)", "hybrid")
                st.markdown("### üèÜ Ph√¢n t√≠ch & K·∫øt lu·∫≠n (Focus on Hybrid)")
                st.success("""
                **T·∫°i sao Hybrid l√† t·ªëi ∆∞u nh·∫•t?**
                
                1. **Recall & Precision:** Hybrid ƒë·∫°t ƒë∆∞·ª£c s·ª± c√¢n b·∫±ng t·ªët h∆°n:
                   - GNN gi√∫p tƒÉng Recall (t√¨m ƒë∆∞·ª£c s·∫£n ph·∫©m ti·ªÅm nƒÉng user ch∆∞a t·ª´ng th·∫•y)
                   - CB gi√∫p tƒÉng Precision (ƒë·∫£m b·∫£o s·∫£n ph·∫©m gi·ªëng s·ªü th√≠ch c≈©)
                
                2. **Coverage & Diversity:** 
                   - Coverage c·ªßa Hybrid th∆∞·ªùng cao h∆°n GNN thu·∫ßn t√∫y v√¨ c√≥ th·ªÉ g·ª£i √Ω c·∫£ nh·ªØng s·∫£n ph·∫©m √≠t t∆∞∆°ng t√°c (nh·ªù Content-Based)
                   - Diversity t·ªët h∆°n CB thu·∫ßn t√∫y nh·ªù GNN ƒëa d·∫°ng h√≥a recommendations
                
                3. **Kh·∫Øc ph·ª•c ƒëi·ªÉm y·∫øu:** 
                   - GNN b·ªã y·∫øu khi User m·ªõi (Cold-start) ‚Üí CB b√π ƒë·∫Øp b·∫±ng c√°ch d·ª±a v√†o ƒë·∫∑c tr∆∞ng s·∫£n ph·∫©m
                   - CB b·ªã y·∫øu v·ªÅ ƒë·ªô ƒëa d·∫°ng v√† kh√°m ph√° ‚Üí GNN b√π ƒë·∫Øp b·∫±ng c√°ch h·ªçc t·ª´ t∆∞∆°ng t√°c c·ªßa users kh√°c
                
                4. **Robustness:** Hybrid √≠t b·ªã ·∫£nh h∆∞·ªüng b·ªüi d·ªØ li·ªáu thi·∫øu ho·∫∑c kh√¥ng c√¢n b·∫±ng h∆°n c√°c model ƒë∆°n l·∫ª
                """)

    # ========== PAGE 2: MODEL COMPARISON ==========
    elif page == "üìä Model Comparison":
        st.markdown('<div class="sub-header">üìä So S√°nh Hi·ªáu Su·∫•t C√°c M√¥ H√¨nh</div>', unsafe_allow_html=True)
        
        if comparison_df is not None:
            st.dataframe(comparison_df, use_container_width=True)
            
            # Radar Chart
            metrics = ['recall@10', 'ndcg@10', 'precision@10', 'coverage@10', 'diversity@10']
            fig = go.Figure()
            for _, row in comparison_df.iterrows():
                fig.add_trace(go.Scatterpolar(
                    r=[row[m] for m in metrics],
                    theta=metrics,
                    fill='toself',
                    name=row['model_name']
                ))
            fig.update_layout(polar=dict(radialaxis=dict(visible=True)), title="Radar Chart: C√°c ch·ªâ s·ªë ch√≠nh")
            st.plotly_chart(fig, use_container_width=True)
            
            # Analysis Text
            st.markdown("### ƒê√°nh gi√° chi ti·∫øt")
            best_model = comparison_df.loc[comparison_df['ndcg@10'].idxmax()]['model_name']
            st.info(f"D·ª±a tr√™n ch·ªâ s·ªë quan tr·ªçng **NDCG@10**, m√¥ h√¨nh t·ªët nh·∫•t l√†: **{best_model}**")
            
        else:
            st.warning("Vui l√≤ng ch·∫°y t√≠nh to√°n ·ªü trang 'Algorithms & Steps' tr∆∞·ªõc.")

    # ========== PAGE 3: PERSONALIZED RECOMMENDATIONS ==========
    elif page == "üéØ Personalized Recommendations":
        st.markdown('<div class="sub-header">üéØ G·ª£i √ù C√° Nh√¢n H√≥a (Personalized)</div>', unsafe_allow_html=True)
        
        if preprocessor is None:
            st.warning("Vui l√≤ng ch·∫°y t√≠nh to√°n tr∆∞·ªõc.")
            st.stop()

        col1, col2 = st.columns(2)
        with col1:
            user_list = preprocessor.users_df[['user_idx', 'name', 'age', 'gender']].to_dict('records')
            user_options = {f"{u['name']} ({u['age']}, {u['gender']})": u['user_idx'] for u in user_list}
            selected_user = st.selectbox("Ch·ªçn User", list(user_options.keys()))
            user_idx = user_options[selected_user]
        
        with col2:
            product_list = preprocessor.products_df[['product_idx', 'productDisplayName']].to_dict('records')
            product_options = {p['productDisplayName']: p['product_idx'] for p in product_list}
            selected_product = st.selectbox("Ch·ªçn Payload Product", list(product_options.keys()))
            product_idx = product_options[selected_product]
            
        model_choice = st.radio("Ch·ªçn Model", ["Content-Based Filtering", "GNN (GraphSAGE)", "Hybrid"], horizontal=True)
        
        if st.button("üöÄ G·ª£i √Ω ngay", type="primary"):
            user_info = preprocessor.get_user_info(user_idx)
            user_history = preprocessor.get_user_interaction_history(user_idx)
            
            st.write("---")
            st.markdown("#### üë§ Th√¥ng tin User & Payload")
            c1, c2 = st.columns(2)
            with c1:
                st.write(f"**User:** {user_info['name']}, {user_info['age']} tu·ªïi, {user_info['gender']}")
                st.write(f"**L·ªãch s·ª≠:** {len(user_history)} t∆∞∆°ng t√°c")
            with c2:
                payload_info = preprocessor.get_product_info(product_idx)
                display_product_info(payload_info)
            
            st.write("---")
            st.markdown(f"#### üéØ K·∫øt qu·∫£ t·ª´ {model_choice}")
            
            with st.spinner("ƒêang t√≠nh to√°n..."):
                if model_choice == "Content-Based Filtering":
                    recs, _ = cb_model.recommend_personalized(user_info, user_history, product_idx)
                elif model_choice == "GNN (GraphSAGE)":
                    recs, _ = gnn_model.recommend_personalized(user_info, user_idx, product_idx)
                else:
                    recs, _ = hybrid_model.recommend_personalized(user_info, user_idx, user_history, product_idx)
            
            for i, (pid, score) in enumerate(recs, 1):
                with st.expander(f"#{i} - Score: {score:.4f}"):
                    display_product_info(preprocessor.get_product_info(pid), score)

    # ========== PAGE 4: OUTFIT RECOMMENDATIONS ==========
    elif page == "üëó Outfit Recommendations":
        st.markdown('<div class="sub-header">üëó G·ª£i √ù Trang Ph·ª•c (Outfit)</div>', unsafe_allow_html=True)
        
        if preprocessor is None:
            st.stop()

        # User & Product Selection (Simplified for brevity)
        user_list = preprocessor.users_df[['user_idx', 'name']].to_dict('records')
        user_idx = st.selectbox("Ch·ªçn User", [u['user_idx'] for u in user_list], format_func=lambda x: preprocessor.get_user_info(x)['name'])
        
        product_list = preprocessor.products_df[['product_idx', 'productDisplayName']].to_dict('records')
        product_idx = st.selectbox("Ch·ªçn Payload Product", [p['product_idx'] for p in product_list], format_func=lambda x: preprocessor.get_product_info(x)['productDisplayName'])

        if st.button("‚ú® T·∫°o Outfit", type="primary"):
            user_info = preprocessor.get_user_info(user_idx)
            outfit, _ = cb_model.recommend_outfit(user_info, product_idx)
            
            st.success("ƒê√£ t·∫°o outfit ho√†n ch·ªânh!")
            
            cols = st.columns(3)
            categories = [
                ('Topwear', outfit['topwear']), 
                ('Bottomwear', outfit['bottomwear']), 
                ('Footwear', outfit['footwear']),
                ('Accessories', outfit['accessories']),
                ('Dress (Optional)', outfit['dress']),
                ('Innerwear (Optional)', outfit.get('innerwear', []))
            ]
            
            for idx, (cat_name, items) in enumerate(categories):
                with cols[idx % 3]:
                    st.markdown(f"#### {cat_name}")
                    if items:
                        for pid, score in items[:2]:
                            p_info = preprocessor.get_product_info(pid)
                            st.info(f"{p_info['productDisplayName']}")
                    else:
                        st.write("_Kh√¥ng c√≥ g·ª£i √Ω_")

if __name__ == "__main__":
    main()
