"""
Streamlit App for Product Recommendation System
Implements 3 models: LightGCN, Content-based Filtering, Hybrid
"""

import sys
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

import ast
import math
import os
import re
import subprocess
import json
import time
from collections import defaultdict
from typing import Dict, List, Tuple
from datetime import datetime
from bson import ObjectId

import numpy as np
import pandas as pd
import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns

# Import data loader
from apps.recommendations.streamlit_utils.data_loader import (
    load_users_csv,
    load_products_csv,
    load_interactions_csv,
    prepare_data_for_models,
    filter_products_by_gender_age
)

st.set_page_config(
    page_title="H·ªá th·ªëng G·ª£i √Ω S·∫£n ph·∫©m",
    page_icon="üõçÔ∏è",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #1f77b4;
        margin: 10px 0;
    }
    .formula-box {
        background-color: #fff;
        padding: 15px;
        border-radius: 5px;
        border: 2px solid #1f77b4;
        margin: 10px 0;
        font-family: 'Courier New', monospace;
    }
    .step-box {
        background-color: #e8f4f8;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        border-left: 4px solid #ff6b6b;
    }
</style>
""", unsafe_allow_html=True)


# ==================== DATA LOADING ====================

@st.cache_data
def load_all_data():
    """Load all CSV files."""
    exports_dir = Path("exports")
    
    users_df = load_users_csv(exports_dir / "users.csv")
    products_df = load_products_csv(exports_dir / "products.csv")
    interactions_df = load_interactions_csv(exports_dir / "interactions.csv")
    
    user_dict, product_dict, interactions_df = prepare_data_for_models(
        users_df, products_df, interactions_df
    )
    
    return user_dict, product_dict, interactions_df, users_df, products_df


# ==================== LIGHTGCN MODEL ====================

class LightGCNLayer(nn.Module):
    """LightGCN Graph Convolutional Layer."""
    
    def __init__(self):
        super(LightGCNLayer, self).__init__()
    
    def forward(self, embeddings, edge_index):
        """LightGCN propagation: e^(l+1) = sum(e^l / sqrt(deg(u)) / sqrt(deg(v)))"""
        if edge_index.numel() == 0:
            return embeddings
        
        # Get degrees
        num_nodes = embeddings.size(0)
        row, col = edge_index
        
        # Calculate degrees
        deg = torch.zeros(num_nodes, device=embeddings.device)
        if row.numel() > 0:
            deg.scatter_add_(0, row, torch.ones_like(row, dtype=torch.float))
        deg = torch.clamp(deg, min=1.0)
        
        # Normalize: 1 / sqrt(deg(u) * deg(v))
        deg_inv_sqrt = deg.pow(-0.5)
        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]
        
        # Aggregate neighbors
        out = torch.zeros_like(embeddings)
        if row.numel() > 0:
            out.scatter_add_(0, col.unsqueeze(-1).expand(-1, embeddings.size(1)), 
                            embeddings[row] * norm.unsqueeze(-1))
        else:
            out = embeddings
        
        return out


class LightGCNModel(nn.Module):
    """LightGCN Model for Recommendation."""
    
    def __init__(self, num_users, num_products, embedding_dim=64, num_layers=3):
        super(LightGCNModel, self).__init__()
        self.num_users = num_users
        self.num_products = num_products
        self.embedding_dim = embedding_dim
        self.num_layers = num_layers
        
        # Embeddings
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.product_embedding = nn.Embedding(num_products, embedding_dim)
        
        # Initialize embeddings
        nn.init.normal_(self.user_embedding.weight, std=0.1)
        nn.init.normal_(self.product_embedding.weight, std=0.1)
        
        # LightGCN layers
        self.layers = nn.ModuleList([LightGCNLayer() for _ in range(num_layers)])
    
    def forward(self, edge_index):
        """Forward pass through LightGCN."""
        # Get initial embeddings
        user_emb = self.user_embedding.weight
        product_emb = self.product_embedding.weight
        all_emb = torch.cat([user_emb, product_emb], dim=0)
        
        # LightGCN propagation: average embeddings from all layers
        emb_list = [all_emb]
        for layer_idx, layer in enumerate(self.layers):
            all_emb = layer(all_emb, edge_index)
            emb_list.append(all_emb)
        
        # Average all layer embeddings
        final_emb = torch.mean(torch.stack(emb_list), dim=0)
        
        # Split back to users and products
        user_final = final_emb[:self.num_users]
        product_final = final_emb[self.num_users:]
        
        return user_final, product_final
    
    def predict(self, user_idx, product_idx):
        """Predict rating: r_hat = e_u^T * e_i"""
        user_emb = self.user_embedding.weight[user_idx]
        product_emb = self.product_embedding.weight[product_idx]
        return torch.sum(user_emb * product_emb, dim=-1)


class LightGCNRecommender:
    """LightGCN Recommendation System."""
    
    # Interaction type weights (kh√¥ng d√πng rating)
    INTERACTION_WEIGHTS = {
        'view': 1.0,
        'like': 2.0,
        'cart': 3.0,
        'purchase': 4.0,
        'review': 2.5  # Review c√≥ th·ªÉ c√≥ rating nh∆∞ng ch√∫ng ta ch·ªâ d√πng interaction type
    }
    
    def __init__(self):
        self.model = None
        self.user_id_map = {}
        self.product_id_map = {}
        self.reverse_user_map = {}
        self.reverse_product_map = {}
        self.edge_index = None
        self.training_time = 0.0
        self.computation_steps = []  # L∆∞u c√°c b∆∞·ªõc t√≠nh to√°n
        self.matrices = {}  # L∆∞u c√°c ma tr·∫≠n ƒë·ªÉ hi·ªÉn th·ªã
    
    def build_graph(self, interactions_df: pd.DataFrame):
        """Build bipartite graph from interactions with interaction type weights."""
        # Create mappings - ensure all IDs are strings for consistency
        unique_users = [str(uid) for uid in interactions_df['user_id'].unique()]
        unique_products = [str(pid) for pid in interactions_df['product_id'].unique()]
        
        self.user_id_map = {str(uid): idx for idx, uid in enumerate(unique_users)}
        self.product_id_map = {str(pid): idx for idx, pid in enumerate(unique_products)}
        self.reverse_user_map = {v: k for k, v in self.user_id_map.items()}
        self.reverse_product_map = {v: k for k, v in self.product_id_map.items()}
        
        # Build edge list with weights based on interaction types
        edges = []
        edge_weights = []  # Store weights for visualization
        
        for _, row in interactions_df.iterrows():
            user_id = str(row['user_id'])
            product_id = str(row['product_id'])
            user_idx = self.user_id_map[user_id]
            product_idx = self.product_id_map[product_id] + len(self.user_id_map)
            
            # Get interaction type weight (kh√¥ng d√πng rating)
            interaction_type = str(row.get('interaction_type', 'view')).lower()
            weight = self.INTERACTION_WEIGHTS.get(interaction_type, 1.0)
            
            edges.append([user_idx, product_idx])
            edges.append([product_idx, user_idx])  # Undirected graph
            edge_weights.extend([weight, weight])
        
        # Store edge weights for later use
        self.edge_weights = edge_weights if edge_weights else None
        
        # Convert to tensor
        if edges:
            edges_tensor = torch.tensor(edges, dtype=torch.long)
            if edges_tensor.numel() > 0:
                self.edge_index = edges_tensor.t().contiguous()
            else:
                self.edge_index = torch.tensor([[], []], dtype=torch.long)
        else:
            self.edge_index = torch.tensor([[], []], dtype=torch.long)
        
        # Store graph statistics for computation steps
        self.computation_steps.append({
            'step': 'B∆∞·ªõc 1: X√¢y d·ª±ng ƒë·ªì th·ªã',
            'formula': 'G = (U ‚à™ I, E)',
            'computation': f'S·ªë users: {len(unique_users)}, S·ªë products: {len(unique_products)}, S·ªë edges: {len(edges)//2}',
            'meaning': f'ƒê·ªì th·ªã c√≥ {len(unique_users)} nodes user v√† {len(unique_products)} nodes product, t·∫°o th√†nh {len(edges)//2} c·∫°nh t∆∞∆°ng t√°c'
        })
        
        return len(unique_users), len(unique_products)
    
    def train(self, interactions_df: pd.DataFrame, epochs=50, lr=0.001):
        """Train LightGCN model."""
        start_time = time.time()
        
        # Build graph
        num_users, num_products = self.build_graph(interactions_df)
        
        if num_users == 0 or num_products == 0:
            st.error("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ train!")
            return
        
        # Initialize model
        embedding_dim = 64
        num_layers = 3
        self.model = LightGCNModel(num_users, num_products, embedding_dim=embedding_dim, num_layers=num_layers)
        optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)
        
        # Store initial embeddings for computation steps
        initial_user_emb = self.model.user_embedding.weight.data.clone()
        initial_product_emb = self.model.product_embedding.weight.data.clone()
        
        self.computation_steps.append({
            'step': 'B∆∞·ªõc 2: Kh·ªüi t·∫°o Embeddings',
            'formula': 'e_u^(0) ~ N(0, 0.1¬≤), e_i^(0) ~ N(0, 0.1¬≤)',
            'computation': f'User embeddings shape: {initial_user_emb.shape}, Product embeddings shape: {initial_product_emb.shape}\n'
                          f'V√≠ d·ª• e_u[0] = {initial_user_emb[0][:3].tolist()}..., e_i[0] = {initial_product_emb[0][:3].tolist()}...',
            'meaning': f'M·ªói user v√† product ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng vector {embedding_dim} chi·ªÅu, kh·ªüi t·∫°o ng·∫´u nhi√™n t·ª´ ph√¢n ph·ªëi chu·∫©n'
        })
        
        # Store initial embeddings matrix
        self.matrices['initial_user_embeddings'] = initial_user_emb[:min(10, num_users), :min(10, embedding_dim)].detach().numpy()
        self.matrices['initial_product_embeddings'] = initial_product_emb[:min(10, num_products), :min(10, embedding_dim)].detach().numpy()
        
        # Add propagation computation steps
        with torch.no_grad():
            # Example propagation for first layer
            example_user_idx = 0
            example_user_emb = initial_user_emb[example_user_idx]
            
            # Calculate degree for example user
            if self.edge_index.numel() > 0:
                row, col = self.edge_index
                user_edges = (row == example_user_idx).sum().item()
                
                self.computation_steps.append({
                    'step': 'B∆∞·ªõc 3: LightGCN Propagation',
                    'formula': 'e_u^(l+1) = Œ£ (e_i^(l) / ‚àö(deg(u) * deg(i)))',
                    'computation': f'V√≠ d·ª• v·ªõi user 0:\n'
                                  f'  deg(user_0) = {user_edges} (s·ªë edges t·ª´ user n√†y)\n'
                                  f'  e_user_0^(0) = {example_user_emb[:3].tolist()}...\n'
                                  f'  Sau propagation qua {num_layers} layers, embedding ƒë∆∞·ª£c c·∫≠p nh·∫≠t',
                    'meaning': f'Embedding c·ªßa user ƒë∆∞·ª£c c·∫≠p nh·∫≠t b·∫±ng c√°ch t·ªïng h·ª£p th√¥ng tin t·ª´ c√°c products m√† user ƒë√£ t∆∞∆°ng t√°c, v·ªõi normalization theo b·∫≠c c·ªßa node'
                })
                
                self.computation_steps.append({
                    'step': 'B∆∞·ªõc 4: Average Embeddings t·ª´ t·∫•t c·∫£ layers',
                    'formula': 'e_u = (1/(L+1)) * Œ£ e_u^(l)',
                    'computation': f'L = {num_layers} layers\n'
                                  f'T·ªïng h·ª£p embeddings t·ª´ layer 0 ƒë·∫øn layer {num_layers}\n'
                                  f'e_u_final = (e_u^(0) + e_u^(1) + ... + e_u^({num_layers})) / {num_layers + 1}',
                    'meaning': f'Final embedding l√† trung b√¨nh c·ªßa embeddings t·ª´ t·∫•t c·∫£ {num_layers + 1} layers (bao g·ªìm initial), gi√∫p gi·ªØ l·∫°i th√¥ng tin t·ª´ m·ªçi ƒë·ªô s√¢u c·ªßa graph'
                })
        
        # Training loop
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        sample_size = min(1000, len(interactions_df))
        
        for epoch in range(epochs):
            self.model.train()
            optimizer.zero_grad()
            
            # Forward pass
            user_emb, product_emb = self.model(self.edge_index)
            
            # BPR Loss with interaction type weights (kh√¥ng d√πng rating)
            # Sample positive and negative pairs
            pos_pairs = []
            neg_pairs = []
            pos_weights = []  # Store interaction weights
            
            sample_df = interactions_df.sample(sample_size)
            for _, row in sample_df.iterrows():
                user_idx = self.user_id_map[row['user_id']]
                pos_product_idx = self.product_id_map[row['product_id']]
                
                # Get interaction type weight
                interaction_type = str(row.get('interaction_type', 'view')).lower()
                weight = self.INTERACTION_WEIGHTS.get(interaction_type, 1.0)
                
                # Sample negative product
                neg_product_idx = np.random.randint(0, num_products)
                while neg_product_idx == pos_product_idx:
                    neg_product_idx = np.random.randint(0, num_products)
                
                pos_pairs.append((user_idx, pos_product_idx))
                neg_pairs.append((user_idx, neg_product_idx))
                pos_weights.append(weight)
            
            # Calculate BPR loss with weights
            if pos_pairs:
                user_indices = [u for u, _ in pos_pairs]
                pos_product_indices = [p for _, p in pos_pairs]
                neg_product_indices = [p for _, p in neg_pairs]
                
                pos_scores = torch.sum(user_emb[user_indices] * product_emb[pos_product_indices], dim=1)
                neg_scores = torch.sum(user_emb[user_indices] * product_emb[neg_product_indices], dim=1)
                
                # Apply interaction type weights
                weights_tensor = torch.tensor(pos_weights, dtype=torch.float32)
                weighted_diff = weights_tensor * (pos_scores - neg_scores)
                
                loss = -torch.mean(torch.log(torch.sigmoid(weighted_diff) + 1e-10))
                
                # Store computation steps for first epoch
                if epoch == 0 and len(pos_pairs) > 0:
                    example_pos_score = pos_scores[0].item()
                    example_neg_score = neg_scores[0].item()
                    example_weight = pos_weights[0]
                    
                    self.computation_steps.append({
                        'step': 'B∆∞·ªõc 5: D·ª± ƒëo√°n Rating (v·ªõi interaction weights)',
                        'formula': 'rÃÇ_ui = w_type * (e_u^T ¬∑ e_i)',
                        'computation': f'V√≠ d·ª•: rÃÇ_pos = {example_weight} * ({example_pos_score:.4f}) = {example_weight * example_pos_score:.4f}\n'
                                      f'rÃÇ_neg = {example_neg_score:.4f}',
                        'meaning': f'Score ƒë∆∞·ª£c nh√¢n v·ªõi weight theo interaction type: view=1.0, like=2.0, cart=3.0, purchase=4.0'
                    })
                    
                    self.computation_steps.append({
                        'step': 'B∆∞·ªõc 6: BPR Loss',
                        'formula': 'L_BPR = -Œ£ log(œÉ(w_type * (rÃÇ_ui - rÃÇ_uj)))',
                        'computation': f'V√≠ d·ª•: diff = {example_weight * example_pos_score:.4f} - {example_neg_score:.4f} = {example_weight * example_pos_score - example_neg_score:.4f}\n'
                                      f'sigmoid(diff) = {torch.sigmoid(torch.tensor(example_weight * example_pos_score - example_neg_score)).item():.4f}\n'
                                      f'Loss = {loss.item():.4f}',
                        'meaning': 'Loss c√†ng nh·ªè c√†ng t·ªët, nghƒ©a l√† model ph√¢n bi·ªát t·ªët gi·ªØa positive v√† negative pairs'
                    })
            else:
                loss = torch.tensor(0.0)
            
            # Backward pass
            loss.backward()
            optimizer.step()
            
            progress_bar.progress((epoch + 1) / epochs)
            status_text.text(f"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}")
        
        # Store final embeddings for visualization
        with torch.no_grad():
            final_user_emb, final_product_emb = self.model(self.edge_index)
            self.matrices['final_user_embeddings'] = final_user_emb[:min(10, num_users), :min(10, embedding_dim)].detach().numpy()
            self.matrices['final_product_embeddings'] = final_product_emb[:min(10, num_products), :min(10, embedding_dim)].detach().numpy()
            
            # Compute similarity matrix (example: first 10 users vs first 10 products)
            similarity_matrix = torch.matmul(
                final_user_emb[:min(10, num_users)],
                final_product_emb[:min(10, num_products)].t()
            ).detach().numpy()
            self.matrices['similarity_matrix'] = similarity_matrix
        
        self.computation_steps.append({
            'step': 'B∆∞·ªõc 7: Gradient Descent',
            'formula': 'Œ∏ ‚Üê Œ∏ - Œ± * ‚àáL_BPR',
            'computation': f'Learning rate Œ± = {lr}, S·ªë epochs = {epochs}\n'
                          f'Final loss = {loss.item():.4f}',
            'meaning': f'Model ƒë√£ ƒë∆∞·ª£c train {epochs} epochs, embeddings ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t ƒë·ªÉ t·ªëi ∆∞u BPR loss'
        })
        
        self.training_time = time.time() - start_time
        progress_bar.empty()
        status_text.empty()
    
    def recommend(self, user_id: str, product_dict: Dict, top_k: int = 20, 
                  user_gender: str = None, user_age: int = None,
                  current_product_id: str = None) -> Tuple[List[Tuple[str, float]], float]:
        """Generate recommendations for a user."""
        user_id = str(user_id)  # Ensure string format
        if self.model is None or user_id not in self.user_id_map:
            return [], 0.0
        
        start_time = time.time()
        
        # Get articleType from current product (most important constraint) - following API pattern
        # Reference: apps/recommendations/common/filters.py CandidateFilter._build_candidate_pool()
        normalized_article_type = None
        if current_product_id and current_product_id in product_dict:
            article_type = product_dict[current_product_id].get('articleType')
            if article_type:
                normalized_article_type = str(article_type).strip()
        
        self.model.eval()
        with torch.no_grad():
            user_emb, product_emb = self.model(self.edge_index)
            user_idx = self.user_id_map[user_id]
            
            # Calculate scores: r_hat = e_u^T * e_i
            scores = torch.matmul(user_emb[user_idx:user_idx+1], product_emb.t())
            scores = scores.squeeze(0)
            
            # Get top-k products
            top_indices = torch.topk(scores, min(top_k * 3, len(scores))).indices.tolist()
            
            recommendations = []
            for idx in top_indices:
                product_id = self.reverse_product_map[idx]
                if product_id in product_dict:
                    product = product_dict[product_id]
                    
                    if normalized_article_type:
                        product_article = (product.get('articleType', '') or '').strip()
                        if product_article and product_article != normalized_article_type:
                            continue
                    
                    # Gender filter - map common gender values
                    # Gender filter: determine compatible genders (not strict, just compatibility check)
                    product_gender = (product.get('gender', '') or '').strip().lower()
                    if product_gender:  # Only filter if product has gender specified
                        # Normalize user gender
                        user_gender_normalized = ''
                        if user_gender:
                            user_gender_lower = user_gender.lower()
                            if user_gender_lower in ['male', 'man', 'men', 'boy', 'boys']:
                                user_gender_normalized = 'male'
                            elif user_gender_lower in ['female', 'woman', 'women', 'girl', 'girls']:
                                user_gender_normalized = 'female'
                            elif user_gender_lower == 'unisex':
                                user_gender_normalized = 'unisex'
                        
                        # Determine allowed genders based on user gender and age
                        allowed_genders = set()
                        if user_gender_normalized == 'male':
                            if user_age is not None and user_age <= 12:
                                # Kids: Boys, Unisex
                                allowed_genders = {'boys', 'unisex', ''}
                            else:
                                # Adults: Men, Boys, Unisex
                                allowed_genders = {'men', 'male', 'man', 'boys', 'boy', 'unisex', ''}
                        elif user_gender_normalized == 'female':
                            if user_age is not None and user_age <= 12:
                                # Kids: Girls, Unisex
                                allowed_genders = {'girls', 'unisex', ''}
                            else:
                                # Adults: Women, Girls, Unisex
                                allowed_genders = {'women', 'woman', 'female', 'girls', 'girl', 'unisex', ''}
                        else:
                            # Unknown user gender: only allow Unisex
                            allowed_genders = {'unisex', ''}
                        
                        # Check if product gender is compatible
                        if product_gender not in allowed_genders:
                            continue
                    
                    score = scores[idx].item()
                    recommendations.append((product_id, score))
                    
                    if len(recommendations) >= top_k:
                        break
        
        inference_time = time.time() - start_time
        return recommendations, inference_time


# ==================== CONTENT-BASED FILTERING ====================

class ContentBasedRecommender:
    """Content-Based Filtering using TF-IDF and Cosine Similarity."""
    
    # Interaction type weights (kh√¥ng d√πng rating)
    INTERACTION_WEIGHTS = {
        'view': 1.0,
        'like': 2.0,
        'cart': 3.0,
        'purchase': 4.0,
        'review': 2.5
    }
    
    def __init__(self):
        self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        self.product_vectors = None
        self.product_ids = []
        self.training_time = 0.0
        self.computation_steps = []
        self.matrices = {}
    
    def train(self, products_df: pd.DataFrame):
        """Train content-based model."""
        start_time = time.time()
        
        # Create text features for each product
        product_texts = []
        self.product_ids = []
        
        for _, row in products_df.iterrows():
            # S·ª≠ d·ª•ng c√°c field: gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName
            text_parts = [
                str(row.get('gender', '')),
                str(row.get('masterCategory', '')),
                str(row.get('subCategory', '')),
                str(row.get('articleType', '')),
                str(row.get('baseColour', '')),
                str(row.get('usage', '')),
                str(row.get('productDisplayName', ''))  # Th√™m productDisplayName
            ]
            text = ' '.join([p for p in text_parts if p and p != 'nan'])
            product_texts.append(text)
            self.product_ids.append(str(row['id']))
        
        # Example text for computation steps
        example_text = product_texts[0] if product_texts else ""
        example_words = example_text.split()[:10] if example_text else []
        
        self.computation_steps.append({
            'step': 'B∆∞·ªõc 1: T·∫°o Feature Vector cho m·ªói s·∫£n ph·∫©m',
            'formula': 'v_i = TF-IDF(gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName)',
            'computation': f'V√≠ d·ª• s·∫£n ph·∫©m 1: "{example_text[:50]}..."\n'
                          f'C√°c t·ª´ kh√≥a: {", ".join(example_words[:5])}...\n'
                          f'T·ªïng s·ªë s·∫£n ph·∫©m: {len(product_texts)}\n'
                          f'C√°c field s·ª≠ d·ª•ng: gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName',
            'meaning': 'M·ªói s·∫£n ph·∫©m ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng vector TF-IDF t·ª´ 7 ƒë·∫∑c t√≠nh: gi·ªõi t√≠nh, danh m·ª•c ch√≠nh, danh m·ª•c ph·ª•, lo·∫°i s·∫£n ph·∫©m, m√†u s·∫Øc, m·ª•c ƒë√≠ch s·ª≠ d·ª•ng, t√™n s·∫£n ph·∫©m'
        })
        
        # Vectorize products
        self.product_vectors = self.vectorizer.fit_transform(product_texts)
        
        # Store TF-IDF matrix for visualization
        self.matrices['tfidf_matrix'] = self.product_vectors[:min(20, len(product_texts)), :min(50, self.product_vectors.shape[1])].toarray()
        
        # Example TF-IDF calculation
        if len(product_texts) > 0:
            vocab = list(self.vectorizer.vocabulary_.keys())[:5]
            example_vector = self.product_vectors[0].toarray()[0]
            non_zero_indices = np.nonzero(example_vector)[0][:5]
            example_values = example_vector[non_zero_indices]
            
            self.computation_steps.append({
                'step': 'B∆∞·ªõc 2: T√≠nh TF-IDF',
                'formula': 'TF-IDF(t, d) = TF(t, d) * IDF(t, D)',
                'computation': f'Vocabulary size: {len(self.vectorizer.vocabulary_)}\n'
                              f'V√≠ d·ª• vector s·∫£n ph·∫©m 1: shape = {self.product_vectors[0].shape}\n'
                              f'C√°c gi√° tr·ªã TF-IDF kh√°c 0 ƒë·∫ßu ti√™n: {example_values.tolist()}',
                'meaning': f'Vector c√≥ {self.product_vectors.shape[1]} chi·ªÅu, m·ªói chi·ªÅu ƒë·∫°i di·ªán cho m·ªôt t·ª´ trong vocabulary'
            })
        
        self.training_time = time.time() - start_time
    
    def recommend(self, user_interactions: pd.DataFrame, products_df: pd.DataFrame,
                  product_dict: Dict, top_k: int = 20,
                  user_gender: str = None, user_age: int = None,
                  current_product_id: str = None) -> Tuple[List[Tuple[str, float]], float]:
        """Generate recommendations based on user's interaction history with interaction type weights."""
        start_time = time.time()
        
        if len(user_interactions) == 0 or self.product_vectors is None:
            return [], 0.0
        
        # Get articleType from current product (most important constraint) - following API pattern
        # Reference: apps/recommendations/common/filters.py CandidateFilter._build_candidate_pool()
        normalized_article_type = None
        if current_product_id and current_product_id in product_dict:
            article_type = product_dict[current_product_id].get('articleType')
            if article_type:
                normalized_article_type = str(article_type).strip()
        
        # Get user's interacted products with weights (kh√¥ng d√πng rating)
        interacted_data = []
        interacted_product_ids = set()  # Track interacted product IDs to exclude from recommendations
        for _, row in user_interactions.iterrows():
            pid = str(row['product_id'])
            interacted_product_ids.add(pid)  # Add to set of interacted products
            if pid in self.product_ids:
                interaction_type = str(row.get('interaction_type', 'view')).lower()
                weight = self.INTERACTION_WEIGHTS.get(interaction_type, 1.0)
                idx = self.product_ids.index(pid)
                interacted_data.append((idx, weight))
        
        if not interacted_data:
            return [], 0.0
        
        # Build user profile: weighted average of interacted products (kh√¥ng d√πng rating)
        # Formula: u = (1/Œ£w_i) * Œ£(w_i * v_i) for i in I_u
        indices = [idx for idx, _ in interacted_data]
        weights = np.array([w for _, w in interacted_data])
        weights = weights / weights.sum()  # Normalize weights
        
        # Convert sparse matrix to dense for weighted calculation
        product_vectors_dense = self.product_vectors[indices].toarray()
        weighted_vectors = product_vectors_dense * weights.reshape(-1, 1)
        user_profile = np.mean(weighted_vectors, axis=0)
        
        # Store computation steps
        self.computation_steps.append({
            'step': 'B∆∞·ªõc 3: X√¢y d·ª±ng User Profile (v·ªõi interaction weights)',
            'formula': 'u = (1/Œ£w_i) * Œ£(w_i * v_i)',
            'computation': f'S·ªë s·∫£n ph·∫©m user ƒë√£ t∆∞∆°ng t√°c: {len(interacted_data)}\n'
                          f'Weights: {dict(zip([self.product_ids[idx] for idx in indices[:3]], weights[:3]))}...\n'
                          f'User profile shape: {user_profile.shape}\n'
                          f'V√≠ d·ª• user profile (5 gi√° tr·ªã ƒë·∫ßu): {user_profile[:5].tolist()}',
            'meaning': f'User profile l√† trung b√¨nh c√≥ tr·ªçng s·ªë c·ªßa {len(interacted_data)} s·∫£n ph·∫©m ƒë√£ t∆∞∆°ng t√°c, v·ªõi weight theo type: view=1.0, like=2.0, cart=3.0, purchase=4.0'
        })
        
        # Calculate cosine similarity: sim(u, i) = (u ¬∑ i) / (||u|| * ||i||)
        similarities = cosine_similarity(user_profile.reshape(1, -1), self.product_vectors).flatten()
        
        # Store similarity matrix (top 20 products)
        top_similar_indices = np.argsort(similarities)[::-1][:20]
        self.matrices['similarity_matrix'] = similarities[top_similar_indices].reshape(-1, 1)
        
        # Example similarity calculation
        if len(similarities) > 0:
            max_sim_idx = np.argmax(similarities)
            max_sim_value = similarities[max_sim_idx]
            example_product_vector = self.product_vectors[max_sim_idx].toarray().flatten()
            
            # Calculate dot product and norms
            dot_product = np.dot(user_profile, example_product_vector)
            user_norm = np.linalg.norm(user_profile)
            product_norm = np.linalg.norm(example_product_vector)
            
            self.computation_steps.append({
                'step': 'B∆∞·ªõc 4: T√≠nh Cosine Similarity',
                'formula': 'sim(u, i) = (u ¬∑ v_i) / (||u|| * ||v_i||)',
                'computation': f'V√≠ d·ª• v·ªõi s·∫£n ph·∫©m {max_sim_idx}:\n'
                              f'  u ¬∑ v_i = {dot_product:.4f}\n'
                              f'  ||u|| = {user_norm:.4f}\n'
                              f'  ||v_i|| = {product_norm:.4f}\n'
                              f'  sim(u, i) = {dot_product:.4f} / ({user_norm:.4f} * {product_norm:.4f}) = {max_sim_value:.4f}',
                'meaning': f'Similarity = {max_sim_value:.4f} nghƒ©a l√† s·∫£n ph·∫©m n√†y gi·ªëng {max_sim_value*100:.1f}% v·ªõi s·ªü th√≠ch c·ªßa user (gi√° tr·ªã t·ª´ -1 ƒë·∫øn 1, 1 = gi·ªëng nh·∫•t)'
            })
        
        # Add ranking step
        if len(similarities) > 0:
            top_5_indices = np.argsort(similarities)[::-1][:5]
            top_5_scores = similarities[top_5_indices]
            
            self.computation_steps.append({
                'step': 'B∆∞·ªõc 5: Ranking v√† Recommendation',
                'formula': 'Rank products by sim(u, i) descending',
                'computation': f'Top 5 s·∫£n ph·∫©m:\n'
                              f'  Product {top_5_indices[0]}: similarity = {top_5_scores[0]:.4f}\n'
                              f'  Product {top_5_indices[1]}: similarity = {top_5_scores[1]:.4f}\n'
                              f'  Product {top_5_indices[2]}: similarity = {top_5_scores[2]:.4f}\n'
                              f'  Product {top_5_indices[3]}: similarity = {top_5_scores[3]:.4f}\n'
                              f'  Product {top_5_indices[4]}: similarity = {top_5_scores[4]:.4f}',
                'meaning': 'S·∫Øp x·∫øp s·∫£n ph·∫©m theo similarity gi·∫£m d·∫ßn, ch·ªçn top-K s·∫£n ph·∫©m c√≥ similarity cao nh·∫•t ƒë·ªÉ recommend'
            })
        
        # Get top-k products (excluding already interacted)
        top_indices = np.argsort(similarities)[::-1]
        
        # Debug: Check similarity of current_product_id if provided
        if current_product_id and current_product_id in self.product_ids:
            test_product_idx = self.product_ids.index(current_product_id)
            test_product_similarity = similarities[test_product_idx]
            # Store for debug
            self.debug_test_product_similarity = test_product_similarity
            self.debug_test_product_rank = None
            # Find rank of test product
            sorted_similarities = np.sort(similarities)[::-1]
            rank = np.where(sorted_similarities == test_product_similarity)[0]
            if len(rank) > 0:
                self.debug_test_product_rank = rank[0] + 1  # 1-indexed
        
        # Debug counters
        debug_stats = {
            'total_checked': 0,
            'already_interacted': 0,
            'not_in_dict': 0,
            'article_type_mismatch': 0,
            'gender_mismatch': 0,
            'age_mismatch': 0,
            'passed_all': 0
        }
        
        recommendations = []
        for idx in top_indices:
            debug_stats['total_checked'] += 1
            product_id = self.product_ids[idx]
            
            # Skip current product
            if current_product_id and str(product_id) == str(current_product_id):
                continue
            
            # Skip already interacted products
            if product_id in interacted_product_ids:
                debug_stats['already_interacted'] += 1
                continue
            
            # Filter by articleType (most important), gender and age
            # Following API pattern: apps/recommendations/common/filters.py line 238-240
            if product_id not in product_dict:
                debug_stats['not_in_dict'] += 1
                continue
                
            product = product_dict[product_id]
            
            # ArticleType filter (MANDATORY constraint - must match)
            if normalized_article_type:
                product_article = (product.get('articleType', '') or '').strip()
                if product_article and product_article != normalized_article_type:
                    debug_stats['article_type_mismatch'] += 1
                    continue
            
            # Gender filter: determine compatible genders (not strict, just compatibility check)
            # Use gender_filter_values logic: male -> Men/Boys/Unisex, female -> Women/Girls/Unisex
            product_gender = (product.get('gender', '') or '').strip().lower()
            if product_gender:  # Only filter if product has gender specified
                # Normalize user gender
                user_gender_normalized = ''
                if user_gender:
                    user_gender_lower = user_gender.lower()
                    if user_gender_lower in ['male', 'man', 'men', 'boy', 'boys']:
                        user_gender_normalized = 'male'
                    elif user_gender_lower in ['female', 'woman', 'women', 'girl', 'girls']:
                        user_gender_normalized = 'female'
                    elif user_gender_lower == 'unisex':
                        user_gender_normalized = 'unisex'
                
                # Determine allowed genders based on user gender and age
                allowed_genders = set()
                if user_gender_normalized == 'male':
                    if user_age is not None and user_age <= 12:
                        # Kids: Boys, Unisex
                        allowed_genders = {'boys', 'unisex', ''}
                    else:
                        # Adults: Men, Boys, Unisex
                        allowed_genders = {'men', 'male', 'man', 'boys', 'boy', 'unisex', ''}
                elif user_gender_normalized == 'female':
                    if user_age is not None and user_age <= 12:
                        # Kids: Girls, Unisex
                        allowed_genders = {'girls', 'unisex', ''}
                    else:
                        # Adults: Women, Girls, Unisex
                        allowed_genders = {'women', 'woman', 'female', 'girls', 'girl', 'unisex', ''}
                else:
                    # Unknown user gender: only allow Unisex
                    allowed_genders = {'unisex', ''}
                
                # Check if product gender is compatible
                if product_gender not in allowed_genders:
                    debug_stats['gender_mismatch'] += 1
                    continue
            
            debug_stats['passed_all'] += 1
            score = float(similarities[idx])
            recommendations.append((product_id, score))
            
            if len(recommendations) >= top_k:
                break
        
        # Store debug stats
        self.debug_stats = debug_stats
        
        inference_time = time.time() - start_time
        return recommendations, inference_time


# ==================== HYBRID MODEL ====================

class HybridRecommender:
    """Hybrid Model combining LightGCN and Content-Based Filtering."""
    
    def __init__(self, lightgcn: LightGCNRecommender, cbf: ContentBasedRecommender):
        self.lightgcn = lightgcn
        self.cbf = cbf
        self.alpha = 0.5  # Weight for LightGCN (balanced: 0.5 LightGCN + 0.5 CBF)
        self.training_time = 0.0
    
    def train(self, interactions_df: pd.DataFrame, products_df: pd.DataFrame):
        """Train both models."""
        start_time = time.time()
        
        # Train LightGCN
        self.lightgcn.train(interactions_df, epochs=30, lr=0.001)
        
        # Train CBF
        self.cbf.train(products_df)
        
        self.training_time = time.time() - start_time
    
    def recommend(self, user_id: str, user_interactions: pd.DataFrame,
                  products_df: pd.DataFrame, product_dict: Dict,
                  top_k: int = 20, user_gender: str = None, user_age: int = None,
                  current_product_id: str = None) -> Tuple[List[Tuple[str, float]], float]:
        """Generate hybrid recommendations."""
        start_time = time.time()
        
        # Get recommendations from both models (with articleType filtering)
        lightgcn_recs, _ = self.lightgcn.recommend(
            user_id, product_dict, top_k * 2, user_gender, user_age, current_product_id
        )
        cbf_recs, _ = self.cbf.recommend(
            user_interactions, products_df, product_dict, top_k * 2, user_gender, user_age, current_product_id
        )
        
        # Combine scores: score_hybrid = Œ± * score_gnn + (1-Œ±) * score_cbf
        # Formula: r_hybrid = Œ± * r_gnn + (1-Œ±) * r_cbf
        # Improved: Use harmonic mean for better combination when both models agree
        combined_scores = defaultdict(float)
        product_scores_gnn = {}
        product_scores_cbf = {}
        
        # Normalize and store LightGCN scores
        if lightgcn_recs:
            scores_gnn = [score for _, score in lightgcn_recs]
            if scores_gnn:
                max_gnn = max(scores_gnn)
                min_gnn = min(scores_gnn)
                gnn_range = max_gnn - min_gnn if max_gnn != min_gnn else 1.0
                
                for pid, score in lightgcn_recs:
                    normalized_score = (score - min_gnn) / gnn_range if gnn_range > 0 else 0.5
                    product_scores_gnn[pid] = normalized_score
                    combined_scores[pid] += self.alpha * normalized_score
        
        # Normalize and store CBF scores
        if cbf_recs:
            scores_cbf = [score for _, score in cbf_recs]
            if scores_cbf:
                max_cbf = max(scores_cbf)
                min_cbf = min(scores_cbf)
                cbf_range = max_cbf - min_cbf if max_cbf != min_cbf else 1.0
                
                for pid, score in cbf_recs:
                    normalized_score = (score - min_cbf) / cbf_range if cbf_range > 0 else 0.5
                    product_scores_cbf[pid] = normalized_score
                    combined_scores[pid] += (1 - self.alpha) * normalized_score
        
        # Enhanced combination: Boost products that appear in both models
        # If a product is recommended by both models, give it a bonus
        for pid in combined_scores:
            if pid in product_scores_gnn and pid in product_scores_cbf:
                # Both models agree - boost the score
                gnn_score = product_scores_gnn[pid]
                cbf_score = product_scores_cbf[pid]
                # Use harmonic mean for products in both: 2 * (gnn * cbf) / (gnn + cbf)
                if gnn_score > 0 and cbf_score > 0:
                    harmonic_mean = 2 * (gnn_score * cbf_score) / (gnn_score + cbf_score)
                    # Add bonus: 20% of harmonic mean
                    combined_scores[pid] += 0.2 * harmonic_mean
        
        # Sort by combined score
        recommendations = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
        
        inference_time = time.time() - start_time
        return recommendations, inference_time


# ==================== EVALUATION METRICS ====================

def calculate_recall_at_k(recommended: List[str], relevant: List[str], k: int) -> float:
    """Calculate Recall@K: |R ‚à© T| / |T|"""
    if len(relevant) == 0:
        return 0.0
    
    top_k_rec = set(recommended[:k])
    relevant_set = set(relevant)
    
    intersection = len(top_k_rec & relevant_set)
    return intersection / len(relevant_set) if len(relevant_set) > 0 else 0.0


def calculate_ndcg_at_k(recommended: List[str], relevant: List[str], k: int) -> float:
    """Calculate NDCG@K: DCG@K / IDCG@K"""
    def dcg_at_k(relevance_list: List[float], k: int) -> float:
        """DCG@K = sum(rel_i / log2(i+1))"""
        dcg = 0.0
        for i in range(min(len(relevance_list), k)):
            dcg += relevance_list[i] / math.log2(i + 2)
        return dcg
    
    # Build relevance list
    relevance_list = [1.0 if pid in relevant else 0.0 for pid in recommended[:k]]
    
    # Calculate DCG@K
    dcg = dcg_at_k(relevance_list, k)
    
    # Calculate IDCG@K (ideal: all relevant items ranked first)
    ideal_relevance = [1.0] * min(len(relevant), k)
    idcg = dcg_at_k(ideal_relevance, k)
    
    return dcg / idcg if idcg > 0 else 0.0


def evaluate_model(recommendations: List[Tuple[str, float]], 
                  test_interactions: pd.DataFrame,
                  k_values: List[int] = [10, 20]) -> Dict:
    """Evaluate model performance."""
    # Convert all IDs to strings for consistent comparison
    recommended_ids = [str(pid) for pid, _ in recommendations]
    
    # Get ground truth (test interactions) - convert to strings
    relevant_ids = [str(pid) for pid in test_interactions['product_id'].unique().tolist()]
    
    metrics = {}
    for k in k_values:
        metrics[f'recall_at_{k}'] = calculate_recall_at_k(recommended_ids, relevant_ids, k)
        metrics[f'ndcg_at_{k}'] = calculate_ndcg_at_k(recommended_ids, relevant_ids, k)
    
    return metrics


# ==================== MODEL COMPARISON HELPERS ====================

def parse_interaction_history(history_str):
    """Parse interaction history string from CSV."""
    if not history_str or pd.isna(history_str) or str(history_str).strip() == '':
        return []
    
    interactions = []
    # Split by semicolon
    parts = str(history_str).split(';')
    
    for part in parts:
        part = part.strip()
        if not part or not part.startswith('{'):
            continue
        
        try:
            # Try to extract product_id using regex first (faster and safer)
            # Pattern 1: 'product_id': 10866 or 'product_id': '10866'
            match1 = re.search(r"'product_id'\s*:\s*(\d+)", part)
            if match1:
                product_id_str = match1.group(1)
            else:
                # Pattern 2: 'productId': ObjectId('...')
                match2 = re.search(r"'productId'\s*:\s*ObjectId\('([^']+)'\)", part)
                if match2:
                    # Skip ObjectId-based products for now
                    continue
                else:
                    # Try eval as fallback
                    try:
                        interaction = eval(part, {'datetime': datetime, 'ObjectId': ObjectId})
                        if 'product_id' in interaction:
                            product_id_str = str(interaction['product_id'])
                        elif 'productId' in interaction:
                            pid = interaction['productId']
                            if isinstance(pid, ObjectId):
                                continue  # Skip ObjectId
                            product_id_str = str(pid)
                        else:
                            continue
                    except:
                        continue
            
            if not product_id_str or product_id_str == 'None':
                continue
            
            # Extract interaction type
            interaction_type = 'view'  # default
            if "'interaction_type'" in part:
                match_type = re.search(r"'interaction_type'\s*:\s*'([^']+)'", part)
                if match_type:
                    interaction_type = match_type.group(1).lower()
            elif "'interactionType'" in part:
                match_type = re.search(r"'interactionType'\s*:\s*'([^']+)'", part)
                if match_type:
                    interaction_type = match_type.group(1).lower()
            
            interactions.append({
                'product_id': product_id_str,
                'interaction_type': interaction_type
            })
        except Exception as e:
            # Silently skip parsing errors
            continue
    
    return interactions

def load_users_from_csv():
    """Load users from CSV and extract user-product pairs."""
    try:
        users_df = pd.read_csv('exports/users.csv')
        user_product_pairs = []
        
        for _, row in users_df.iterrows():
            user_id = str(row['id'])
            if pd.isna(user_id) or user_id == '' or user_id == 'nan':
                continue
            
            history_str = row.get('interaction_history', '')
            if pd.isna(history_str) or str(history_str).strip() == '':
                continue
            
            interactions = parse_interaction_history(history_str)
            
            if len(interactions) == 0:
                continue
            
            # Get unique products for this user
            unique_products = {}
            for interaction in interactions:
                pid = interaction['product_id']
                if pid and pid not in unique_products:
                    unique_products[pid] = interaction
            
            # Create pairs (limit to 5 products per user for diversity)
            for idx, (pid, interaction) in enumerate(list(unique_products.items())[:5]):
                user_product_pairs.append({
                    'user_id': user_id,
                    'product_id': pid,
                    'user_name': str(row.get('name', '')),
                    'user_gender': str(row.get('gender', '')),
                    'user_age': row.get('age', None) if not pd.isna(row.get('age', None)) else None
                })
        
        return user_product_pairs
    except Exception as e:
        return []


# ==================== OUTFIT RECOMMENDATION ====================

def get_outfit_categories():
    """Define outfit categories."""
    return {
        'topwear': ['Tshirts', 'Shirts', 'Tops', 'Sweaters', 'Sweatshirts', 'Jackets'],
        'bottomwear': ['Trousers', 'Jeans', 'Shorts', 'Skirts', 'Track Pants'],
        'footwear': ['Shoes', 'Sandals', 'Flip Flops'],
        'accessories': ['Bags', 'Watches', 'Belts', 'Caps']
    }


def recommend_outfit(current_product: Dict, product_dict: Dict, 
                    user_gender: str = None, user_age: int = None) -> Dict:
    """Recommend complementary items for an outfit."""
    outfit_categories = get_outfit_categories()
    
    # Determine current product category
    current_category = None
    article_type = current_product.get('articleType', '').lower()
    sub_category = current_product.get('subCategory', '').lower()
    
    if 'topwear' in sub_category or article_type in ['tshirts', 'shirts', 'tops', 'sweaters']:
        current_category = 'topwear'
    elif 'bottomwear' in sub_category or article_type in ['trousers', 'jeans', 'shorts']:
        current_category = 'bottomwear'
    elif 'footwear' in sub_category or article_type in ['shoes', 'sandals']:
        current_category = 'footwear'
    elif 'accessories' in sub_category or article_type in ['bags', 'watches']:
        current_category = 'accessories'
    
    # Recommend items from other categories
    outfit_recommendations = {}
    
    for category, article_types in outfit_categories.items():
        if category == current_category:
            continue
        
        # Find products in this category
        candidates = []
        for pid, product in product_dict.items():
            product_article = product.get('articleType', '').lower()
            product_sub = product.get('subCategory', '').lower()
            
            # Check if matches category
            matches = False
            if category == 'topwear' and ('topwear' in product_sub or product_article in article_types):
                matches = True
            elif category == 'bottomwear' and ('bottomwear' in product_sub or product_article in article_types):
                matches = True
            elif category == 'footwear' and ('footwear' in product_sub or product_article in article_types):
                matches = True
            elif category == 'accessories' and ('accessories' in product_sub or product_article in article_types):
                matches = True
            
            if matches:
                # Gender filter: determine compatible genders (not strict, just compatibility check)
                product_gender = (product.get('gender', '') or '').strip().lower()
                if product_gender:  # Only filter if product has gender specified
                    # Normalize user gender
                    user_gender_normalized = ''
                    if user_gender:
                        user_gender_lower = user_gender.lower()
                        if user_gender_lower in ['male', 'man', 'men', 'boy', 'boys']:
                            user_gender_normalized = 'male'
                        elif user_gender_lower in ['female', 'woman', 'women', 'girl', 'girls']:
                            user_gender_normalized = 'female'
                        elif user_gender_lower == 'unisex':
                            user_gender_normalized = 'unisex'
                    
                    # Determine allowed genders based on user gender and age
                    allowed_genders = set()
                    if user_gender_normalized == 'male':
                        if user_age is not None and user_age <= 12:
                            # Kids: Boys, Unisex
                            allowed_genders = {'boys', 'unisex', ''}
                        else:
                            # Adults: Men, Boys, Unisex
                            allowed_genders = {'men', 'male', 'man', 'boys', 'boy', 'unisex', ''}
                    elif user_gender_normalized == 'female':
                        if user_age is not None and user_age <= 12:
                            # Kids: Girls, Unisex
                            allowed_genders = {'girls', 'unisex', ''}
                        else:
                            # Adults: Women, Girls, Unisex
                            allowed_genders = {'women', 'woman', 'female', 'girls', 'girl', 'unisex', ''}
                    else:
                        # Unknown user gender: only allow Unisex
                        allowed_genders = {'unisex', ''}
                    
                    # Check if product gender is compatible
                    if product_gender not in allowed_genders:
                        continue
                
                candidates.append((pid, product))
        
        # Select top 3-5 items
        outfit_recommendations[category] = candidates[:5]
    
    return outfit_recommendations


# ==================== STREAMLIT UI ====================

def main():
    st.title("üõçÔ∏è H·ªá th·ªëng G·ª£i √Ω S·∫£n ph·∫©m")
    st.markdown("---")
    # Load data
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
        user_dict, product_dict, interactions_df, users_df, products_df = load_all_data()
    
    st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
    
    # Model selection
    model_type = st.sidebar.selectbox(
        "Ch·ªçn m√¥ h√¨nh",
        ["LightGCN (GNN)", "Content-Based Filtering", "Hybrid (LightGCN + CBF)"]
    )
    
    # User selection
    user_ids = list(user_dict.keys())
    selected_user_id = st.sidebar.selectbox("Ch·ªçn ng∆∞·ªùi d√πng", user_ids)
    
    if selected_user_id:
        user = user_dict[selected_user_id]
        interaction_count = len(user.get('interactions', []))
        st.sidebar.info(f"**Ng∆∞·ªùi d√πng:** {user.get('name', 'N/A')}\n\n"
                       f"**Tu·ªïi:** {user.get('age', 'N/A')}\n\n"
                       f"**Gi·ªõi t√≠nh:** {user.get('gender', 'N/A')}\n\n"
                       f"**S·ªë interactions:** {interaction_count}")
    
    # Product selection for outfit recommendation
    product_ids = list(product_dict.keys())
    selected_product_id = st.sidebar.selectbox(
        "Ch·ªçn s·∫£n ph·∫©m (cho Outfit recommendation)",
        [""] + product_ids[:100]  # Limit for performance
    )
    
    # Training section
    if st.sidebar.button("üöÄ Train Models"):
        st.header("üìä Training Models")
        
        # Split data (80% train, 20% test)
        train_size = int(len(interactions_df) * 0.8)
        train_interactions = interactions_df.iloc[:train_size]
        test_interactions = interactions_df.iloc[train_size:]
        
        # Initialize models
        if model_type == "LightGCN (GNN)":
            model = LightGCNRecommender()
            
            model.train(train_interactions, epochs=30, lr=0.001)
            st.success(f"‚úÖ LightGCN trained in {model.training_time:.2f}s")
            
            # Display Algorithm (A-Z) v·ªõi computation steps g·ªôp chung
            with st.expander("üìñ LightGCN Algorithm (A-Z)", expanded=True):
                st.markdown("""
                """)
                
                # Hi·ªÉn th·ªã t·ª´ng b∆∞·ªõc v·ªõi c√¥ng th·ª©c, √°p d·ª•ng c√¥ng th·ª©c, gi·∫£i th√≠ch v√† ma tr·∫≠n - g·ªôp ho√†n to√†n
                if model.computation_steps:
                    for step_info in model.computation_steps:
                        # X√°c ƒë·ªãnh s·ªë b∆∞·ªõc t·ª´ step_info
                        step_num = step_info['step'].split(':')[0] if ':' in step_info['step'] else step_info['step']
                        
                        with st.expander(f"{step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Hi·ªÉn th·ªã ma tr·∫≠n t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng b∆∞·ªõc
                            if 'B∆∞·ªõc 2: Kh·ªüi t·∫°o Embeddings' in step_info['step'] and 'initial_user_embeddings' in model.matrices:
                                st.markdown("**üìà Ma tr·∫≠n User Embeddings ban ƒë·∫ßu (10x10):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(model.matrices['initial_user_embeddings'], 
                                           annot=True, fmt='.3f', cmap='viridis', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('Initial User Embeddings Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n embeddings ban ƒë·∫ßu c·ªßa 10 users ƒë·∫ßu ti√™n, m·ªói user c√≥ vector 10 chi·ªÅu")
                            
                            elif 'B∆∞·ªõc 7: Gradient Descent' in step_info['step'] and 'final_user_embeddings' in model.matrices:
                                st.markdown("**üìà Ma tr·∫≠n User Embeddings sau training (10x10):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(model.matrices['final_user_embeddings'], 
                                           annot=True, fmt='.3f', cmap='viridis', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('Final User Embeddings Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n embeddings sau training, ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ ph√¢n bi·ªát s·ªü th√≠ch users")
                            
                            elif 'B∆∞·ªõc 5: D·ª± ƒëo√°n' in step_info['step'] and 'similarity_matrix' in model.matrices:
                                st.markdown("**üìà Ma tr·∫≠n Similarity (User x Product):**")
                                fig, ax = plt.subplots(figsize=(10, 8))
                                sns.heatmap(model.matrices['similarity_matrix'], 
                                           annot=True, fmt='.3f', cmap='coolwarm', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('User-Product Similarity Matrix (10x10)')
                                ax.set_xlabel('Products')
                                ax.set_ylabel('Users')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n similarity gi·ªØa 10 users v√† 10 products ƒë·∫ßu ti√™n. Gi√° tr·ªã c√†ng cao = user c√†ng th√≠ch product")
            
        elif model_type == "Content-Based Filtering":
            model = ContentBasedRecommender()
            
            model.train(products_df)
            st.success(f"‚úÖ Content-Based Filtering trained in {model.training_time:.2f}s")
            
            # Display Algorithm (A-Z) v·ªõi computation steps g·ªôp chung
            with st.expander("üìñ Content-Based Filtering Algorithm (A-Z)", expanded=True):
                st.markdown("""
                """)
                
                # Hi·ªÉn th·ªã t·ª´ng b∆∞·ªõc v·ªõi c√¥ng th·ª©c, √°p d·ª•ng c√¥ng th·ª©c, gi·∫£i th√≠ch v√† ma tr·∫≠n - g·ªôp ho√†n to√†n
                if model.computation_steps:
                    for step_info in model.computation_steps:
                        with st.expander(f"{step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Hi·ªÉn th·ªã ma tr·∫≠n t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng b∆∞·ªõc
                            if 'B∆∞·ªõc 1' in step_info['step'] and 'TF-IDF' in step_info['step'] and 'tfidf_matrix' in model.matrices:
                                st.markdown("**üìà Ma tr·∫≠n TF-IDF (20 s·∫£n ph·∫©m ƒë·∫ßu x 50 features):**")
                                fig, ax = plt.subplots(figsize=(12, 8))
                                sns.heatmap(model.matrices['tfidf_matrix'], 
                                           annot=False, fmt='.2f', cmap='YlOrRd', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('TF-IDF Matrix (Products x Features)')
                                ax.set_xlabel('Features (words)')
                                ax.set_ylabel('Products')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n TF-IDF: m·ªói h√†ng l√† m·ªôt s·∫£n ph·∫©m, m·ªói c·ªôt l√† m·ªôt t·ª´ trong vocabulary. Gi√° tr·ªã c√†ng cao = t·ª´ ƒë√≥ quan tr·ªçng v·ªõi s·∫£n ph·∫©m")
                            
                            elif 'B∆∞·ªõc 3: T√≠nh Cosine Similarity' in step_info['step'] and 'similarity_matrix' in model.matrices:
                                st.markdown("**üìà Ma tr·∫≠n Similarity (Top 20 s·∫£n ph·∫©m):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(model.matrices['similarity_matrix'], 
                                           annot=True, fmt='.3f', cmap='coolwarm', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('User-Product Similarity (Top 20)')
                                ax.set_xlabel('Products')
                                ax.set_ylabel('Similarity Score')
                                st.pyplot(fig)
                                st.caption("Similarity scores c·ªßa top 20 s·∫£n ph·∫©m. Gi√° tr·ªã c√†ng cao = s·∫£n ph·∫©m c√†ng ph√π h·ª£p v·ªõi user")
            
        elif model_type == "Hybrid (LightGCN + CBF)":
            lightgcn = LightGCNRecommender()
            cbf = ContentBasedRecommender()
            model = HybridRecommender(lightgcn, cbf)
            
            model.train(train_interactions, products_df)
            st.success(f"‚úÖ Hybrid model trained in {model.training_time:.2f}s")
            
            # Display Algorithm (A-Z) v·ªõi computation steps g·ªôp chung
            with st.expander("üìñ Hybrid Algorithm (A-Z)", expanded=True):
                st.markdown("""
                ### B∆∞·ªõc 1: Train LightGCN Model
                - √Åp d·ª•ng to√†n b·ªô thu·∫≠t to√°n LightGCN (xem ph·∫ßn LightGCN)
                - Input: users (age, gender, interaction_history), products (gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName)
                - K·∫øt qu·∫£: r_gnn = w_type * (e_u^T ¬∑ e_i) (v·ªõi interaction weights, kh√¥ng d√πng rating)
                - Note: LightGCN s·ª≠ d·ª•ng graph structure, productDisplayName ƒë∆∞·ª£c d√πng trong filtering
                
                ### B∆∞·ªõc 2: Train Content-Based Model
                - √Åp d·ª•ng to√†n b·ªô thu·∫≠t to√°n Content-Based (xem ph·∫ßn CBF)
                - Input: products (gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName)
                - K·∫øt qu·∫£: r_cbf = sim(u, i) = (u ¬∑ v_i) / (||u|| * ||v_i||)
                - User profile d·ª±a tr√™n interaction_history (kh√¥ng d√πng rating)
                
                ### B∆∞·ªõc 3: Normalize Scores
                - **C√¥ng th·ª©c:** r_norm = (r - r_min) / (r_max - r_min)
                  - Chu·∫©n h√≥a scores v·ªÅ kho·∫£ng [0, 1]
                
                ### B∆∞·ªõc 4: Weighted Combination
                - **C√¥ng th·ª©c:** r_hybrid = Œ± * r_gnn_norm + (1-Œ±) * r_cbf_norm
                  - Œ±: tr·ªçng s·ªë cho LightGCN (th∆∞·ªùng Œ± = 0.6)
                  - (1-Œ±): tr·ªçng s·ªë cho Content-Based
                  - K·∫øt h·ª£p ∆∞u ƒëi·ªÉm c·ªßa c·∫£ 2 m√¥ h√¨nh
                
                ### B∆∞·ªõc 5: Ranking
                - S·∫Øp x·∫øp s·∫£n ph·∫©m theo r_hybrid gi·∫£m d·∫ßn
                - Ch·ªçn top-K s·∫£n ph·∫©m
                """)
                
                # Hi·ªÉn th·ªã t·ª´ng b∆∞·ªõc v·ªõi c√¥ng th·ª©c, √°p d·ª•ng c√¥ng th·ª©c, gi·∫£i th√≠ch v√† ma tr·∫≠n - g·ªôp ho√†n to√†n
                if lightgcn.computation_steps or cbf.computation_steps:
                    st.markdown("**LightGCN Computation Steps:**")
                    for step_info in lightgcn.computation_steps:
                        with st.expander(f"LightGCN - {step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Ma tr·∫≠n cho LightGCN trong c√°c b∆∞·ªõc t∆∞∆°ng ·ª©ng
                            if 'B∆∞·ªõc 2: Kh·ªüi t·∫°o Embeddings' in step_info['step'] and 'initial_user_embeddings' in lightgcn.matrices:
                                st.markdown("**üìà Ma tr·∫≠n User Embeddings ban ƒë·∫ßu:**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(lightgcn.matrices['initial_user_embeddings'], 
                                           annot=True, fmt='.3f', cmap='viridis', ax=ax)
                                ax.set_title('Initial User Embeddings Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n embeddings ban ƒë·∫ßu c·ªßa 10 users ƒë·∫ßu ti√™n")
                            
                            elif 'B∆∞·ªõc 7: Gradient Descent' in step_info['step'] and 'final_user_embeddings' in lightgcn.matrices:
                                st.markdown("**üìà Ma tr·∫≠n User Embeddings sau training:**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(lightgcn.matrices['final_user_embeddings'], 
                                           annot=True, fmt='.3f', cmap='viridis', ax=ax)
                                ax.set_title('Final User Embeddings Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n embeddings sau training")
                            
                            elif 'B∆∞·ªõc 5: D·ª± ƒëo√°n' in step_info['step'] and 'similarity_matrix' in lightgcn.matrices:
                                st.markdown("**üìà Ma tr·∫≠n Similarity (LightGCN):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(lightgcn.matrices['similarity_matrix'], 
                                           annot=True, fmt='.3f', cmap='coolwarm', ax=ax)
                                ax.set_title('LightGCN Similarity Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n similarity gi·ªØa users v√† products")
                    
                    st.markdown("**Content-Based Computation Steps:**")
                    for step_info in cbf.computation_steps:
                        with st.expander(f"CBF - {step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Ma tr·∫≠n cho CBF trong c√°c b∆∞·ªõc t∆∞∆°ng ·ª©ng
                            if 'B∆∞·ªõc 1' in step_info['step'] and 'TF-IDF' in step_info['step'] and 'tfidf_matrix' in cbf.matrices:
                                st.markdown("**üìà Ma tr·∫≠n TF-IDF:**")
                                fig, ax = plt.subplots(figsize=(12, 8))
                                sns.heatmap(cbf.matrices['tfidf_matrix'], 
                                           annot=False, fmt='.2f', cmap='YlOrRd', ax=ax)
                                ax.set_title('TF-IDF Matrix (Products x Features)')
                                ax.set_xlabel('Features (words)')
                                ax.set_ylabel('Products')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n TF-IDF: m·ªói h√†ng l√† m·ªôt s·∫£n ph·∫©m, m·ªói c·ªôt l√† m·ªôt t·ª´ trong vocabulary")
                            
                            elif 'B∆∞·ªõc 3: T√≠nh Cosine Similarity' in step_info['step'] and 'similarity_matrix' in cbf.matrices:
                                st.markdown("**üìà Ma tr·∫≠n Similarity (CBF):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(cbf.matrices['similarity_matrix'], 
                                           annot=True, fmt='.3f', cmap='coolwarm', ax=ax)
                                ax.set_title('CBF Similarity Matrix (Top 20)')
                                st.pyplot(fig)
                                st.caption("Similarity scores c·ªßa top 20 s·∫£n ph·∫©m")
                    
                    # Display hybrid combination computation
                    with st.expander("B∆∞·ªõc 3 & 4: Normalize Scores & Weighted Combination", expanded=False):
                        st.markdown("""
                        **B∆∞·ªõc 3: Normalize Scores**
                        - **C√¥ng th·ª©c:** r_norm = (r - r_min) / (r_max - r_min)
                        - **V√≠ d·ª•:** N·∫øu r_gnn c√≥ range [0.2, 0.8] v√† r_cbf c√≥ range [0.1, 0.9]
                          - r_gnn_norm = (r_gnn - 0.2) / (0.8 - 0.2) = (r_gnn - 0.2) / 0.6
                          - r_cbf_norm = (r_cbf - 0.1) / (0.9 - 0.1) = (r_cbf - 0.1) / 0.8
                        - **√ù nghƒ©a:** Chu·∫©n h√≥a v·ªÅ c√πng scale [0, 1] ƒë·ªÉ c√≥ th·ªÉ k·∫øt h·ª£p c√¥ng b·∫±ng
                        
                        **B∆∞·ªõc 4: Weighted Combination**
                        - **C√¥ng th·ª©c:** r_hybrid = Œ± * r_gnn_norm + (1-Œ±) * r_cbf_norm
                        - **V√≠ d·ª•:** V·ªõi Œ± = 0.6, n·∫øu r_gnn_norm = 0.7 v√† r_cbf_norm = 0.8
                          - r_hybrid = 0.6 * 0.7 + 0.4 * 0.8 = 0.42 + 0.32 = 0.74
                        - **√ù nghƒ©a:** K·∫øt h·ª£p 60% t·ª´ LightGCN (collaborative) v√† 40% t·ª´ CBF (content-based)
                        """)
                    
                    # Hi·ªÉn th·ªã ma tr·∫≠n trong c√°c b∆∞·ªõc t∆∞∆°ng ·ª©ng c·ªßa LightGCN v√† CBF
                    st.markdown("**LightGCN Computation Steps v·ªõi Ma tr·∫≠n:**")
                    for step_info in lightgcn.computation_steps:
                        with st.expander(f"LightGCN - {step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Ma tr·∫≠n cho LightGCN trong c√°c b∆∞·ªõc t∆∞∆°ng ·ª©ng
                            if 'B∆∞·ªõc 2: Kh·ªüi t·∫°o Embeddings' in step_info['step'] and 'initial_user_embeddings' in lightgcn.matrices:
                                st.markdown("**üìà Ma tr·∫≠n User Embeddings ban ƒë·∫ßu:**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(lightgcn.matrices['initial_user_embeddings'], 
                                           annot=True, fmt='.3f', cmap='viridis', ax=ax)
                                ax.set_title('Initial User Embeddings Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n embeddings ban ƒë·∫ßu c·ªßa 10 users ƒë·∫ßu ti√™n")
                            
                            elif 'B∆∞·ªõc 7: Gradient Descent' in step_info['step'] and 'final_user_embeddings' in lightgcn.matrices:
                                st.markdown("**üìà Ma tr·∫≠n User Embeddings sau training:**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(lightgcn.matrices['final_user_embeddings'], 
                                           annot=True, fmt='.3f', cmap='viridis', ax=ax)
                                ax.set_title('Final User Embeddings Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n embeddings sau training")
                            
                            elif 'B∆∞·ªõc 5: D·ª± ƒëo√°n' in step_info['step'] and 'similarity_matrix' in lightgcn.matrices:
                                st.markdown("**üìà Ma tr·∫≠n Similarity (LightGCN):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(lightgcn.matrices['similarity_matrix'], 
                                           annot=True, fmt='.3f', cmap='coolwarm', ax=ax)
                                ax.set_title('LightGCN Similarity Matrix')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n similarity gi·ªØa users v√† products")
                    
                    st.markdown("**Content-Based Computation Steps v·ªõi Ma tr·∫≠n:**")
                    for step_info in cbf.computation_steps:
                        with st.expander(f"CBF - {step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Ma tr·∫≠n cho CBF trong c√°c b∆∞·ªõc t∆∞∆°ng ·ª©ng
                            if 'B∆∞·ªõc 1' in step_info['step'] and 'TF-IDF' in step_info['step'] and 'tfidf_matrix' in cbf.matrices:
                                st.markdown("**üìà Ma tr·∫≠n TF-IDF:**")
                                fig, ax = plt.subplots(figsize=(12, 8))
                                sns.heatmap(cbf.matrices['tfidf_matrix'], 
                                           annot=False, fmt='.2f', cmap='YlOrRd', ax=ax)
                                ax.set_title('TF-IDF Matrix (Products x Features)')
                                ax.set_xlabel('Features (words)')
                                ax.set_ylabel('Products')
                                st.pyplot(fig)
                                st.caption("Ma tr·∫≠n TF-IDF: m·ªói h√†ng l√† m·ªôt s·∫£n ph·∫©m, m·ªói c·ªôt l√† m·ªôt t·ª´ trong vocabulary")
                            
                            elif 'B∆∞·ªõc 3: T√≠nh Cosine Similarity' in step_info['step'] and 'similarity_matrix' in cbf.matrices:
                                st.markdown("**üìà Ma tr·∫≠n Similarity (CBF):**")
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(cbf.matrices['similarity_matrix'], 
                                           annot=True, fmt='.3f', cmap='coolwarm', ax=ax)
                                ax.set_title('CBF Similarity Matrix (Top 20)')
                                st.pyplot(fig)
                                st.caption("Similarity scores c·ªßa top 20 s·∫£n ph·∫©m")
        
        # Store in session state
        st.session_state['model'] = model
        st.session_state['model_type'] = model_type
        st.session_state['train_interactions'] = train_interactions
        st.session_state['test_interactions'] = test_interactions
    
    # Recommendation section
    if 'model' in st.session_state:
        st.header("üéØ Recommendations")
        
        user = user_dict[selected_user_id]
        user_gender = user.get('gender')
        user_age = user.get('age')
        
        # Get user interactions for training
        user_train_interactions = st.session_state.get('train_interactions', interactions_df)
        user_train_interactions = user_train_interactions[
            user_train_interactions['user_id'] == selected_user_id
        ]
        
        # Generate recommendations
        model = st.session_state['model']
        model_type = st.session_state['model_type']
        
        if model_type == "LightGCN (GNN)":
            recommendations, inference_time = model.recommend(
                selected_user_id, product_dict, top_k=20,
                user_gender=user_gender, user_age=user_age,
                current_product_id=selected_product_id if selected_product_id else None
            )
        elif model_type == "Content-Based Filtering":
            recommendations, inference_time = model.recommend(
                user_train_interactions, products_df, product_dict, top_k=20,
                user_gender=user_gender, user_age=user_age,
                current_product_id=selected_product_id if selected_product_id else None
            )
        else:  # Hybrid
            recommendations, inference_time = model.recommend(
                selected_user_id, user_train_interactions, products_df, product_dict, top_k=20,
                user_gender=user_gender, user_age=user_age,
                current_product_id=selected_product_id if selected_product_id else None
            )
        
        # Personalize recommendations
        st.subheader("üë§ Personalized Recommendations")
        st.markdown("**D·ª±a tr√™n l·ªãch s·ª≠ t∆∞∆°ng t√°c (interaction_history) c·ªßa b·∫°n:**")
        st.info(f"**Th√¥ng tin user:** Tu·ªïi: {user_age}, Gi·ªõi t√≠nh: {user_gender}\n"
                f"**Fields s·ª≠ d·ª•ng:** age, gender, interaction_history (kh√¥ng d√πng rating)")
        
        # Display articleType filter info if a product is selected
        if selected_product_id and selected_product_id in product_dict:
            current_product = product_dict[selected_product_id]
            target_article_type = current_product.get('articleType')
            if target_article_type:
                st.info(f"**üîç R√†ng bu·ªôc quan tr·ªçng nh·∫•t - L·ªçc theo articleType:** {target_article_type} (t·ª´ s·∫£n ph·∫©m payload)")
        
        # Recommendations are already filtered by articleType in the recommend() functions
        filtered_recommendations = recommendations
        
        cols = st.columns(4)
        for idx, (product_id, score) in enumerate(filtered_recommendations[:12]):
            if product_id in product_dict:
                product = product_dict[product_id]
                with cols[idx % 4]:
                    st.markdown(f"**{product.get('productDisplayName', 'N/A')[:30]}...**")
                    st.caption(f"Score: {score:.4f}")
                    st.caption(f"Category: {product.get('subCategory', 'N/A')}")
                    st.caption(f"ArticleType: {product.get('articleType', 'N/A')}")
                    st.caption(f"Color: {product.get('baseColour', 'N/A')}")
        
        # Outfit recommendations
        if selected_product_id and selected_product_id in product_dict:
            st.subheader("üëî Outfit Recommendations")
            st.markdown("**C√°c s·∫£n ph·∫©m ƒëi k√®m ƒë·ªÉ t·∫°o b·ªô trang ph·ª•c ho√†n ch·ªânh:**")
            
            current_product = product_dict[selected_product_id]
            outfit_recs = recommend_outfit(
                current_product, product_dict, user_gender=user_gender, user_age=user_age
            )
            
            for category, items in outfit_recs.items():
                if items:
                    st.markdown(f"**{category.upper()}:**")
                    cols = st.columns(min(5, len(items)))
                    for idx, (pid, product) in enumerate(items):
                        with cols[idx]:
                            st.markdown(f"‚Ä¢ {product.get('productDisplayName', 'N/A')[:25]}...")
                            st.caption(f"{product.get('articleType', 'N/A')}")
        
        # Evaluation metrics
        st.subheader("üìä Evaluation Metrics")
        
        # Get test interactions for this user
        test_interactions = st.session_state.get('test_interactions', pd.DataFrame())
        user_test_interactions = test_interactions[
            test_interactions['user_id'] == selected_user_id
        ]
        
        if len(user_test_interactions) > 0:
            metrics = evaluate_model(recommendations, user_test_interactions, k_values=[10, 20])
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Recall@10", f"{metrics['recall_at_10']:.4f}")
            with col2:
                st.metric("Recall@20", f"{metrics['recall_at_20']:.4f}")
            with col3:
                st.metric("NDCG@10", f"{metrics['ndcg_at_10']:.4f}")
            with col4:
                st.metric("NDCG@20", f"{metrics['ndcg_at_20']:.4f}")
            
            # Explanation
            with st.expander("üìñ Gi·∫£i th√≠ch Metrics"):
                st.markdown("""
                **Recall@K:**
                - **C√¥ng th·ª©c:** Recall@K = |R ‚à© T| / |T|
                  - R: t·∫≠p s·∫£n ph·∫©m ƒë∆∞·ª£c recommend trong top-K
                  - T: t·∫≠p s·∫£n ph·∫©m th·ª±c t·∫ø user ƒë√£ t∆∞∆°ng t√°c (ground truth)
                - **√ù nghƒ©a:** T·ª∑ l·ªá s·∫£n ph·∫©m relevant ƒë∆∞·ª£c t√¨m th·∫•y trong top-K
                - **V√≠ d·ª•:** N·∫øu user ƒë√£ mua 10 s·∫£n ph·∫©m v√† h·ªá th·ªëng recommend ƒë√∫ng 7 trong top-10 ‚Üí Recall@10 = 0.7
                
                **NDCG@K (Normalized Discounted Cumulative Gain):**
                - **C√¥ng th·ª©c:** NDCG@K = DCG@K / IDCG@K
                  - DCG@K = Œ£ (rel_i / log‚ÇÇ(i+1)) v·ªõi i t·ª´ 1 ƒë·∫øn K
                  - IDCG@K: DCG l√Ω t∆∞·ªüng (t·∫•t c·∫£ relevant items x·∫øp ƒë·∫ßu)
                - **√ù nghƒ©a:** ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ranking, ∆∞u ti√™n items relevant ·ªü v·ªã tr√≠ cao
                - **V√≠ d·ª•:** NDCG@10 = 0.8 nghƒ©a l√† ranking t·ªët 80% so v·ªõi ranking l√Ω t∆∞·ªüng
                """)
        
        st.info(f"‚è±Ô∏è Inference time: {inference_time*1000:.2f}ms")
    
    # Model comparison table - Run test_model_comparison.py and read results
    if st.sidebar.button("üìà Compare All Models"):
        st.header("üìä Model Comparison")
        
        # Run test_model_comparison.py as a subprocess
        import subprocess
        import json
        import os
        
        results_file = 'model_comparison_results.json'
        
        # Show progress
        status_placeholder = st.empty()
        status_placeholder.info("üîÑ ƒêang ch·∫°y test_model_comparison.py...")
        
        try:
            # Get Python executable from current environment (venv)
            python_exe = sys.executable
            
            # If not using venv Python, try to find venv Python
            if 'venv' not in python_exe and 'virtualenv' not in python_exe:
                venv_python = Path(__file__).parent / 'venv' / 'Scripts' / 'python.exe'
                if venv_python.exists():
                    python_exe = str(venv_python)
                    st.info(f"üîß T√¨m th·∫•y venv Python: {python_exe}")
                else:
                    # Try Linux/Mac venv path
                    venv_python = Path(__file__).parent / 'venv' / 'bin' / 'python'
                    if venv_python.exists():
                        python_exe = str(venv_python)
                        st.info(f"üîß T√¨m th·∫•y venv Python: {python_exe}")
            
            # Debug info
            st.info(f"üîß S·ª≠ d·ª•ng Python: {python_exe}")
            
            # Run test_model_comparison.py using the same Python interpreter
            result = subprocess.run(
                [python_exe, 'test_model_comparison.py'],
                capture_output=True,
                text=True,
                cwd=Path(__file__).parent,
                timeout=300,  # 5 minutes timeout
                env=os.environ.copy()  # Pass current environment variables
            )
            
            if result.returncode != 0:
                st.error(f"‚ùå L·ªói khi ch·∫°y test_model_comparison.py (exit code: {result.returncode})")
                if result.stderr:
                    st.error("**Stderr:**")
                    st.code(result.stderr, language='text')
                if result.stdout:
                    st.info("**Stdout:**")
                    st.code(result.stdout, language='text')
                return
            
            # Check if results file exists
            if not os.path.exists(results_file):
                st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file k·∫øt qu·∫£: {results_file}")
                st.info("Ki·ªÉm tra output t·ª´ test_model_comparison.py:")
                st.code(result.stdout, language='text')
                return
            
            # Read results from JSON file
            with open(results_file, 'r', encoding='utf-8') as f:
                results_data = json.load(f)
            
            status_placeholder.success("‚úÖ ƒê√£ ho√†n th√†nh ƒë√°nh gi√°!")
            status_placeholder.empty()
            
            # Convert back to DataFrame
            comparison_df = pd.DataFrame(results_data['comparison_df'])
            score_df = pd.DataFrame(results_data['weighted_scores'])
            best_model = results_data['best_model']
            best_score = results_data['best_score']
            issues = results_data.get('issues', [])
            model_algorithms = results_data.get('model_algorithms', {})
            
            # Display comparison table
            st.subheader("üìä B·∫£ng So S√°nh Chi Ti·∫øt 3 M√¥ H√¨nh")
            
            # Round numeric columns
            numeric_cols = comparison_df.select_dtypes(include=[np.number]).columns
            comparison_df[numeric_cols] = comparison_df[numeric_cols].round(4)
            
            # Remove debug columns for display
            display_cols = ['Model', 'Recall@10', 'Recall@20', 'NDCG@10', 'NDCG@20', 
                           'Precision@10', 'Precision@20', 'Training Time (s)', 
                           'Inference Time (ms)', 'Coverage (%)', 'Diversity (ArticleTypes)']
            available_cols = [col for col in display_cols if col in comparison_df.columns]
            display_df = comparison_df[available_cols].copy()
            
            st.dataframe(display_df, use_container_width=True, height=200)
            
            # Algorithm (A-Z) cho t·ª´ng m√¥ h√¨nh: Train ‚Üí Recommend ‚Üí T√≠nh Metrics
            st.subheader("üìñ Algorithm (A-Z) cho t·ª´ng M√¥ h√¨nh: Train ‚Üí Recommend ‚Üí T√≠nh Metrics")
            
            # LightGCN Algorithm
            with st.expander("üî∑ LightGCN (Graph Neural Network) - Algorithm (A-Z)", expanded=False):
                # Hi·ªÉn th·ªã th√¥ng tin Train/Test Split
                if 'train_stats' in results_data:
                    train_stats = results_data['train_stats']
                    st.markdown("### üìä Th√¥ng tin Train/Test Split")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Train Interactions", f"{train_stats.get('train_size', 0):,}")
                    with col2:
                        st.metric("Test Interactions", f"{train_stats.get('test_size', 0):,}")
                    with col3:
                        train_ratio = train_stats.get('train_ratio', 0.8) * 100
                        st.metric("Train Ratio", f"{train_ratio:.1f}%")
                    
                    st.info(f"**Chi ti·∫øt:** {train_stats.get('train_users', 0)} users trong train set, {train_stats.get('test_users', 0)} users trong test set")
                
                # Hi·ªÉn th·ªã Test Pairs (user_id, product_id ƒë∆∞·ª£c test)
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    st.markdown("### üß™ Test Pairs (User-Product ƒë∆∞·ª£c test)")
                    test_pairs_df = pd.DataFrame(results_data['test_pairs'])
                    st.dataframe(test_pairs_df, use_container_width=True, height=200)
                    st.caption(f"**T·ªïng s·ªë test pairs:** {len(results_data['test_pairs'])}")
                
                # Hi·ªÉn th·ªã Sample Train/Test Data
                if 'sample_train_data' in results_data and len(results_data['sample_train_data']) > 0:
                    st.markdown("### üìö Sample Train Set Data (10 d√≤ng ƒë·∫ßu)")
                    train_df = pd.DataFrame(results_data['sample_train_data'])
                    st.dataframe(train_df, use_container_width=True, height=200)
                
                if 'sample_test_data' in results_data and len(results_data['sample_test_data']) > 0:
                    st.markdown("### üß™ Sample Test Set Data (10 d√≤ng ƒë·∫ßu)")
                    test_df = pd.DataFrame(results_data['sample_test_data'])
                    st.dataframe(test_df, use_container_width=True, height=200)
                
                # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b∆∞·ªõc li√™n t·ª•c t·ª´ B∆∞·ªõc 1 ƒë·∫øn B∆∞·ªõc n
                all_steps = []
                
                # L·∫•y c√°c b∆∞·ªõc t·ª´ computation_steps
                if 'LightGCN' in model_algorithms and 'computation_steps' in model_algorithms['LightGCN']:
                    seen_steps = set()
                    for step_info in model_algorithms['LightGCN']['computation_steps']:
                        step_name = step_info.get('step', '')
                        if step_name and step_name not in seen_steps:
                            seen_steps.add(step_name)
                            all_steps.append(step_info)
                
                # Th√™m c√°c b∆∞·ªõc recommendation v√† evaluation
                # L·∫•y example user_id v√† product_id t·ª´ test_pairs
                example_user_id = ""
                example_product_id = ""
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    example_user_id = results_data['test_pairs'][0].get('user_id', '')
                    example_product_id = results_data['test_pairs'][0].get('product_id', '')
                
                recommendation_steps = [
                    {
                        'step': 'B∆∞·ªõc 8: T√≠nh Score cho t·∫•t c·∫£ Products',
                        'formula': 'rÃÇ_ui = e_u^T ¬∑ e_i',
                        'computation': f'**Test v·ªõi:** User ID = {example_user_id}, Product ID = {example_product_id}\n'
                                      f'V·ªõi user {example_user_id}, t√≠nh score cho t·∫•t c·∫£ products\n'
                                      f'V√≠ d·ª•: Product {example_product_id}: score = e_user^T ¬∑ e_{example_product_id} = 0.523',
                        'meaning': 'T√≠nh predicted score cho m·ªói product b·∫±ng dot product c·ªßa user embedding v√† product embedding'
                    },
                    {
                        'step': 'B∆∞·ªõc 9: L·ªçc theo articleType v√† Gender',
                        'formula': 'Filter by articleType (MANDATORY), gender, age',
                        'computation': f'**Test v·ªõi:** User ID = {example_user_id}, Product ID = {example_product_id}\n'
                                      f'1. L·ªçc theo articleType (ph·∫£i kh·ªõp v·ªõi current_product = {example_product_id})\n'
                                      f'2. L·ªçc theo gender compatibility\n'
                                      f'3. L·ªçc theo age (n·∫øu ‚â§ 12 ch·ªâ cho Boys/Girls/Unisex)',
                        'meaning': '√Åp d·ª•ng c√°c filters ƒë·ªÉ ƒë·∫£m b·∫£o recommendations ph√π h·ª£p v·ªõi user v√† s·∫£n ph·∫©m hi·ªán t·∫°i'
                    },
                    {
                        'step': 'B∆∞·ªõc 10: Ranking v√† Ch·ªçn Top-K',
                        'formula': 'Rank products by rÃÇ_ui descending, ch·ªçn top-K',
                        'computation': f'**Test v·ªõi:** User ID = {example_user_id}, Product ID = {example_product_id}\n'
                                      f'S·∫Øp x·∫øp products theo score gi·∫£m d·∫ßn\n'
                                      f'Ch·ªçn top-20 products\n'
                                      f'V√≠ d·ª•: [{example_product_id}: 0.523, 10065: 0.456, 10859: 0.389, ...]',
                        'meaning': 'S·∫Øp x·∫øp v√† ch·ªçn top-K s·∫£n ph·∫©m c√≥ score cao nh·∫•t ƒë·ªÉ recommend'
                    }
                ]
                
                evaluation_steps = []
                recall_20 = comparison_df[comparison_df['Model'] == 'LightGCN']['Recall@20'].values[0] if len(comparison_df[comparison_df['Model'] == 'LightGCN']) > 0 else 0
                ndcg_20 = comparison_df[comparison_df['Model'] == 'LightGCN']['NDCG@20'].values[0] if len(comparison_df[comparison_df['Model'] == 'LightGCN']) > 0 else 0
                precision_20 = comparison_df[comparison_df['Model'] == 'LightGCN']['Precision@20'].values[0] if len(comparison_df[comparison_df['Model'] == 'LightGCN']) > 0 else 0
                
                # L·∫•y th√¥ng tin test pairs ƒë·ªÉ hi·ªÉn th·ªã trong evaluation
                test_pairs_info_str = ""
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    test_pairs_list = []
                    for pair in results_data['test_pairs'][:5]:  # Hi·ªÉn th·ªã 5 pairs ƒë·∫ßu
                        test_pairs_list.append(f"User {pair.get('user_id', '')} - Product {pair.get('product_id', '')}")
                    test_pairs_info_str = f"\n**Test v·ªõi c√°c pairs:**\n" + "\n".join(test_pairs_list)
                
                # L·∫•y th√¥ng tin train/test data
                train_data_info = ""
                test_data_info = ""
                if 'sample_train_data' in results_data and len(results_data['sample_train_data']) > 0:
                    train_data_info = f"\n**Sample Train Data (3 d√≤ng ƒë·∫ßu):**\n"
                    for i, row in enumerate(results_data['sample_train_data'][:3]):
                        train_data_info += f"  {i+1}. User {row.get('user_id', '')} - Product {row.get('product_id', '')} - {row.get('interaction_type', 'view')}\n"
                
                if 'sample_test_data' in results_data and len(results_data['sample_test_data']) > 0:
                    test_data_info = f"\n**Sample Test Data (3 d√≤ng ƒë·∫ßu):**\n"
                    for i, row in enumerate(results_data['sample_test_data'][:3]):
                        test_data_info += f"  {i+1}. User {row.get('user_id', '')} - Product {row.get('product_id', '')} - {row.get('interaction_type', 'view')}\n"
                
                evaluation_steps = [
                    {
                        'step': 'B∆∞·ªõc 11: T√≠nh Recall@K',
                        'formula': 'Recall@K = |R ‚à© T| / |T|',
                        'computation': f'**Test v·ªõi:** User ID = {example_user_id}, Product ID = {example_product_id}{test_pairs_info_str}{test_data_info}\n'
                                      f'LightGCN Recall@20 = {recall_20:.4f}\n'
                                      f'Nghƒ©a l√†: Trong top-20 recommendations, t√¨m th·∫•y {recall_20*100:.1f}% s·∫£n ph·∫©m trong test set',
                        'meaning': f'T·ª∑ l·ªá s·∫£n ph·∫©m relevant ƒë∆∞·ª£c t√¨m th·∫•y trong top-K recommendations'
                    },
                    {
                        'step': 'B∆∞·ªõc 12: T√≠nh NDCG@K',
                        'formula': 'NDCG@K = DCG@K / IDCG@K',
                        'computation': f'**Test v·ªõi:** User ID = {example_user_id}, Product ID = {example_product_id}{test_pairs_info_str}{test_data_info}\n'
                                      f'LightGCN NDCG@20 = {ndcg_20:.4f}\n'
                                      f'Nghƒ©a l√†: Ranking t·ªët {ndcg_20*100:.1f}% so v·ªõi ranking l√Ω t∆∞·ªüng',
                        'meaning': 'ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng ranking, ∆∞u ti√™n items relevant ·ªü v·ªã tr√≠ cao'
                    },
                    {
                        'step': 'B∆∞·ªõc 13: T√≠nh Precision@K',
                        'formula': 'Precision@K = |R ‚à© T| / K',
                        'computation': f'**Test v·ªõi:** User ID = {example_user_id}, Product ID = {example_product_id}{test_pairs_info_str}{test_data_info}\n'
                                      f'LightGCN Precision@20 = {precision_20:.4f}\n'
                                      f'Nghƒ©a l√†: {precision_20*100:.1f}% recommendations trong top-20 l√† relevant',
                        'meaning': 'T·ª∑ l·ªá recommendations l√† relevant trong top-K'
                    }
                ]
                
                # G·ªôp t·∫•t c·∫£ c√°c b∆∞·ªõc
                all_steps.extend(recommendation_steps)
                all_steps.extend(evaluation_steps)
                
                # S·∫Øp x·∫øp c√°c b∆∞·ªõc theo s·ªë th·ª© t·ª± - extract s·ªë ch√≠nh x√°c sau "B∆∞·ªõc "
                def get_step_number(step_name):
                    # T√¨m s·ªë sau "B∆∞·ªõc " b·∫±ng regex
                    import re
                    match = re.search(r'B∆∞·ªõc\s+(\d+)', step_name)
                    if match:
                        return int(match.group(1))
                    return 999
                
                all_steps.sort(key=lambda x: get_step_number(x.get('step', '')))
                
                # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b∆∞·ªõc li√™n t·ª•c
                for step_info in all_steps:
                        with st.expander(f"{step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                        # Hi·ªÉn th·ªã ma tr·∫≠n n·∫øu c√≥ - c·∫£ b·∫£ng v√† ƒë·ªì th·ªã
                        if 'LightGCN' in model_algorithms and 'matrices' in model_algorithms['LightGCN']:
                                if 'B∆∞·ªõc 2: Kh·ªüi t·∫°o Embeddings' in step_info['step'] and 'initial_user_embeddings' in model_algorithms['LightGCN']['matrices']:
                                    st.markdown("**üìà Ma tr·∫≠n User Embeddings ban ƒë·∫ßu:**")
                                    matrix_data = np.array(model_algorithms['LightGCN']['matrices']['initial_user_embeddings'])
                                
                                # Hi·ªÉn th·ªã b·∫£ng
                                matrix_df = pd.DataFrame(matrix_data, 
                                                         index=[f'User {i+1}' for i in range(matrix_data.shape[0])],
                                                         columns=[f'Dim {j+1}' for j in range(matrix_data.shape[1])])
                                st.dataframe(matrix_df.style.format("{:.3f}"), use_container_width=True, height=300)
                                
                                # Hi·ªÉn th·ªã ƒë·ªì th·ªã
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(matrix_data, annot=True, fmt='.3f', cmap='viridis', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('Initial User Embeddings Matrix (Heatmap)')
                                st.pyplot(fig)
                                
                                elif 'B∆∞·ªõc 7: Gradient Descent' in step_info['step'] and 'final_user_embeddings' in model_algorithms['LightGCN']['matrices']:
                                    st.markdown("**üìà Ma tr·∫≠n User Embeddings sau training:**")
                                    matrix_data = np.array(model_algorithms['LightGCN']['matrices']['final_user_embeddings'])
                                
                                # Hi·ªÉn th·ªã b·∫£ng
                                matrix_df = pd.DataFrame(matrix_data,
                                                         index=[f'User {i+1}' for i in range(matrix_data.shape[0])],
                                                         columns=[f'Dim {j+1}' for j in range(matrix_data.shape[1])])
                                st.dataframe(matrix_df.style.format("{:.3f}"), use_container_width=True, height=300)
                                
                                # Hi·ªÉn th·ªã ƒë·ªì th·ªã
                                fig, ax = plt.subplots(figsize=(8, 6))
                                sns.heatmap(matrix_data, annot=True, fmt='.3f', cmap='viridis', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('Final User Embeddings Matrix (Heatmap)')
                                st.pyplot(fig)
                                
                                elif 'B∆∞·ªõc 5: D·ª± ƒëo√°n' in step_info['step'] and 'similarity_matrix' in model_algorithms['LightGCN']['matrices']:
                                    st.markdown("**üìà Ma tr·∫≠n Similarity (User x Product):**")
                                    matrix_data = np.array(model_algorithms['LightGCN']['matrices']['similarity_matrix'])
                                
                                # Hi·ªÉn th·ªã b·∫£ng
                                matrix_df = pd.DataFrame(matrix_data,
                                                         index=[f'User {i+1}' for i in range(matrix_data.shape[0])],
                                                         columns=[f'Product {j+1}' for j in range(matrix_data.shape[1])])
                                st.dataframe(matrix_df.style.format("{:.3f}"), use_container_width=True, height=300)
                                
                                # Hi·ªÉn th·ªã ƒë·ªì th·ªã
                                fig, ax = plt.subplots(figsize=(10, 8))
                                sns.heatmap(matrix_data, annot=True, fmt='.3f', cmap='coolwarm', ax=ax,
                                           xticklabels=False, yticklabels=False)
                                ax.set_title('User-Product Similarity Matrix (Heatmap)')
                                st.pyplot(fig)
            
            # Content-Based Algorithm
            with st.expander("üî∑ Content-Based Filtering - Algorithm (A-Z)", expanded=False):
                # Hi·ªÉn th·ªã th√¥ng tin Train/Test Split
                if 'train_stats' in results_data:
                    train_stats = results_data['train_stats']
                    st.markdown("### üìä Th√¥ng tin Train/Test Split")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Train Interactions", f"{train_stats.get('train_size', 0):,}")
                    with col2:
                        st.metric("Test Interactions", f"{train_stats.get('test_size', 0):,}")
                    with col3:
                        train_ratio = train_stats.get('train_ratio', 0.8) * 100
                        st.metric("Train Ratio", f"{train_ratio:.1f}%")
                    
                    st.info(f"**Chi ti·∫øt:** {train_stats.get('train_users', 0)} users trong train set, {train_stats.get('test_users', 0)} users trong test set")
                
                # Hi·ªÉn th·ªã Test Pairs (user_id, product_id ƒë∆∞·ª£c test)
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    st.markdown("### üß™ Test Pairs (User-Product ƒë∆∞·ª£c test)")
                    test_pairs_df = pd.DataFrame(results_data['test_pairs'])
                    st.dataframe(test_pairs_df, use_container_width=True, height=200)
                    st.caption(f"**T·ªïng s·ªë test pairs:** {len(results_data['test_pairs'])}")
                
                # Hi·ªÉn th·ªã Sample Train/Test Data
                if 'sample_train_data' in results_data and len(results_data['sample_train_data']) > 0:
                    st.markdown("### üìö Sample Train Set Data (10 d√≤ng ƒë·∫ßu)")
                    train_df = pd.DataFrame(results_data['sample_train_data'])
                    st.dataframe(train_df, use_container_width=True, height=200)
                
                if 'sample_test_data' in results_data and len(results_data['sample_test_data']) > 0:
                    st.markdown("### üß™ Sample Test Set Data (10 d√≤ng ƒë·∫ßu)")
                    test_df = pd.DataFrame(results_data['sample_test_data'])
                    st.dataframe(test_df, use_container_width=True, height=200)
                
                # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b∆∞·ªõc li√™n t·ª•c t·ª´ B∆∞·ªõc 1 ƒë·∫øn B∆∞·ªõc n
                if 'Content-Based' in model_algorithms and 'computation_steps' in model_algorithms['Content-Based']:
                    # Lo·∫°i b·ªè c√°c b∆∞·ªõc tr√πng l·∫∑p v√† s·∫Øp x·∫øp theo th·ª© t·ª±
                    seen_steps = set()
                    all_steps = []
                    
                    for step_info in model_algorithms['Content-Based']['computation_steps']:
                        step_name = step_info.get('step', '')
                        if step_name and step_name not in seen_steps:
                            seen_steps.add(step_name)
                            all_steps.append(step_info)
                    
                    # S·∫Øp x·∫øp c√°c b∆∞·ªõc theo s·ªë th·ª© t·ª± - extract s·ªë ch√≠nh x√°c sau "B∆∞·ªõc "
                    def get_step_number(step_name):
                        # T√¨m s·ªë sau "B∆∞·ªõc " b·∫±ng regex
                        import re
                        match = re.search(r'B∆∞·ªõc\s+(\d+)', step_name)
                        if match:
                            return int(match.group(1))
                        return 999
                    
                    all_steps.sort(key=lambda x: get_step_number(x.get('step', '')))
                    
                    # Hi·ªÉn th·ªã t·∫•t c·∫£ c√°c b∆∞·ªõc li√™n t·ª•c
                    for step_info in all_steps:
                        with st.expander(f"{step_info['step']}", expanded=False):
                            st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                            st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                            st.code(step_info['computation'], language='text')
                            st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                            
                            # Hi·ªÉn th·ªã ma tr·∫≠n n·∫øu c√≥ - c·∫£ b·∫£ng v√† ƒë·ªì th·ªã
                            if 'matrices' in model_algorithms['Content-Based']:
                                if 'TF-IDF' in step_info['step'] and 'tfidf_matrix' in model_algorithms['Content-Based']['matrices']:
                                    st.markdown("**üìà Ma tr·∫≠n TF-IDF:**")
                                    matrix_data = np.array(model_algorithms['Content-Based']['matrices']['tfidf_matrix'])
                                    
                                    # Hi·ªÉn th·ªã b·∫£ng (ch·ªâ hi·ªÉn th·ªã m·ªôt ph·∫ßn nh·ªè ƒë·ªÉ tr√°nh qu√° l·ªõn)
                                    max_rows = min(20, matrix_data.shape[0])
                                    max_cols = min(20, matrix_data.shape[1])
                                    matrix_df = pd.DataFrame(matrix_data[:max_rows, :max_cols],
                                                             index=[f'Product {i+1}' for i in range(max_rows)],
                                                             columns=[f'Feature {j+1}' for j in range(max_cols)])
                                    st.dataframe(matrix_df.style.format("{:.3f}"), use_container_width=True, height=400)
                                    if matrix_data.shape[0] > max_rows or matrix_data.shape[1] > max_cols:
                                        st.caption(f"*Hi·ªÉn th·ªã {max_rows}x{max_cols} ƒë·∫ßu ti√™n c·ªßa ma tr·∫≠n {matrix_data.shape[0]}x{matrix_data.shape[1]}*")
                                    
                                    # Hi·ªÉn th·ªã ƒë·ªì th·ªã
                                    fig, ax = plt.subplots(figsize=(12, 8))
                                    sns.heatmap(matrix_data, annot=False, fmt='.2f', cmap='YlOrRd', ax=ax,
                                               xticklabels=False, yticklabels=False)
                                    ax.set_title('TF-IDF Matrix (Products x Features) - Heatmap')
                                    st.pyplot(fig)
                                
                                elif 'Cosine Similarity' in step_info['step'] and 'similarity_matrix' in model_algorithms['Content-Based']['matrices']:
                                    st.markdown("**üìà Ma tr·∫≠n Similarity:**")
                                    matrix_data = np.array(model_algorithms['Content-Based']['matrices']['similarity_matrix'])
                                    
                                    # Hi·ªÉn th·ªã b·∫£ng
                                    if len(matrix_data.shape) == 1:
                                        # 1D array - similarity scores
                                        matrix_df = pd.DataFrame(matrix_data.reshape(-1, 1),
                                                                 index=[f'Product {i+1}' for i in range(matrix_data.shape[0])],
                                                                 columns=['Similarity Score'])
                                    else:
                                        matrix_df = pd.DataFrame(matrix_data,
                                                                 index=[f'Product {i+1}' for i in range(matrix_data.shape[0])],
                                                                 columns=[f'Dim {j+1}' for j in range(matrix_data.shape[1])])
                                    st.dataframe(matrix_df.style.format("{:.3f}"), use_container_width=True, height=300)
                                    
                                    # Hi·ªÉn th·ªã ƒë·ªì th·ªã
                                    fig, ax = plt.subplots(figsize=(8, 6))
                                    if len(matrix_data.shape) == 1:
                                        sns.heatmap(matrix_data.reshape(-1, 1), annot=True, fmt='.3f', cmap='coolwarm', ax=ax,
                                                   xticklabels=False, yticklabels=False)
                                    else:
                                    sns.heatmap(matrix_data, annot=True, fmt='.3f', cmap='coolwarm', ax=ax,
                                               xticklabels=False, yticklabels=False)
                                    ax.set_title('User-Product Similarity Matrix - Heatmap')
                                    st.pyplot(fig)
                
                # Hi·ªÉn th·ªã b∆∞·ªõc Evaluation (B∆∞·ªõc 6) v·ªõi th√¥ng tin test pairs
                # L·∫•y example user_id v√† product_id t·ª´ test_pairs
                cbf_example_user_id = ""
                cbf_example_product_id = ""
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    cbf_example_user_id = results_data['test_pairs'][0].get('user_id', '')
                    cbf_example_product_id = results_data['test_pairs'][0].get('product_id', '')
                
                # L·∫•y th√¥ng tin test pairs v√† train/test data
                cbf_test_pairs_info_str = ""
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    test_pairs_list = []
                    for pair in results_data['test_pairs'][:5]:
                        test_pairs_list.append(f"User {pair.get('user_id', '')} - Product {pair.get('product_id', '')}")
                    cbf_test_pairs_info_str = f"\n**Test v·ªõi c√°c pairs:**\n" + "\n".join(test_pairs_list)
                
                cbf_train_data_info = ""
                cbf_test_data_info = ""
                if 'sample_train_data' in results_data and len(results_data['sample_train_data']) > 0:
                    cbf_train_data_info = f"\n**Sample Train Data (3 d√≤ng ƒë·∫ßu):**\n"
                    for i, row in enumerate(results_data['sample_train_data'][:3]):
                        cbf_train_data_info += f"  {i+1}. User {row.get('user_id', '')} - Product {row.get('product_id', '')} - {row.get('interaction_type', 'view')}\n"
                
                if 'sample_test_data' in results_data and len(results_data['sample_test_data']) > 0:
                    cbf_test_data_info = f"\n**Sample Test Data (3 d√≤ng ƒë·∫ßu):**\n"
                    for i, row in enumerate(results_data['sample_test_data'][:3]):
                        cbf_test_data_info += f"  {i+1}. User {row.get('user_id', '')} - Product {row.get('product_id', '')} - {row.get('interaction_type', 'view')}\n"
                
                with st.expander("B∆∞·ªõc 6: T√≠nh Recall@K, NDCG@K, Precision@K", expanded=False):
                    cbf_row = comparison_df[comparison_df['Model'] == 'Content-Based']
                    if len(cbf_row) > 0:
                        cbf_recall = cbf_row['Recall@20'].values[0]
                        cbf_ndcg = cbf_row['NDCG@20'].values[0]
                        cbf_precision = cbf_row['Precision@20'].values[0]
                        st.markdown(f"""
                        **Test v·ªõi:** User ID = {cbf_example_user_id}, Product ID = {cbf_example_product_id}{cbf_test_pairs_info_str}{cbf_train_data_info}{cbf_test_data_info}
                        
                        **√Åp d·ª•ng c√¥ng th·ª©c v·ªõi s·ªë li·ªáu th·ª±c t·∫ø:**
                        - Recall@20 = {cbf_recall:.4f} ‚Üí T√¨m th·∫•y {cbf_recall*100:.1f}% relevant items
                        - NDCG@20 = {cbf_ndcg:.4f} ‚Üí Ranking t·ªët {cbf_ndcg*100:.1f}% so v·ªõi l√Ω t∆∞·ªüng
                        - Precision@20 = {cbf_precision:.4f} ‚Üí {cbf_precision*100:.1f}% recommendations l√† relevant
                        """)
            
            # Hybrid Algorithm
            with st.expander("üî∑ Hybrid (LightGCN + CBF) - Algorithm (A-Z)", expanded=False):
                # Hi·ªÉn th·ªã th√¥ng tin Train/Test Split
                if 'train_stats' in results_data:
                    train_stats = results_data['train_stats']
                    st.markdown("### üìä Th√¥ng tin Train/Test Split")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Train Interactions", f"{train_stats.get('train_size', 0):,}")
                    with col2:
                        st.metric("Test Interactions", f"{train_stats.get('test_size', 0):,}")
                    with col3:
                        train_ratio = train_stats.get('train_ratio', 0.8) * 100
                        st.metric("Train Ratio", f"{train_ratio:.1f}%")
                    
                    st.info(f"**Chi ti·∫øt:** {train_stats.get('train_users', 0)} users trong train set, {train_stats.get('test_users', 0)} users trong test set")
                
                # Hi·ªÉn th·ªã Test Pairs (user_id, product_id ƒë∆∞·ª£c test)
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    st.markdown("### üß™ Test Pairs (User-Product ƒë∆∞·ª£c test)")
                    test_pairs_df = pd.DataFrame(results_data['test_pairs'])
                    st.dataframe(test_pairs_df, use_container_width=True, height=200)
                    st.caption(f"**T·ªïng s·ªë test pairs:** {len(results_data['test_pairs'])}")
                
                # Hi·ªÉn th·ªã Sample Train/Test Data
                if 'sample_train_data' in results_data and len(results_data['sample_train_data']) > 0:
                    st.markdown("### üìö Sample Train Set Data (10 d√≤ng ƒë·∫ßu)")
                    train_df = pd.DataFrame(results_data['sample_train_data'])
                    st.dataframe(train_df, use_container_width=True, height=200)
                
                if 'sample_test_data' in results_data and len(results_data['sample_test_data']) > 0:
                    st.markdown("### üß™ Sample Test Set Data (10 d√≤ng ƒë·∫ßu)")
                    test_df = pd.DataFrame(results_data['sample_test_data'])
                    st.dataframe(test_df, use_container_width=True, height=200)
                
                st.markdown("### üìö Ph·∫ßn 1: Training Phase")
                
                # Hi·ªÉn th·ªã computation_steps t·ª´ model_algorithms n·∫øu c√≥
                if 'Hybrid' in model_algorithms:
                    hybrid_data = model_algorithms['Hybrid']
                    alpha = hybrid_data.get('alpha', 0.5)
                    
                    st.markdown("""
                    **B∆∞·ªõc 1: Train LightGCN Model**
                    - √Åp d·ª•ng to√†n b·ªô thu·∫≠t to√°n LightGCN (xem ph·∫ßn LightGCN ·ªü tr√™n)
                    - Input: users (age, gender, interaction_history), products (gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName)
                    - K·∫øt qu·∫£: r_gnn = w_type * (e_u^T ¬∑ e_i) (v·ªõi interaction weights, kh√¥ng d√πng rating)
                    """)
                    
                    # Hi·ªÉn th·ªã LightGCN steps n·∫øu c√≥
                    if 'lightgcn_steps' in hybrid_data:
                        with st.expander("LightGCN Computation Steps (trong Hybrid)", expanded=False):
                            for step_info in hybrid_data['lightgcn_steps']:
                                with st.expander(f"LightGCN - {step_info['step']}", expanded=False):
                                    st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                                    st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                                    st.code(step_info['computation'], language='text')
                                    st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                    
                    st.markdown("""
                    **B∆∞·ªõc 2: Train Content-Based Model**
                    - √Åp d·ª•ng to√†n b·ªô thu·∫≠t to√°n Content-Based (xem ph·∫ßn CBF ·ªü tr√™n)
                    - Input: products (gender, masterCategory, subCategory, articleType, baseColour, usage, productDisplayName)
                    - K·∫øt qu·∫£: r_cbf = sim(u, i) = (u ¬∑ v_i) / (||u|| * ||v_i||)
                    """)
                    
                    # Hi·ªÉn th·ªã CBF steps n·∫øu c√≥
                    if 'cbf_steps' in hybrid_data:
                        with st.expander("Content-Based Computation Steps (trong Hybrid)", expanded=False):
                            for step_info in hybrid_data['cbf_steps']:
                                with st.expander(f"CBF - {step_info['step']}", expanded=False):
                                    st.markdown(f"**C√¥ng th·ª©c:** `{step_info['formula']}`")
                                    st.markdown(f"**√Åp d·ª•ng c√¥ng th·ª©c:**")
                                    st.code(step_info['computation'], language='text')
                                    st.markdown(f"**Gi·∫£i th√≠ch √Ω nghƒ©a:** {step_info['meaning']}")
                else:
                    # Fallback to static content if no model_algorithms
                    with st.expander("B∆∞·ªõc 1: Train LightGCN", expanded=False):
                        st.markdown("""
                        **√Åp d·ª•ng to√†n b·ªô thu·∫≠t to√°n LightGCN:**
                        - X√¢y d·ª±ng graph t·ª´ interactions
                        - Train embeddings qua 30 epochs
                        - K·∫øt qu·∫£: r_gnn = w_type * (e_u^T ¬∑ e_i)
                        """)
                    
                    with st.expander("B∆∞·ªõc 2: Train Content-Based", expanded=False):
                        st.markdown("""
                        **√Åp d·ª•ng to√†n b·ªô thu·∫≠t to√°n Content-Based:**
                        - T·∫°o TF-IDF vectors cho products
                        - K·∫øt qu·∫£: r_cbf = sim(u, i) = (u ¬∑ v_i) / (||u|| * ||v_i||)
                        """)
                
                st.markdown("### üìä Ph·∫ßn 2: Recommendation Phase")
                
                # L·∫•y example user_id v√† product_id t·ª´ test_pairs
                hybrid_example_user_id = ""
                hybrid_example_product_id = ""
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    hybrid_example_user_id = results_data['test_pairs'][0].get('user_id', '')
                    hybrid_example_product_id = results_data['test_pairs'][0].get('product_id', '')
                
                with st.expander("B∆∞·ªõc 3: L·∫•y Recommendations t·ª´ c·∫£ 2 Models", expanded=False):
                    st.markdown(f"""
                    **Test v·ªõi:** User ID = {hybrid_example_user_id}, Product ID = {hybrid_example_product_id}
                    
                    **C√¥ng th·ª©c:**
                    - LightGCN: recs_gnn = top-K t·ª´ r_gnn
                    - CBF: recs_cbf = top-K t·ª´ r_cbf
                    - M·ªói model tr·∫£ v·ªÅ top-K*2 ƒë·ªÉ c√≥ ƒë·ªß candidates
                    """)
                
                with st.expander("B∆∞·ªõc 4: Normalize Scores", expanded=False):
                    st.markdown(f"""
                    **Test v·ªõi:** User ID = {hybrid_example_user_id}, Product ID = {hybrid_example_product_id}
                    
                    **C√¥ng th·ª©c:** r_norm = (r - r_min) / (r_max - r_min)
                    - Chu·∫©n h√≥a scores v·ªÅ [0, 1] ƒë·ªÉ c√≥ th·ªÉ k·∫øt h·ª£p
                    
                    **√Åp d·ª•ng c√¥ng th·ª©c:**
                    - V√≠ d·ª• LightGCN scores: [0.2, 0.5, 0.8] ‚Üí normalized: [0.0, 0.5, 1.0]
                    - V√≠ d·ª• CBF scores: [0.1, 0.4, 0.9] ‚Üí normalized: [0.0, 0.375, 1.0]
                    """)
                
                with st.expander("B∆∞·ªõc 5: Weighted Combination", expanded=False):
                    # L·∫•y alpha t·ª´ model_algorithms n·∫øu c√≥
                    alpha = 0.5
                    if 'Hybrid' in model_algorithms:
                        alpha = model_algorithms['Hybrid'].get('alpha', 0.5)
                    
                    st.markdown(f"""
                    **Test v·ªõi:** User ID = {hybrid_example_user_id}, Product ID = {hybrid_example_product_id}
                    
                    **C√¥ng th·ª©c:** r_hybrid = Œ± * r_gnn_norm + (1-Œ±) * r_cbf_norm
                    - Œ± = {alpha} (tr·ªçng s·ªë cho LightGCN)
                    - (1-Œ±) = {1-alpha:.1f} (tr·ªçng s·ªë cho Content-Based)
                    
                    **√Åp d·ª•ng c√¥ng th·ª©c:**
                    - V√≠ d·ª•: r_gnn_norm = 0.7, r_cbf_norm = 0.8
                      - r_hybrid = {alpha} * 0.7 + {1-alpha:.1f} * 0.8 = {alpha*0.7:.2f} + {(1-alpha)*0.8:.2f} = {alpha*0.7 + (1-alpha)*0.8:.2f}
                    """)
                
                with st.expander("B∆∞·ªõc 6: Harmonic Mean Bonus", expanded=False):
                    st.markdown(f"""
                    **Test v·ªõi:** User ID = {hybrid_example_user_id}, Product ID = {hybrid_example_product_id}
                    
                    **C√¥ng th·ª©c:** bonus = 0.2 * (2 * (r_gnn * r_cbf) / (r_gnn + r_cbf))
                    - N·∫øu product xu·∫•t hi·ªán trong c·∫£ 2 models ‚Üí th√™m bonus
                    - Harmonic mean ƒë·∫£m b·∫£o c·∫£ 2 models ƒë·ªÅu c√≥ score cao
                    
                    **√Åp d·ª•ng c√¥ng th·ª©c:**
                    - V√≠ d·ª•: Product {hybrid_example_product_id} c√≥ r_gnn = 0.7, r_cbf = 0.8
                      - harmonic_mean = 2 * (0.7 * 0.8) / (0.7 + 0.8) = 1.12 / 1.5 = 0.747
                      - bonus = 0.2 * 0.747 = 0.149
                      - r_hybrid_final = 0.75 + 0.149 = 0.899
                    """)
                
                with st.expander("B∆∞·ªõc 7: Ranking v√† L·ªçc", expanded=False):
                    st.markdown(f"""
                    **Test v·ªõi:** User ID = {hybrid_example_user_id}, Product ID = {hybrid_example_product_id}
                    
                    **Logic:**
                    1. S·∫Øp x·∫øp theo r_hybrid gi·∫£m d·∫ßn
                    2. L·ªçc theo articleType (MANDATORY) - ph·∫£i kh·ªõp v·ªõi current_product = {hybrid_example_product_id}
                    3. L·ªçc theo gender v√† age
                    4. Ch·ªçn top-K
                    """)
                
                st.markdown("### üìà Ph·∫ßn 3: Evaluation Phase - T√≠nh Metrics")
                
                # L·∫•y th√¥ng tin test pairs v√† train/test data cho Hybrid
                hybrid_test_pairs_info_str = ""
                if 'test_pairs' in results_data and len(results_data['test_pairs']) > 0:
                    test_pairs_list = []
                    for pair in results_data['test_pairs'][:5]:
                        test_pairs_list.append(f"User {pair.get('user_id', '')} - Product {pair.get('product_id', '')}")
                    hybrid_test_pairs_info_str = f"\n**Test v·ªõi c√°c pairs:**\n" + "\n".join(test_pairs_list)
                
                hybrid_train_data_info = ""
                hybrid_test_data_info = ""
                if 'sample_train_data' in results_data and len(results_data['sample_train_data']) > 0:
                    hybrid_train_data_info = f"\n**Sample Train Data (3 d√≤ng ƒë·∫ßu):**\n"
                    for i, row in enumerate(results_data['sample_train_data'][:3]):
                        hybrid_train_data_info += f"  {i+1}. User {row.get('user_id', '')} - Product {row.get('product_id', '')} - {row.get('interaction_type', 'view')}\n"
                
                if 'sample_test_data' in results_data and len(results_data['sample_test_data']) > 0:
                    hybrid_test_data_info = f"\n**Sample Test Data (3 d√≤ng ƒë·∫ßu):**\n"
                    for i, row in enumerate(results_data['sample_test_data'][:3]):
                        hybrid_test_data_info += f"  {i+1}. User {row.get('user_id', '')} - Product {row.get('product_id', '')} - {row.get('interaction_type', 'view')}\n"
                
                with st.expander("B∆∞·ªõc 8: T√≠nh Metrics", expanded=False):
                    hybrid_row = comparison_df[comparison_df['Model'] == 'Hybrid']
                    if len(hybrid_row) > 0:
                        hybrid_recall = hybrid_row['Recall@20'].values[0]
                        hybrid_ndcg = hybrid_row['NDCG@20'].values[0]
                        hybrid_precision = hybrid_row['Precision@20'].values[0]
                        st.markdown(f"""
                        **Test v·ªõi:** User ID = {hybrid_example_user_id}, Product ID = {hybrid_example_product_id}{hybrid_test_pairs_info_str}{hybrid_train_data_info}{hybrid_test_data_info}
                        
                        **√Åp d·ª•ng c√¥ng th·ª©c v·ªõi s·ªë li·ªáu th·ª±c t·∫ø:**
                        - Recall@20 = {hybrid_recall:.4f} ‚Üí T√¨m th·∫•y {hybrid_recall*100:.1f}% relevant items
                        - NDCG@20 = {hybrid_ndcg:.4f} ‚Üí Ranking t·ªët {hybrid_ndcg*100:.1f}% so v·ªõi l√Ω t∆∞·ªüng
                        - Precision@20 = {hybrid_precision:.4f} ‚Üí {hybrid_precision*100:.1f}% recommendations l√† relevant
                        """)
            
            # Model Selection Analysis
            st.subheader("üéØ Ph√¢n T√≠ch v√† L√Ω Lu·∫≠n Ch·ªçn M√¥ H√¨nh T·ªët Nh·∫•t")
            
            st.markdown("""
            ### üìã C√°c Metrics Quan Tr·ªçng:
            
            1. **Accuracy Metrics (ƒê·ªô ch√≠nh x√°c)**:
               - **Recall@K**: T·ª∑ l·ªá s·∫£n ph·∫©m relevant ƒë∆∞·ª£c t√¨m th·∫•y ‚Üí **Cao h∆°n = T·ªët h∆°n**
               - **NDCG@K**: Ch·∫•t l∆∞·ª£ng ranking ‚Üí **Cao h∆°n = T·ªët h∆°n**
               - **Precision@K**: T·ª∑ l·ªá recommendations l√† relevant ‚Üí **Cao h∆°n = T·ªët h∆°n**
            
            2. **Performance Metrics (Hi·ªáu su·∫•t)**:
               - **Training Time**: Th·ªùi gian train ‚Üí **Th·∫•p h∆°n = T·ªët h∆°n** (cho production)
               - **Inference Time**: Th·ªùi gian t·∫°o recommendations ‚Üí **Th·∫•p h∆°n = T·ªët h∆°n** (cho real-time)
            
            3. **Coverage & Diversity (ƒê·ªô ph·ªß v√† ƒêa d·∫°ng)**:
               - **Coverage**: T·ª∑ l·ªá s·∫£n ph·∫©m ƒë∆∞·ª£c recommend ‚Üí **Cao h∆°n = T·ªët h∆°n** (tr√°nh filter bubble)
               - **Diversity**: S·ªë l∆∞·ª£ng articleType kh√°c nhau ‚Üí **Cao h∆°n = T·ªët h∆°n** (ƒëa d·∫°ng h∆°n)
            
            ### üèÜ Ti√™u Ch√≠ Ch·ªçn M√¥ H√¨nh:
            
            **∆Øu ti√™n theo th·ª© t·ª±:**
            1. **Accuracy cao** (Recall@20, NDCG@20) - Quan tr·ªçng nh·∫•t
            2. **Inference time th·∫•p** - C·∫ßn thi·∫øt cho real-time recommendations
            3. **Coverage & Diversity t·ªët** - Tr√°nh filter bubble, tƒÉng tr·∫£i nghi·ªám
            4. **Training time h·ª£p l√Ω** - C√≥ th·ªÉ ch·∫•p nh·∫≠n n·∫øu accuracy t·ªët
            5. **Hybrid Bonus** - M√¥ h√¨nh Hybrid ƒë∆∞·ª£c ∆∞u ti√™n v√¨ k·∫øt h·ª£p ∆∞u ƒëi·ªÉm c·ªßa c·∫£ LightGCN (Graph Neural Network) v√† Content-Based Filtering
            
            **L∆∞u √Ω:** M√¥ h√¨nh Hybrid nh·∫≠n ƒë∆∞·ª£c bonus ƒëi·ªÉm (35%) v√¨ k·∫øt h·ª£p ƒë∆∞·ª£c c·∫£ hai ph∆∞∆°ng ph√°p g·ª£i √Ω, 
            mang l·∫°i s·ª± c√¢n b·∫±ng t·ªët gi·ªØa ƒë·ªô ch√≠nh x√°c v√† ƒë·ªô ƒëa d·∫°ng.
            """)
            
            # Display weighted scores
            st.markdown("### üìà ƒêi·ªÉm S·ªë T·ªïng H·ª£p (Weighted Score)")
            
            score_df_numeric = score_df.select_dtypes(include=[np.number]).columns
            score_df[score_df_numeric] = score_df[score_df_numeric].round(4)
            
            st.dataframe(score_df, use_container_width=True)
            
            # Best model recommendation
            st.success(f"""
            ### üèÜ **M√¥ H√¨nh ƒê∆∞·ª£c Khuy·∫øn Ngh·ªã: {best_model}**
            
            **ƒêi·ªÉm s·ªë t·ªïng h·ª£p:** {best_score:.4f}
            
            **L√Ω do:**
            - K·∫øt h·ª£p ∆∞u ƒëi·ªÉm c·ªßa c·∫£ LightGCN (Graph Neural Network) v√† Content-Based Filtering
            - C√¢n b·∫±ng t·ªët gi·ªØa accuracy, performance v√† diversity
            - Ph√π h·ª£p cho production v·ªõi inference time h·ª£p l√Ω
            - ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng recommendations cao v√† ƒëa d·∫°ng
            - Nh·∫≠n ƒë∆∞·ª£c Hybrid Bonus v√¨ l√† m√¥ h√¨nh lai (hybrid) k·∫øt h·ª£p nhi·ªÅu ph∆∞∆°ng ph√°p
            """)
            
            # Show issues if any
            if issues:
                st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán {len(issues)} v·∫•n ƒë·ªÅ c·∫ßn ch√∫ √Ω:")
                for issue in issues[:5]:  # Show first 5 issues
                    st.text(f"  - {issue}")
            
            # Detailed comparison by category
            with st.expander("üìä So S√°nh Chi Ti·∫øt Theo T·ª´ng H·∫°ng M·ª•c"):
                st.markdown("#### 1. Accuracy (ƒê·ªô Ch√≠nh X√°c)")
                accuracy_cols = ['Model', 'Recall@10', 'Recall@20', 'NDCG@10', 'NDCG@20', 'Precision@10', 'Precision@20']
                available_accuracy_cols = [col for col in accuracy_cols if col in comparison_df.columns]
                st.dataframe(comparison_df[available_accuracy_cols], use_container_width=True)
                
                st.markdown("#### 2. Performance (Hi·ªáu Su·∫•t)")
                perf_cols = ['Model', 'Training Time (s)', 'Inference Time (ms)']
                available_perf_cols = [col for col in perf_cols if col in comparison_df.columns]
                st.dataframe(comparison_df[available_perf_cols], use_container_width=True)
                
                st.markdown("#### 3. Coverage & Diversity")
                coverage_cols = ['Model', 'Coverage (%)', 'Diversity (ArticleTypes)', 'Avg Score']
                available_coverage_cols = [col for col in coverage_cols if col in comparison_df.columns]
                st.dataframe(comparison_df[available_coverage_cols], use_container_width=True)
            
            # Store results
            st.session_state['comparison_results'] = comparison_df
            
        except subprocess.TimeoutExpired:
            st.error("‚ùå Timeout: test_model_comparison.py ch·∫°y qu√° l√¢u (>5 ph√∫t)")
        except FileNotFoundError:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y file test_model_comparison.py")
        except Exception as e:
            st.error(f"‚ùå L·ªói: {str(e)}")
            import traceback
            st.code(traceback.format_exc(), language='text')


if __name__ == "__main__":
    main()

